{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1aWliW/m4TXw+LC4BA3CW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "gpu_env",
      "display_name": "Python (GPU)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayyanar7/2023/blob/main/FirstGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i4wd5Nux-JgL"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze-S-dgXNaV2",
        "outputId": "c50203f7-3357-4deb-9cd6-cc232ca42b8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40fQrftJlbi2",
        "outputId": "64ef16f4-4477-4e3f-bd6e-d6f5f15603d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1j2MgAohVCv",
        "outputId": "cf7bbced-83d6-4b47-f137-6e9375bd1af7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torchvision in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (0.22.1)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.7.1 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (2.7.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.7.1->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.7.1->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.7.1->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.7.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.7.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.7.1->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.7.1->torchvision) (75.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch==2.7.1->torchvision) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMxnutjIik9Y",
        "outputId": "5cc63cc7-3edd-4b5c-e73c-87f385702fe8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.66.5)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pytorch_fid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCf_68RCiqXF",
        "outputId": "63057b16-fd3e-444e-a91d-84b5f28d3243"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pytorch_fid in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_fid) (1.26.4)\n",
            "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_fid) (10.4.0)\n",
            "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch_fid) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from pytorch_fid) (2.7.1)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from pytorch_fid) (0.22.1)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch_fid) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch_fid) (4.11.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.0.1->pytorch_fid) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch_fid) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch_fid) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch_fid) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch_fid) (75.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch_fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.0.1->pytorch_fid) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from copy import deepcopy\n",
        "from torch.nn.utils.spectral_norm import spectral_norm\n",
        "# from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "# from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4FqJkSIbNe00"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__\n",
        "# np.__version__\n",
        "# pytorch_fid.__version__\n",
        "# pytorch_image_generation_metrics.__version__\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b9eWQaakI4n",
        "outputId": "a8f2418e-9350-4365-eb67-5229ee693734"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pytorch-fid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIFQAsL2moPy",
        "outputId": "37622318-cfb0-476e-da40-cea82257445c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pytorch-fid in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-fid) (1.26.4)\n",
            "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-fid) (10.4.0)\n",
            "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-fid) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from pytorch-fid) (2.7.1)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from pytorch-fid) (0.22.1)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (4.11.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.1->pytorch-fid) (75.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.0.1->pytorch-fid) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_fid import fid_score\n",
        "# from pytorch-gan-metrics import get_inception_score, ImageDataset\n",
        "# from pytorch_image_generation_metrics import get_inception_score, ImageDataset"
      ],
      "metadata": {
        "id": "zKzz_3mhOSy8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "c287d9bd-bb40-4524-8724-6a299ea889e5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytorch_fid'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_fid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fid_score\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# from pytorch-gan-metrics import get_inception_score, ImageDataset\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# from pytorch_image_generation_metrics import get_inception_score, ImageDataset\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pytorch_fid'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zCTu2fQJiGk6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b83935f4",
        "outputId": "2de463b8-b143-4edc-e751-19799ebe4c57"
      },
      "source": [
        "!pip install pytorch-image-generation-metrics"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pytorch-image-generation-metrics in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def DiffAugment(x, policy='', channels_first=True):\n",
        "    if policy:\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 3, 1, 2)\n",
        "        for p in policy.split(','):\n",
        "            for f in AUGMENT_FNS[p]:\n",
        "                x = f(x)\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 2, 3, 1)\n",
        "        x = x.contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_brightness(x):\n",
        "    x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_saturation(x):\n",
        "    x_mean = x.mean(dim=1, keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 2) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_contrast(x):\n",
        "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.5) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_translation(x, ratio=0.125):\n",
        "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
        "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
        "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
        "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2).contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_cutout(x, ratio=0.5):\n",
        "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
        "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
        "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
        "    mask[grid_batch, grid_x, grid_y] = 0\n",
        "    x = x * mask.unsqueeze(1)\n",
        "    return x\n",
        "\n",
        "\n",
        "AUGMENT_FNS = {\n",
        "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
        "    'translation': [rand_translation],\n",
        "    'cutout': [rand_cutout],\n",
        "}"
      ],
      "metadata": {
        "id": "_OLxp9Fpm393"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryStep(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return (input > 0.).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        zero_index = torch.abs(input) > 1\n",
        "        middle_index = (torch.abs(input) <= 1) * (torch.abs(input) > 0.4)\n",
        "        additional = 2 - 4 * torch.abs(input)\n",
        "        additional[zero_index] = 0.\n",
        "        additional[middle_index] = 0.4\n",
        "        return grad_input * additional\n",
        "\n",
        "\n",
        "class MaskedMLP(nn.Module):\n",
        "    def __init__(self, in_size, out_size, bias=True, sparse_train=False):\n",
        "        super(MaskedMLP, self).__init__()\n",
        "        self.in_size = in_size\n",
        "        self.out_size = out_size\n",
        "        self.weight = nn.Parameter(torch.Tensor(out_size, in_size))\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_size))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.threshold = nn.Parameter(torch.Tensor(out_size))\n",
        "        self.step = BinaryStep.apply\n",
        "        self.mask = None\n",
        "        self.sparse_train = sparse_train\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        # if self.bias is not None:\n",
        "        #     fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "        #     bound = 1 / math.sqrt(fan_in)\n",
        "        #     nn.init.uniform_(self.bias, -bound, bound)\n",
        "        nn.init.xavier_uniform(self.weight.data, 1.)\n",
        "        if self.bias is not None:\n",
        "            nn.init.zeros_(self.bias)\n",
        "        with torch.no_grad():\n",
        "            # std = self.weight.std()\n",
        "            self.threshold.data.fill_(0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        if self.sparse_train:\n",
        "            # print('sparse training')\n",
        "            abs_weight = torch.abs(self.weight)\n",
        "            threshold = self.threshold.view(abs_weight.shape[0], -1)\n",
        "            abs_weight = abs_weight - threshold\n",
        "            mask = self.step(abs_weight)\n",
        "            ratio = torch.sum(mask) / mask.numel()\n",
        "            # print(\"keep ratio {:.2f}\".format(ratio))\n",
        "            if ratio <= 0.01:\n",
        "                with torch.no_grad():\n",
        "                    # std = self.weight.std()\n",
        "                    self.threshold.data.fill_(0)\n",
        "                abs_weight = torch.abs(self.weight)\n",
        "                threshold = self.threshold.view(abs_weight.shape[0], -1)\n",
        "                abs_weight = abs_weight - threshold\n",
        "                mask = self.step(abs_weight)\n",
        "            self.mask = mask.bool()\n",
        "        else:\n",
        "            # print('dense training')\n",
        "            self.mask = torch.ones_like(self.weight).bool()\n",
        "        # masked_weight = self.weight * mask\n",
        "        output = torch.nn.functional.linear(input, self.weight * self.mask, self.bias)\n",
        "        return output\n",
        "\n",
        "\n",
        "class MaskedConv2d(nn.Module):\n",
        "    def __init__(self, in_c, out_c, kernel_size, stride=1,\n",
        "                 padding=0, dilation=1, groups=1, bias=True, sparse_train=False):\n",
        "        super(MaskedConv2d, self).__init__()\n",
        "        self.in_channels = in_c\n",
        "        self.out_channels = out_c\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.groups = groups\n",
        "\n",
        "        ## define weight\n",
        "        self.weight = nn.Parameter(torch.Tensor(\n",
        "            out_c, in_c // groups, *kernel_size\n",
        "        ))\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_c))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.threshold = nn.Parameter(torch.Tensor(out_c))\n",
        "        self.step = BinaryStep.apply\n",
        "        self.mask = None\n",
        "        self.sparse_train = sparse_train\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        # if self.bias is not None:\n",
        "        #     fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "        #     bound = 1 / math.sqrt(fan_in)\n",
        "        #     nn.init.uniform_(self.bias, -bound, bound)\n",
        "        nn.init.xavier_uniform(self.weight.data, 1.)\n",
        "        if self.bias is not None:\n",
        "            nn.init.zeros_(self.bias)\n",
        "        with torch.no_grad():\n",
        "            self.threshold.data.fill_(0.)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(self.sparse_train)\n",
        "        if self.sparse_train:\n",
        "            # print('sparse training')\n",
        "            weight_shape = self.weight.shape\n",
        "            threshold = self.threshold.view(weight_shape[0], -1)\n",
        "            weight = torch.abs(self.weight)\n",
        "            weight = weight.view(weight_shape[0], -1)\n",
        "            weight = weight - threshold\n",
        "            mask = self.step(weight)\n",
        "            mask = mask.view(weight_shape)\n",
        "            ratio = torch.sum(mask) / mask.numel()\n",
        "            # print(\"threshold {:3f}\".format(self.threshold[0]))\n",
        "            # print(\"keep ratio {:.2f}\".format(ratio))\n",
        "            if ratio <= 0.01:\n",
        "                with torch.no_grad():\n",
        "                    self.threshold.data.fill_(0.)\n",
        "                threshold = self.threshold.view(weight_shape[0], -1)\n",
        "                weight = torch.abs(self.weight)\n",
        "                weight = weight.view(weight_shape[0], -1)\n",
        "                weight = weight - threshold\n",
        "                mask = self.step(weight)\n",
        "                mask = mask.view(weight_shape)\n",
        "            self.mask = mask.bool()\n",
        "        # masked_weight = self.weight * mask\n",
        "        else:\n",
        "            # print('dense training')\n",
        "            self.mask = torch.ones_like(self.weight).bool()\n",
        "        # self.weight.retain_grad()\n",
        "        conv_out = torch.nn.functional.conv2d(x, self.weight * self.mask, bias=self.bias, stride=self.stride,\n",
        "                                              padding=self.padding, dilation=self.dilation, groups=self.groups)\n",
        "        return conv_out\n",
        "\n",
        "\n",
        "def print_layer_keep_ratio(model):\n",
        "    total = 0.\n",
        "    keep = 0.\n",
        "    layer_keep = []\n",
        "    # print(model.modules())\n",
        "    for layer in model.modules():\n",
        "        if isinstance(layer, MaskedMLP):\n",
        "            total, keep, layer_keep = count_mlp(layer, total, keep, layer_keep)\n",
        "        elif isinstance(layer, MaskedConv2d):\n",
        "            total, keep, layer_keep = count_conv(layer, total, keep, layer_keep)\n",
        "    return keep / total, layer_keep\n",
        "\n",
        "\n",
        "def count_mlp(layer, total, keep, layer_keep):\n",
        "    abs_weight = torch.abs(layer.weight)\n",
        "    threshold = layer.threshold.view(abs_weight.shape[0], -1)\n",
        "    abs_weight = abs_weight - threshold\n",
        "    mask = layer.step(abs_weight)\n",
        "    ratio = torch.sum(mask) / mask.numel()\n",
        "    total += mask.numel()\n",
        "    keep += torch.sum(mask)\n",
        "    # logger.info(\"Layer threshold {:.4f}\".format(layer.threshold[0]))\n",
        "    layer_ratio = \"{}, keep ratio {:.4f}\".format(layer, ratio)\n",
        "    print(layer_ratio)\n",
        "    layer_keep.append(layer_ratio)\n",
        "    return total, keep, layer_keep\n",
        "\n",
        "\n",
        "def count_conv(layer, total, keep, layer_keep):\n",
        "    weight_shape = layer.weight.shape\n",
        "    threshold = layer.threshold.view(weight_shape[0], -1)\n",
        "    weight = torch.abs(layer.weight)\n",
        "    weight = weight.view(weight_shape[0], -1)\n",
        "    weight = weight - threshold\n",
        "    mask = layer.step(weight)\n",
        "    # print(mask)\n",
        "    ratio = torch.sum(mask) / mask.numel()\n",
        "    total += mask.numel()\n",
        "    keep += torch.sum(mask)\n",
        "    layer_ratio = \"{}, keep ratio {:.4f}\".format(layer, ratio)\n",
        "    print(layer_ratio)\n",
        "    layer_keep.append(layer_ratio)\n",
        "    return total, keep, layer_keep\n",
        "\n",
        "\n",
        "def set_training_mode(model, training_mode):\n",
        "    for layer in model.modules():\n",
        "        if isinstance(layer, MaskedMLP) or isinstance(layer, MaskedConv2d):\n",
        "            layer.sparse_train = training_mode\n",
        "\n",
        "\n",
        "def sparsity_regularizer(model, lambda_):\n",
        "    sr_loss = 0\n",
        "    for layer in model.modules():\n",
        "        if isinstance(layer, MaskedConv2d) or isinstance(layer, MaskedMLP):\n",
        "            sr_loss += lambda_ * torch.sum(torch.exp(-layer.threshold))\n",
        "\n",
        "    return sr_loss\n",
        "\n",
        "def copy_params(model):\n",
        "    flatten = deepcopy(list(p.data for p in model.parameters()))\n",
        "    return flatten\n",
        "\n",
        "\n",
        "def load_params(model, new_param):\n",
        "    for p, new_p in zip(model.parameters(), new_param):\n",
        "        p.data.copy_(new_p)\n"
      ],
      "metadata": {
        "id": "yjzgP97NnNBe"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ResGenBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            MaskedConv2d(in_channels, out_channels, (3, 3), stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            MaskedConv2d(out_channels, out_channels, (3, 3), stride=1, padding=1),\n",
        "        )\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            MaskedConv2d(in_channels, out_channels, (1, 1), stride=1, padding=0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.residual(x) + self.shortcut(x)\n",
        "\n",
        "\n",
        "class RG_ResGenerator32(nn.Module):\n",
        "    def __init__(self, z_dim, sparse_train_mode=False):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.linear = MaskedMLP(z_dim, 4 * 4 * 256)\n",
        "        self.sparse_train_mode = sparse_train_mode\n",
        "        self.blocks = nn.Sequential(\n",
        "            ResGenBlock(256, 256),\n",
        "            ResGenBlock(256, 256),\n",
        "            ResGenBlock(256, 256),\n",
        "        )\n",
        "        self.output = nn.Sequential(\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            MaskedConv2d(256, 3, (3, 3), stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        # self.set_training_mode()\n",
        "        z = self.linear(z)\n",
        "        z = z.view(-1, 256, 4, 4)\n",
        "        return self.output(self.blocks(z))\n",
        "\n",
        "\n",
        "class OptimizedResDisblock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            MaskedConv2d(in_channels, out_channels, (1, 1), 1, 0))\n",
        "        self.residual = nn.Sequential(\n",
        "            MaskedConv2d(in_channels, out_channels, (3, 3), 1, 1),\n",
        "            nn.ReLU(),\n",
        "            MaskedConv2d(out_channels, out_channels, (3, 3), 1, 1),\n",
        "            nn.AvgPool2d(2))\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        for m in self.residual.modules():\n",
        "            if isinstance(m, MaskedConv2d):\n",
        "                # init.xavier_uniform_(m.weight, math.sqrt(2))\n",
        "                # init.zeros_(m.bias)\n",
        "                spectral_norm(m)\n",
        "        for m in self.shortcut.modules():\n",
        "            if isinstance(m, MaskedConv2d):\n",
        "                # init.xavier_uniform_(m.weight)\n",
        "                # init.zeros_(m.bias)\n",
        "                spectral_norm(m)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(self.residual(x))\n",
        "        return self.residual(x) + self.shortcut(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "F_sRcXigneZp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResDisBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=False):\n",
        "        super().__init__()\n",
        "        shortcut = []\n",
        "        if in_channels != out_channels or down:\n",
        "            shortcut.append(\n",
        "                MaskedConv2d(in_channels, out_channels, (1, 1), 1, 0))\n",
        "        if down:\n",
        "            shortcut.append(nn.AvgPool2d(2))\n",
        "        self.shortcut = nn.Sequential(*shortcut)\n",
        "\n",
        "        residual = [\n",
        "            nn.ReLU(),\n",
        "            MaskedConv2d(in_channels, out_channels, (3, 3), 1, 1),\n",
        "            nn.ReLU(),\n",
        "            MaskedConv2d(out_channels, out_channels, (3, 3), 1, 1),\n",
        "        ]\n",
        "        if down:\n",
        "            residual.append(nn.AvgPool2d(2))\n",
        "        self.residual = nn.Sequential(*residual)\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        for m in self.residual.modules():\n",
        "            if isinstance(m, MaskedConv2d):\n",
        "                spectral_norm(m)\n",
        "        for m in self.shortcut.modules():\n",
        "            if isinstance(m, MaskedConv2d):\n",
        "                spectral_norm(m)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.residual(x) + self.shortcut(x)\n",
        "\n",
        "\n",
        "class RG_ResDiscriminator32(nn.Module):\n",
        "    def __init__(self, sparse_train_mode=False):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            OptimizedResDisblock(3, 128),\n",
        "            ResDisBlock(128, 128, down=True),\n",
        "            ResDisBlock(128, 128),\n",
        "            ResDisBlock(128, 128),\n",
        "            nn.ReLU())\n",
        "        self.linear = MaskedMLP(128, 1, bias=False)\n",
        "        self.initialize()\n",
        "        self.sparse_train_mode = sparse_train_mode\n",
        "\n",
        "    def initialize(self):\n",
        "        spectral_norm(self.linear)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x).sum(dim=[2, 3])\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "CBEEm51XnfNo"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Create the dataset\n",
        "    dataset = dset.CIFAR10(root=args.dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(args.image_size),\n",
        "                               transforms.CenterCrop(args.image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]), download=True, train=True)\n",
        "\n",
        "    # Make sub-training dataset\n",
        "    subset = torch.utils.data.Subset(dataset, np.arange(int(len(dataset) * args.data_ratio)))\n",
        "    # Create the dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(subset, batch_size=args.batch_size,\n",
        "                                             shuffle=True, num_workers=args.workers)\n",
        "\n",
        "    netD = RG_ResDiscriminator32().to(device)\n",
        "    netG = RG_ResGenerator32(args.noise_size).to(device)\n",
        "\n",
        "    netG_avg_param = copy_params(netG)\n",
        "\n",
        "    netG.sparse_train_mode = True\n",
        "    netD.sparse_train_mode = True\n",
        "\n",
        "    set_training_mode(netG, netG.sparse_train_mode)\n",
        "    set_training_mode(netD, netD.sparse_train_mode)\n",
        "\n",
        "    # Setup Adam optimizers for both G and D\n",
        "    optimizerD = optim.Adam(netD.parameters(), args.lr, (0, 0.9))\n",
        "    optimizerG = optim.Adam(netG.parameters(), args.lr, (0, 0.9))\n",
        "\n",
        "    fixed_noise = torch.randn(64, args.noise_size, device=device)\n",
        "\n",
        "    print(\"Starting Training Loop...\")\n",
        "    best_fid = 9999\n",
        "    fid_record = []\n",
        "\n",
        "    for epoch in range(1, args.epoch + 1):\n",
        "\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "            netD.zero_grad()\n",
        "            real_cpu = data[0].to(device)\n",
        "            b_size = real_cpu.size(0)\n",
        "\n",
        "            if diffaug_flag:\n",
        "                real_cpu = DiffAugment(real_cpu, policy=policy)\n",
        "\n",
        "            output = netD(real_cpu).view(-1)\n",
        "            errD_real = torch.mean(nn.ReLU(inplace=True)(1.0 - output))\n",
        "\n",
        "            if netD.sparse_train_mode:\n",
        "                sr_loss = sparsity_regularizer(netD, args.lambda_)\n",
        "                errD_real = errD_real + sr_loss\n",
        "\n",
        "            errD_real.backward()\n",
        "            D_x = output.mean().item()\n",
        "\n",
        "            noise = torch.randn(b_size, args.noise_size, device=device)\n",
        "            fake = netG(noise)\n",
        "\n",
        "            if diffaug_flag:\n",
        "                fake = DiffAugment(fake, policy=policy)\n",
        "\n",
        "            output = netD(fake.detach()).view(-1)\n",
        "            errD_fake = torch.mean(nn.ReLU(inplace=True)(1 + output))\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = output.mean().item()\n",
        "            errD = errD_real + errD_fake\n",
        "\n",
        "            if netD.sparse_train_mode:\n",
        "                for layer in netD.modules():\n",
        "                    if isinstance(layer, MaskedConv2d) or isinstance(layer, MaskedMLP):\n",
        "                        try:\n",
        "                            layer.weight_orig.grad.data = layer.weight_orig.grad.data * layer.mask\n",
        "                        except:\n",
        "                            layer.weight.grad.data = layer.weight.grad.data * layer.mask\n",
        "\n",
        "            optimizerD.step()\n",
        "\n",
        "            if i % args.n_critic == 0:\n",
        "                netG.zero_grad()\n",
        "                noise = torch.randn(b_size, args.noise_size, device=device)\n",
        "                fake = netG(noise)\n",
        "\n",
        "                if diffaug_flag:\n",
        "                    fake = DiffAugment(fake, policy=policy)\n",
        "\n",
        "                output = netD(fake).view(-1)\n",
        "                errG = -torch.mean(output)\n",
        "\n",
        "                if netG.sparse_train_mode:\n",
        "                    sr_loss = sparsity_regularizer(netG, args.lambda_)\n",
        "                    errG = errG + sr_loss\n",
        "\n",
        "                errG.backward()\n",
        "                D_G_z2 = output.mean().item()\n",
        "\n",
        "                if netG.sparse_train_mode:\n",
        "                    for layer in netG.modules():\n",
        "\n",
        "                        if isinstance(layer, MaskedConv2d) or isinstance(layer, MaskedMLP):\n",
        "                            try:\n",
        "                                layer.weight_orig.grad.data = layer.weight_orig.grad.data * layer.mask\n",
        "                            except:\n",
        "                                layer.weight.grad.data = layer.weight.grad.data * layer.mask\n",
        "\n",
        "                optimizerG.step()\n",
        "\n",
        "                # moving average weight\n",
        "                for p, avg_p in zip(netG.parameters(), netG_avg_param):\n",
        "                    avg_p.mul_(0.999).add_(0.001, p.data)\n",
        "\n",
        "            # Output training stats\n",
        "            if i % 50 == 0:\n",
        "                print('[%4d/%4d][%3d/%3d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                      % (epoch, args.epoch, i, len(dataloader),\n",
        "                         errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Evaluation\n",
        "        if epoch % args.eva_epoch == 0:\n",
        "\n",
        "            if netD.sparse_train_mode:\n",
        "                d_current_keep_ratio, d_layer_keep_ratio = print_layer_keep_ratio(netD)\n",
        "                print('D keep ratio: %.4f' % d_current_keep_ratio)\n",
        "                with open('%s/D_keep_ratio_lambda_%s.txt' % (current_model_result_dir, str(args.lambda_)), 'a') as f:\n",
        "                    f.write('epoch: %d' % epoch + '\\n')\n",
        "                    for x in d_layer_keep_ratio:\n",
        "                        f.write(x + '\\n')\n",
        "                    f.write('Overall:' + str(d_current_keep_ratio.item()) + '\\n')\n",
        "                    f.write('\\n')\n",
        "            if netG.sparse_train_mode:\n",
        "                print('--------------')\n",
        "                g_current_keep_ratio, g_layer_keep_ratio = print_layer_keep_ratio(netG)\n",
        "                print('G keep ratio: %.4f' % g_current_keep_ratio)\n",
        "                with open('%s/G_keep_ratio_lambda_%s.txt' % (current_model_result_dir, str(args.lambda_)), 'a') as f:\n",
        "                    f.write('epoch: %d' % epoch + '\\n')\n",
        "                    for x in g_layer_keep_ratio:\n",
        "                        f.write(x + '\\n')\n",
        "                    f.write('Overall:' + str(g_current_keep_ratio.item()) + '\\n')\n",
        "                    f.write('\\n')\n",
        "\n",
        "            backup_param = copy_params(netG)\n",
        "            load_params(netG, netG_avg_param)\n",
        "            netG.eval()\n",
        "\n",
        "            fake = netG(fixed_noise).detach().cpu()\n",
        "            torchvision.utils.save_image(torchvision.utils.make_grid(fake, padding=2, normalize=True),\n",
        "                                './%s/epoch_%d.png' % (current_model_result_dir, epoch))\n",
        "            print('Epoch %2d viz images had been saved!' % epoch)\n",
        "\n",
        "            eva_size = 100\n",
        "            for iii in tqdm(range(args.eva_size // eva_size), desc='Generating images'):\n",
        "                Noisee = torch.randn(eva_size, args.noise_size, device=device)\n",
        "                temp_fake = netG(Noisee)\n",
        "                for iiii in range(eva_size):\n",
        "                    torchvision.utils.save_image(temp_fake[iiii].detach(),\n",
        "                                        '%s/f_%s.png' % (current_model_eva_dir, str(iii * eva_size + iiii)),\n",
        "                                        normalize=True, range=(-1, 1))\n",
        "            print('-' * 10 + 'Evaluation Begin' + '-' * 10)\n",
        "\n",
        "            print('----FID----')\n",
        "            print('-------------Eva FID------------')\n",
        "            fid = fid_score.calculate_fid_given_paths([current_model_eva_dir, './dataset/cifar10.test.npz'],\n",
        "                                                        100, device, 2048)\n",
        "\n",
        "            print('FID : %.4f' % fid)\n",
        "            if fid < best_fid:\n",
        "                best_fid = fid\n",
        "                print('----IS-----')\n",
        "                dataset = ImageDataset(current_model_eva_dir, exts=['png', 'jpg'])\n",
        "                loader = torch.utils.data.DataLoader(dataset, batch_size=100, num_workers=4)\n",
        "                IS, IS_std = get_inception_score(loader)\n",
        "                print('Inception Score: {:.2f} +/- {:.2f}'.format(IS, IS_std))\n",
        "\n",
        "            fid_record.append(fid)\n",
        "\n",
        "            load_params(netG, backup_param)\n",
        "\n",
        "            # avg_netG = deepcopy(netG)\n",
        "            # load_params(avg_netG, netG_avg_param)\n",
        "\n",
        "            if len(fid_record) >= 5:\n",
        "                print(fid_record[-5], fid_record[-4], fid_record[-3], fid_record[-2], fid_record[-1])\n",
        "                average_fid = 0.1 * fid_record[-5] + 0.1 * fid_record[-4] + 0.2 * fid_record[-3] + \\\n",
        "                              0.2 * fid_record[-2] + 0.4 * fid_record[-1]\n",
        "                print(average_fid)\n",
        "\n",
        "                if average_fid >= fid:\n",
        "                    netG.sparse_train_mode = True\n",
        "                    netD.sparse_train_mode = True\n",
        "                else:\n",
        "                    netG.sparse_train_mode = False\n",
        "                    netD.sparse_train_mode = False\n",
        "                set_training_mode(netG, netG.sparse_train_mode)\n",
        "                set_training_mode(netD, netD.sparse_train_mode)\n",
        "\n",
        "            netG.train()\n"
      ],
      "metadata": {
        "id": "OJjPm81Znv-b"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    model_name = 'RG-SNGAN'\n",
        "    argparser = argparse.ArgumentParser()\n",
        "    argparser.add_argument('--epoch', type=int, default=800)\n",
        "    argparser.add_argument('--batch_size', type=int, default=64)\n",
        "    argparser.add_argument('--lr', type=float, default=2e-4)\n",
        "    argparser.add_argument('--workers', type=int, default=4)\n",
        "    argparser.add_argument('--image_size', type=int, default=32)\n",
        "    argparser.add_argument('--noise_size', type=int, default=128)\n",
        "    argparser.add_argument('--dataroot', type=str, default='./dataset')\n",
        "    argparser.add_argument('--n_critic', type=int, default=5)\n",
        "    argparser.add_argument('--lambda_', type=float, default=1e-12)\n",
        "    argparser.add_argument('--data_ratio', type=float, default=1.0)\n",
        "    argparser.add_argument('--eva_size', type=int, default=10000)\n",
        "    argparser.add_argument('--eva_epoch', type=int, default=5)\n",
        "    argparser.add_argument('--diffaug', action='store_true', help='apply DiffAug')\n",
        "\n",
        "    # args = argparser.parse_args()\n",
        "    args, unknown = argparser.parse_known_args()\n",
        "    print(unknown)\n",
        "    print(args)\n",
        "    if not os.path.exists(args.dataroot):\n",
        "        os.makedirs(args.dataroot)\n",
        "\n",
        "    current_model_result_dir = './%s/result' % model_name\n",
        "\n",
        "    if not os.path.exists(current_model_result_dir):\n",
        "        os.makedirs(current_model_result_dir)\n",
        "\n",
        "    current_model_eva_dir = './%s/eva' % model_name\n",
        "\n",
        "    if not os.path.exists(current_model_eva_dir):\n",
        "        os.makedirs(current_model_eva_dir)\n",
        "\n",
        "    device = \"cuda\"\n",
        "\n",
        "    pre_calculated_fid_dir = './dataset/cifar10.test.npz'\n",
        "    assert os.path.exists(pre_calculated_fid_dir), 'Please put pre-calculated cifar10.test.npz file into ./dataset folder, you can download it from https://drive.google.com/drive/folders/1UBdzl6GtNMwNQ5U-4ESlIer43tNjiGJC'\n",
        "    print(pre_calculated_fid_dir)\n",
        "    if args.diffaug == 1:\n",
        "        policy = 'color,translation,cutout'\n",
        "        diffaug_flag = True\n",
        "        print('Diffaug is now enabled')\n",
        "    else:\n",
        "        diffaug_flag = False\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "ouNc7wRmn9hi",
        "outputId": "511a0d67-9464-4787-9db9-2ebe95b54673"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--epoch EPOCH] [--batch_size BATCH_SIZE] [--lr LR] [--workers WORKERS]\n",
            "                             [--image_size IMAGE_SIZE] [--noise_size NOISE_SIZE] [--dataroot DATAROOT]\n",
            "                             [--n_critic N_CRITIC] [--lambda_ LAMBDA_] [--data_ratio DATA_RATIO] [--eva_size EVA_SIZE]\n",
            "                             [--eva_epoch EVA_EPOCH] [--diffaug]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Admin\\AppData\\Roaming\\jupyter\\runtime\\kernel-b3c29120-3770-4a73-8b47-8417b414f43c.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "j5zk01i_oirP",
        "outputId": "befaa29e-693a-404e-dc50-52c0c60e0c3f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mSystemExit\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m argparser.add_argument(\u001b[33m'\u001b[39m\u001b[33m--eva_epoch\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[38;5;28mint\u001b[39m, default=\u001b[32m5\u001b[39m)\n\u001b[32m     16\u001b[39m argparser.add_argument(\u001b[33m'\u001b[39m\u001b[33m--diffaug\u001b[39m\u001b[33m'\u001b[39m, action=\u001b[33m'\u001b[39m\u001b[33mstore_true\u001b[39m\u001b[33m'\u001b[39m, help=\u001b[33m'\u001b[39m\u001b[33mapply DiffAug\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m args = \u001b[43margparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(args.dataroot):\n\u001b[32m     21\u001b[39m     os.makedirs(args.dataroot)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Environments\\Python313\\Lib\\argparse.py:1884\u001b[39m, in \u001b[36mArgumentParser.parse_args\u001b[39m\u001b[34m(self, args, namespace)\u001b[39m\n\u001b[32m   1882\u001b[39m msg = _(\u001b[33m'\u001b[39m\u001b[33munrecognized arguments: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m) % \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(argv)\n\u001b[32m   1883\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exit_on_error:\n\u001b[32m-> \u001b[39m\u001b[32m1884\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1886\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ArgumentError(\u001b[38;5;28;01mNone\u001b[39;00m, msg)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Environments\\Python313\\Lib\\argparse.py:2665\u001b[39m, in \u001b[36mArgumentParser.error\u001b[39m\u001b[34m(self, message)\u001b[39m\n\u001b[32m   2663\u001b[39m \u001b[38;5;28mself\u001b[39m.print_usage(_sys.stderr)\n\u001b[32m   2664\u001b[39m args = {\u001b[33m'\u001b[39m\u001b[33mprog\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mself\u001b[39m.prog, \u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m: message}\n\u001b[32m-> \u001b[39m\u001b[32m2665\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[33;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Environments\\Python313\\Lib\\argparse.py:2652\u001b[39m, in \u001b[36mArgumentParser.exit\u001b[39m\u001b[34m(self, status, message)\u001b[39m\n\u001b[32m   2650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message:\n\u001b[32m   2651\u001b[39m     \u001b[38;5;28mself\u001b[39m._print_message(message, _sys.stderr)\n\u001b[32m-> \u001b[39m\u001b[32m2652\u001b[39m \u001b[43m_sys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mSystemExit\u001b[39m: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsX2QtftooIg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}