{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJwh/mH9a2O4xXQ37Vq1Y0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayyanar7/2023/blob/main/Text2Gan_Conditional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maX70SFw-hSW",
        "outputId": "670d0904-bee5-4b68-fad3-6528a6f985ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/kmahesh541/flowershd5dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.47G/3.47G [02:44<00:00, 22.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/kmahesh541/flowershd5dataset/versions/1\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kmahesh541/flowershd5dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hdf5_fpath = path+\"/flowers-hd5/data/flowers/flowers.hdf5\"\n",
        "print(hdf5_fpath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNrF4VzTBb6L",
        "outputId": "e2a3111e-88bb-4a80-c96b-d0ece3f6e55c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/kmahesh541/flowershd5dataset/versions/1/flowers-hd5/data/flowers/flowers.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import h5py\n",
        "import argparse\n",
        "import torch\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from datetime import timedelta\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "print(\"All libraries imported!\")\n",
        "\n",
        "f = h5py.File(hdf5_fpath)\n",
        "\n",
        "#1. to know the categories in hdf5 file\n",
        "print(list(f))\n",
        "print(\"\\nNo. of items in test = \",len(list(f['test'])))\n",
        "print(\"\\nNo. of items in train = \",len(list(f['train'])))\n",
        "print(\"\\nNo. of items in valid = \",len(list(f['valid'])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bNygeagBlai",
        "outputId": "07e69edd-0253-4645-d163-98105bec6d8a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported!\n",
            "['test', 'train', 'valid']\n",
            "\n",
            "No. of items in test =  5775\n",
            "\n",
            "No. of items in train =  29390\n",
            "\n",
            "No. of items in valid =  5780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NearestNeighbor:\n",
        "    def __init__(self, dataset, source, cuda, ngf):\n",
        "        self.dataset = dataset\n",
        "        data = None\n",
        "        representation = None\n",
        "        labels = []\n",
        "        embeddings = []\n",
        "        path = ''\n",
        "        data_path = path + 'source_{}_nn_data.pl'.format(source)\n",
        "        labels_path = path + 'source_{}_nn_labels.pl'.format(source)\n",
        "        nbrs_path = path + 'source_{}_nn.pl'.format(source)\n",
        "        embeddings_path = path + 'source_{}_nn_embeddings.pl'.format(source)\n",
        "        print(\"data_path: \",data_path)\n",
        "        print(\"data_path: \"+labels_path)\n",
        "        print(\"data_path: \"+nbrs_path)\n",
        "        print(\"data_path: \"+embeddings_path)\n",
        "        self.model = gan_factory.generator_factory('vae', ngf, False)\n",
        "        if cuda:\n",
        "            self.model = self.model.cuda()\n",
        "        #self.model.load_state_dict(torch.load('./checkpoints/flowers_autoencoder/gen.pth'))\n",
        "\n",
        "        if os.path.exists(data_path):\n",
        "            print('start loading data for NN test {}'.format(data_path))\n",
        "            data = pickle.load(open(data_path, 'rb'))\n",
        "            labels = pickle.load(open(labels_path, 'rb'))\n",
        "            nbrs = pickle.load(open(nbrs_path, 'rb'))\n",
        "            embeddings = pickle.load(open(embeddings_path, 'rb'))\n",
        "        else:\n",
        "            print('start creating data for NN test {}'.format(data_path))\n",
        "            for i, sample in enumerate(dataset):\n",
        "                #print(\"**** iter i = \",i)\n",
        "                if data is None:\n",
        "                    data = sample['right_images'].numpy()\n",
        "                    data_var = Variable(sample['right_images'].float(), volatile=True)\n",
        "                    if cuda:\n",
        "                        data_var = data_var.cuda()\n",
        "                    representation = self.model.encoder_only(data_var).data.cpu().numpy()\n",
        "                    labels = sample['txt']\n",
        "                    embeddings = sample['right_embed']\n",
        "                else:\n",
        "                    data = np.append(data, sample['right_images'].numpy(), axis=0)\n",
        "                    data_var = Variable(sample['right_images'].float(), volatile=True)\n",
        "                    if cuda:\n",
        "                        data_var = data_var.cuda()\n",
        "                    representation = np.append(representation, self.model.encoder_only(data_var).data.cpu().numpy(),\n",
        "                                               axis=0)\n",
        "                    labels += sample['txt']\n",
        "                    embeddings = np.append(embeddings, sample['right_embed'].numpy(), axis=0)\n",
        "            nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(representation.reshape(-1, 228))\n",
        "            pickle.dump(data, open(data_path, 'wb'))\n",
        "            pickle.dump(labels, open(labels_path, 'wb'))\n",
        "            pickle.dump(nbrs, open(nbrs_path, 'wb'))\n",
        "            pickle.dump(embeddings, open(embeddings_path, 'wb'))\n",
        "        print('finish loading data for NN test')\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.nbrs = nbrs\n",
        "        self.embeddings = embeddings\n",
        "\n",
        "    def get_text(self, samples, limit=-1):\n",
        "        text_results, _, _ = self.get_text_and_images_and_embedding(samples, limit)\n",
        "        return text_results\n",
        "\n",
        "    def get_text_and_images(self, samples, limit):\n",
        "        text_results, image_results, _ = self.get_text_and_images_and_embedding(samples, limit)\n",
        "        return text_results, image_results\n",
        "\n",
        "    def get_text_and_images_and_embedding(self, samples, limit=-1):\n",
        "        samples_embedding = self.model.encoder_only(samples).data.cpu().numpy().reshape(-1, 228)\n",
        "        if limit != -1:\n",
        "            samples_embedding = samples_embedding[:limit]\n",
        "        distances, indices = self.nbrs.kneighbors(samples_embedding)\n",
        "        text_results = [self.labels[index] for index in indices[:, 0]]\n",
        "        image_results = [self.data[index] for index in indices[:, 0]]\n",
        "        embedding_results = [self.embeddings[index] for index in indices[:, 0]]\n",
        "        return text_results, image_results, embedding_results\n",
        ""
      ],
      "metadata": {
        "id": "7-tv6s9GCMz1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ txt2image_dataset.py ###################\n",
        "\n",
        "class Text2ImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, datasetFile, transform=None, split=0):\n",
        "        self.datasetFile = datasetFile\n",
        "        self.transform = transform\n",
        "        self.dataset = None\n",
        "        self.dataset_keys = None\n",
        "        self.split = 'train' if split == 0 else 'valid' if split == 1 else 'test'\n",
        "        self.h5py2int = lambda x: int(np.array(x))\n",
        "\n",
        "    def __len__(self):\n",
        "        f = h5py.File(self.datasetFile, 'r')\n",
        "        self.dataset_keys = [str(k) for k in f[self.split].keys()]\n",
        "        length = len(f[self.split])\n",
        "        f.close()\n",
        "\n",
        "        return length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.dataset is None:\n",
        "            self.dataset = h5py.File(self.datasetFile, mode='r')\n",
        "            self.dataset_keys = [str(k) for k in self.dataset[self.split].keys()]\n",
        "\n",
        "        example_name = self.dataset_keys[idx]\n",
        "        example = self.dataset[self.split][example_name]\n",
        "\n",
        "        # pdb.set_trace()\n",
        "\n",
        "        right_image = bytes(np.array(example['img']))\n",
        "        right_embed = np.array(example['embeddings'], dtype=float)\n",
        "        wrong_image = bytes(np.array(self.find_wrong_image(example['class'])))\n",
        "        inter_embed = np.array(self.find_inter_embed())\n",
        "\n",
        "        right_image = Image.open(io.BytesIO(right_image)).resize((64, 64))\n",
        "        wrong_image = Image.open(io.BytesIO(wrong_image)).resize((64, 64))\n",
        "\n",
        "        right_image = self.validate_image(right_image)\n",
        "        wrong_image = self.validate_image(wrong_image)\n",
        "\n",
        "        txt = np.array(example['txt']).astype(str)\n",
        "        class_ = np.array(example['class']).astype(str)\n",
        "\n",
        "        sample = {\n",
        "                'right_images': torch.FloatTensor(right_image),\n",
        "                'right_embed': torch.FloatTensor(right_embed),\n",
        "                'wrong_images': torch.FloatTensor(wrong_image),\n",
        "                'inter_embed': torch.FloatTensor(inter_embed),\n",
        "                'txt': str(txt),\n",
        "                'class': str(class_)\n",
        "                 }\n",
        "\n",
        "        sample['right_images'] = sample['right_images'].sub_(127.5).div_(127.5)\n",
        "        sample['wrong_images'] =sample['wrong_images'].sub_(127.5).div_(127.5)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def find_wrong_image(self, category):\n",
        "        idx = np.random.randint(len(self.dataset_keys))\n",
        "        example_name = self.dataset_keys[idx]\n",
        "        example = self.dataset[self.split][example_name]\n",
        "        _category = example['class']\n",
        "\n",
        "        if _category != category:\n",
        "            return example['img']\n",
        "\n",
        "        return self.find_wrong_image(category)\n",
        "\n",
        "    def find_inter_embed(self):\n",
        "        idx = np.random.randint(len(self.dataset_keys))\n",
        "        example_name = self.dataset_keys[idx]\n",
        "        example = self.dataset[self.split][example_name]\n",
        "        return example['embeddings']\n",
        "\n",
        "\n",
        "    def validate_image(self, img):\n",
        "        img = np.array(img, dtype=float)\n",
        "        if len(img.shape) < 3:\n",
        "            rgb = np.empty((64, 64, 3), dtype=np.float32)\n",
        "            rgb[:, :, 0] = img\n",
        "            rgb[:, :, 1] = img\n",
        "            rgb[:, :, 2] = img\n",
        "            img = rgb\n",
        "\n",
        "        return img.transpose(2, 0, 1)\n",
        "\n",
        "################ txt2image_dataset.py ends here ###################\n",
        "\n"
      ],
      "metadata": {
        "id": "SYcJcrhBCkSU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Concat_embed(nn.Module):\n",
        "    def __init__(self, embed_dim, projected_embed_dim):\n",
        "        super(Concat_embed, self).__init__()\n",
        "        self.projection = nn.Sequential(nn.Linear(in_features=embed_dim, out_features=projected_embed_dim),\n",
        "                                        nn.BatchNorm1d(num_features=projected_embed_dim),\n",
        "                                        nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "    def forward(self, inp, embed):\n",
        "        projected_embed = self.projection(embed)\n",
        "        replicated_embed = projected_embed.repeat(4, 4, 1, 1).permute(2, 3, 0, 1)\n",
        "        hidden_concat = torch.cat([inp, replicated_embed], 1)\n",
        "\n",
        "        return hidden_concat\n",
        "\n",
        "class Utils(object):\n",
        "    def __init__(self, cuda):\n",
        "        self.is_cuda = cuda\n",
        "\n",
        "    def cuda(self, variable):\n",
        "        return variable.cuda() if self.is_cuda else variable\n",
        "\n",
        "    @staticmethod\n",
        "    def smooth_label(tensor, offset):\n",
        "        return tensor + offset\n",
        "\n",
        "    @staticmethod\n",
        "    def save_checkpoint(netD, netG, dir_path, epoch):\n",
        "        path = dir_path #os.path.join(dir_path, subdir_path)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        torch.save(netD.state_dict(), '{0}/disc_{1}.pth'.format(path, epoch))\n",
        "        torch.save(netG.state_dict(), '{0}/gen_{1}.pth'.format(path, epoch))\n",
        "\n",
        "    @staticmethod\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            m.weight.data.normal_(0.0, 0.02)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            m.weight.data.normal_(1.0, 0.02)\n",
        "            m.bias.data.fill_(0)\n",
        "\n",
        "################ utils.py ends here ###################"
      ],
      "metadata": {
        "id": "OWWgk92aCnmx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class vae_encoder_generator(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(vae_encoder_generator, self).__init__()\n",
        "        self.vae_encoder = vae_encoder(ngf)\n",
        "        self.vae_generator = vae_generator(ngf)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        x = self.vae_encoder(inp)\n",
        "        x = self.vae_generator(x)\n",
        "        return x\n",
        "\n",
        "    def generator_only(self, latent):\n",
        "        return self.vae_generator(latent)\n",
        "\n",
        "    def encoder_only(self, inp):\n",
        "        return self.vae_encoder(inp.cuda())\n",
        "\n",
        "\n",
        "class vae_generator(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(vae_generator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.noise_dim = 100\n",
        "        self.embed_dim = 1024\n",
        "        self.projected_embed_dim = 128\n",
        "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
        "        self.ngf = ngf\n",
        "\n",
        "        # self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
        "        #     nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "        self.netG = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.latent_dim, self.ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 8),\n",
        "            nn.ReLU(True), # state size. (ngf*8) x 4 x 4\n",
        "\n",
        "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 4),\n",
        "            nn.ReLU(True), # state size. (ngf*4) x 8 x 8\n",
        "\n",
        "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 2),\n",
        "            nn.ReLU(True), # state size. (ngf*2) x 16 x 16\n",
        "\n",
        "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(self.ngf, self.num_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (num_channels) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, latent_vector):\n",
        "        # projected_embed = self.projection(embed_vector).unsqueeze(2).unsqueeze(3)\n",
        "        # latent_vector = torch.cat([projected_embed, z], 1)\n",
        "        latent_vector = latent_vector.view(-1, self.latent_dim, 1, 1)\n",
        "        #print(\"**** latent_vector is cuda = \",latent_vector.cpu().is_cuda)\n",
        "        output = self.netG(latent_vector.cpu())\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class vae_encoder(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(vae_encoder, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.embed_dim = 1024\n",
        "        self.noise_dim = 100\n",
        "        self.projected_embed_dim = 128\n",
        "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
        "        self.ngf = ngf\n",
        "\n",
        "        self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
        "            nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "        self.netE = nn.Sequential(\n",
        "            # state size. (num_channels) x 64 x 64\n",
        "            nn.Conv2d(self.num_channels, self.ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.Conv2d(self.ngf, self.ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.Conv2d(self.ngf * 2, self.ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.Conv2d(self.ngf * 4, self.ngf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.Conv2d(self.ngf * 8, self.latent_dim, 4, 1, 0, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, images):\n",
        "        output = self.netE(images)\n",
        "        #print(output.is_cuda)\n",
        "        return output\n",
        "\n",
        "\n",
        "class vae_discriminator(nn.Module):\n",
        "    def __init__(self, remove_noise):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 128\n",
        "        self.embed_dim = 1024\n",
        "        if remove_noise:\n",
        "            self.projected_embed_dim = 228\n",
        "            self.noise_dim = 0\n",
        "        else:\n",
        "            self.projected_embed_dim = 128\n",
        "            self.noise_dim = 100\n",
        "        self.B_dim = 128\n",
        "        self.C_dim = 16\n",
        "        self.minibatch_discriminator = minibatch_discriminator(self.num_channels, self.B_dim, self.C_dim)\n",
        "        #\n",
        "        self.netD_1 = nn.Sequential(\n",
        "            nn.Linear(self.projected_embed_dim + self.noise_dim, 228),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(228, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.netD_2 = nn.Sequential(\n",
        "            nn.Linear(128 + self.B_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        x = inp.view(-1, self.projected_embed_dim + self.noise_dim)\n",
        "        x = self.netD_1(x)\n",
        "        x = self.minibatch_discriminator(x)\n",
        "        x = self.netD_2(x)\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "################ vae.py ends here ###################\n"
      ],
      "metadata": {
        "id": "SzWwq2_YC0Yu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ gan_cls.py ###################\n",
        "\n",
        "class generator(nn.Module):\n",
        "    def __init__(self, remove_noise, variational):\n",
        "        super(generator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.embed_dim = 1024\n",
        "        self.remove_noise = remove_noise\n",
        "        if remove_noise:\n",
        "            self.noise_dim = 0\n",
        "            self.projected_embed_dim = 228\n",
        "        else:\n",
        "            self.noise_dim = 100\n",
        "            self.projected_embed_dim = 128\n",
        "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
        "        self.ngf = 64\n",
        "        self.variational = variational\n",
        "        self.mu = None\n",
        "        self.sd = None\n",
        "\n",
        "        self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
        "            nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "        if variational:\n",
        "            self.en_mu = nn.Conv2d(self.projected_embed_dim, self.projected_embed_dim, 1, 1, 0)\n",
        "            self.en_sigma = nn.Conv2d(self.projected_embed_dim, self.projected_embed_dim, 1, 1, 0)\n",
        "            self.softplus = nn.Softplus()\n",
        "            self.en_mu.weight.data.normal_(0, 0.002)\n",
        "            self.en_mu.bias.data.normal_(0, 0.002)\n",
        "            self.en_sigma.weight.data.normal_(0, 0.002)\n",
        "            self.en_sigma.bias.data.normal_(0, 0.002)\n",
        "\n",
        "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "        self.netG = nn.Sequential(nn.ConvTranspose2d(self.latent_dim, self.ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 8), nn.ReLU(True), # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf * 4),\n",
        "            nn.ReLU(True), # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf * 2),\n",
        "            nn.ReLU(True), # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf), nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(self.ngf, self.num_channels, 4, 2, 1, bias=False), nn.Tanh()\n",
        "            # state size. (num_channels) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, embed_vector, z, noise):\n",
        "        return self.netG(self.encoder_only(embed_vector, z, noise))\n",
        "\n",
        "    def encoder_only(self, embed_vector, z, noise):\n",
        "        projected_embed = self.projection(embed_vector).unsqueeze(2).unsqueeze(3)\n",
        "        if self.variational:\n",
        "            self.mu = self.en_mu(projected_embed)\n",
        "            self.sd = self.softplus(self.en_sigma(projected_embed))\n",
        "            projected_embed = self.mu + self.sd.mul(noise)\n",
        "        if self.remove_noise:\n",
        "            latent_vector = projected_embed\n",
        "        else:\n",
        "            latent_vector = torch.cat([projected_embed, z], 1)\n",
        "        return latent_vector\n",
        "\n",
        "    def generator_only(self, latent_vector):\n",
        "        return self.netG(latent_vector)\n",
        "\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "    def __init__(self, remove_noise):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.embed_dim = 1024\n",
        "        if remove_noise:\n",
        "            self.projected_embed_dim = 228\n",
        "        else:\n",
        "            self.projected_embed_dim = 128\n",
        "        self.ndf = 64\n",
        "        self.B_dim = 128\n",
        "        self.C_dim = 16\n",
        "\n",
        "        self.netD_1 = nn.Sequential(# input is (nc) x 64 x 64\n",
        "            nn.Conv2d(self.num_channels, self.ndf, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(self.ndf, self.ndf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True), )\n",
        "\n",
        "        self.projector = Concat_embed(self.embed_dim, self.projected_embed_dim)\n",
        "\n",
        "        self.netD_2 = nn.Sequential(# state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(self.ndf * 8 + self.projected_embed_dim, 1, 4, 1, 0, bias=False), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, inp, embed):\n",
        "        x_intermediate = self.netD_1(inp)\n",
        "        x = self.projector(x_intermediate, embed)\n",
        "        x = self.netD_2(x)\n",
        "\n",
        "        return x.view(-1, 1).squeeze(1), x_intermediate\n",
        "\n",
        "################ gan_cls.py ends here ###################\n",
        "\n"
      ],
      "metadata": {
        "id": "EY2ogMgvC3nT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ gan_factory.py ###################\n",
        "\n",
        "class gan_factory(object):\n",
        "    @staticmethod\n",
        "    def generator_factory(type, ngf, remove_noise, variational=False):\n",
        "        if type == 'gan':\n",
        "            return generator(remove_noise, variational)\n",
        "        elif type == 'vae':\n",
        "            return vae_encoder_generator(ngf)\n",
        "\n",
        "    @staticmethod\n",
        "    def discriminator_factory(type, remove_noise):\n",
        "        if type == 'gan':\n",
        "            return discriminator(remove_noise)\n",
        "        elif type == 'vae':\n",
        "            return vae_discriminator(remove_noise)\n",
        "\n",
        "################ gan_factory.py ends here ###################"
      ],
      "metadata": {
        "id": "7j2q0ehIDCUI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, type, dataset, split, lr, diter, vis_screen, save_path, l1_coef, l2_coef, pre_trained_gen,\n",
        "                 pre_trained_disc, batch_size, num_workers, epochs, args, params_search=False):\n",
        "        self.config = args\n",
        "        self.cuda = torch.cuda.is_available()\n",
        "\n",
        "        self.generator = gan_factory.generator_factory(type, args.ngf, args.remove_noise_2, args.variational)\n",
        "        self.discriminator = gan_factory.discriminator_factory(type, args.remove_noise_2)\n",
        "\n",
        "        self.target_generator = gan_factory.generator_factory(args.target_type, args.ngf, args.remove_noise_2)\n",
        "\n",
        "        if self.cuda:\n",
        "            self.generator = self.generator.cuda()\n",
        "            self.discriminator = self.discriminator.cuda()\n",
        "\n",
        "        if pre_trained_disc:\n",
        "            print('loading {} from {}'.format('discriminator', pre_trained_disc))\n",
        "            self.discriminator.load_state_dict(torch.load(pre_trained_disc))\n",
        "        else:\n",
        "            if not params_search:\n",
        "                print('creating fresh params for {}'.format('discriminator'))\n",
        "            self.discriminator.apply(Utils.weights_init)\n",
        "\n",
        "        if pre_trained_gen:\n",
        "            print('loading {} from {}'.format('generator', pre_trained_gen))\n",
        "            self.generator.load_state_dict(torch.load(pre_trained_gen))\n",
        "        else:\n",
        "            if not params_search:\n",
        "                print('creating fresh params for {}'.format('generator'))\n",
        "            self.generator.apply(Utils.weights_init)\n",
        "\n",
        "        if dataset == 'flowers_only':\n",
        "            self.dataset = Text2ImageDataset(self.config.flowers_dataset_path, split=0)\n",
        "            self.target_dataset = Text2ImageDataset(self.config.flowers_dataset_path, split=2)\n",
        "        else:\n",
        "            print('Dataset not supported, please select either birds, flowers or flowers_only.')\n",
        "            exit()\n",
        "\n",
        "        self.noise_dim = 100\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.lr = lr\n",
        "        self.beta1 = 0.5\n",
        "        self.num_epochs = epochs\n",
        "        self.DITER = diter\n",
        "\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "\n",
        "        self.data_loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True,\n",
        "                                      num_workers=self.num_workers)\n",
        "        self.target_data_loader = DataLoader(self.target_dataset, batch_size=self.batch_size, shuffle=True,\n",
        "                                             num_workers=self.num_workers)\n",
        "\n",
        "        self.optimD = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
        "        self.optimG = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
        "\n",
        "        self.save_path = save_path\n",
        "        self.type = type\n",
        "        # self.h_el = args.h_el\n",
        "        self.args = args\n",
        "        if not params_search:\n",
        "            self.checkpoints_path = 'tmp/'\n",
        "            if not os.path.exists(self.checkpoints_path):\n",
        "                os.makedirs(self.checkpoints_path)\n",
        "            print(\"***Calling Nearest Neighbour***\")\n",
        "            self.nn = NearestNeighbor(self.target_data_loader, dataset, self.cuda, args.ngf)\n",
        "        self.params_search = params_search\n",
        "\n",
        "    def train(self, cls=False):\n",
        "        print(\"*** Inside train() func ***\")\n",
        "        if self.type == 'gan':\n",
        "            self._train_gan(cls)\n",
        "\n",
        "    def _train_gan(self, cls):\n",
        "        print(\"*** Inside _train_gan() func ***\")\n",
        "        criterion = nn.BCELoss()\n",
        "        l2_loss = nn.MSELoss()\n",
        "        l1_loss = nn.L1Loss()\n",
        "        iteration = 0\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            for sample in self.data_loader:\n",
        "                iteration += 1\n",
        "                right_images = sample['right_images']\n",
        "                right_embed = sample['right_embed']\n",
        "                wrong_images = sample['wrong_images']\n",
        "\n",
        "                right_images = Variable(right_images.float()).cuda()\n",
        "                right_embed = Variable(right_embed.float()).cuda()\n",
        "                wrong_images = Variable(wrong_images.float()).cuda()\n",
        "\n",
        "                real_labels = torch.ones(right_images.size(0))\n",
        "                fake_labels = torch.zeros(right_images.size(0))\n",
        "\n",
        "                # ======== One sided label smoothing ==========\n",
        "                # Helps preventing the discriminator from overpowering the\n",
        "                # generator adding penalty when the discriminator is too confident\n",
        "                # =============================================\n",
        "                smoothed_real_labels = torch.FloatTensor(Utils.smooth_label(real_labels.numpy(), -0.1))\n",
        "\n",
        "                real_labels = Variable(real_labels).cuda()\n",
        "                smoothed_real_labels = Variable(smoothed_real_labels).cuda()\n",
        "                fake_labels = Variable(fake_labels).cuda()\n",
        "\n",
        "                # Train the discriminator\n",
        "                self.discriminator.zero_grad()\n",
        "                outputs, activation_real = self.discriminator(right_images, right_embed)\n",
        "                real_loss = criterion(outputs, smoothed_real_labels)\n",
        "                real_score = outputs\n",
        "\n",
        "                if cls:\n",
        "                    outputs, _ = self.discriminator(wrong_images, right_embed)\n",
        "                    wrong_loss = criterion(outputs, fake_labels)\n",
        "                    wrong_score = outputs\n",
        "\n",
        "                if self.args.remove_noise:\n",
        "                    noise = Variable(torch.zeros(right_images.size(0), self.noise_dim)).cuda()\n",
        "                else:\n",
        "                    noise = Variable(torch.randn(right_images.size(0), self.noise_dim)).cuda()\n",
        "                noise = noise.view(noise.size(0), 100, 1, 1)\n",
        "                fake_images = self.generator(right_embed, noise, noise)\n",
        "                outputs, _ = self.discriminator(fake_images, right_embed)\n",
        "                fake_loss = criterion(outputs, fake_labels)\n",
        "                fake_score = outputs\n",
        "\n",
        "                d_loss = real_loss + fake_loss\n",
        "\n",
        "                if cls:\n",
        "                    d_loss = d_loss + wrong_loss\n",
        "\n",
        "                d_loss.backward()\n",
        "                self.optimD.step()\n",
        "\n",
        "                # Train the generator\n",
        "                self.generator.zero_grad()\n",
        "                if self.args.remove_noise:\n",
        "                    noise = Variable(torch.zeros(right_images.size(0), self.noise_dim)).cuda()\n",
        "                else:\n",
        "                    noise = Variable(torch.randn(right_images.size(0), self.noise_dim)).cuda()\n",
        "                noise = noise.view(noise.size(0), 100, 1, 1)\n",
        "                fake_images = self.generator(right_embed, noise, noise)\n",
        "                outputs, activation_fake = self.discriminator(fake_images, right_embed)\n",
        "                _, activation_real = self.discriminator(right_images, right_embed)\n",
        "\n",
        "                activation_fake = torch.mean(activation_fake, 0)\n",
        "                activation_real = torch.mean(activation_real, 0)\n",
        "                # ======= Generator Loss function============\n",
        "                # This is a customized loss function, the first term is the regular cross entropy loss\n",
        "                # The second term is feature matching loss, this measure the distance between the real and generated\n",
        "                # images statistics by comparing intermediate layers activations\n",
        "                # The third term is L1 distance between the generated and real images, this is helpful for the conditional case\n",
        "                # because it links the embedding feature vector directly to certain pixel values.\n",
        "                # ===========================================\n",
        "                g_loss = criterion(outputs, real_labels) +\\\n",
        "                         self.l2_coef * l2_loss(activation_fake, activation_real.detach()) +\\\n",
        "                         self.l1_coef * l1_loss(fake_images, right_images)\n",
        "\n",
        "                g_loss.backward()\n",
        "                self.optimG.step()\n",
        "\n",
        "                if iteration % 10 == 0:\n",
        "                    print(\"Epoch: %d, d_loss= %f, g_loss= %f, ccaD(X)= %f, D(G(X))= %f\" % (epoch, d_loss.data.cpu().mean(), g_loss.data.cpu().mean(), real_score.data.cpu().mean(), fake_score.data.cpu().mean()))\n",
        "\n",
        "            if (epoch) % 10 == 0:\n",
        "                Utils.save_checkpoint(self.discriminator, self.generator, self.save_path, epoch)\n",
        "\n",
        "    def test(self, numofimg):\n",
        "        self.generator.eval()\n",
        "        self.target_generator.eval()\n",
        "        number_of_images = numofimg\n",
        "        sample = next(iter(self.data_loader))\n",
        "        all_nn_texts = []\n",
        "        all_nn_images = []\n",
        "        all_fake_sources = []\n",
        "        all_transfers = []\n",
        "        text = sample['txt']\n",
        "        right_images = sample['right_images']\n",
        "        right_embed = sample['right_embed']\n",
        "        for i in range(number_of_images):\n",
        "            right_images_v = Variable(right_images.float(), volatile=True)\n",
        "            right_embed_v = Variable(right_embed.float(), volatile=True)\n",
        "            if self.args.remove_noise:\n",
        "                noise = Variable(torch.zeros(right_images_v.size(0), self.noise_dim), volatile=True)\n",
        "            else:\n",
        "                noise = Variable(torch.randn(right_images_v.size(0), self.noise_dim), volatile=True)\n",
        "            if self.cuda:\n",
        "                right_embed_v = right_embed_v.cuda()\n",
        "                noise = noise.cuda()\n",
        "\n",
        "            noise = noise.view(noise.size(0), self.noise_dim, 1, 1)\n",
        "            #print(\"right_embed_v type = \",type(right_embed_v),\"noise = \",type(noise))\n",
        "            fake_target = self.target_generator.generator_only(self.generator.encoder_only(right_embed_v, noise, noise))\n",
        "            all_transfers.append(fake_target)\n",
        "            fake_source = self.generator(right_embed_v, noise,noise)\n",
        "            all_fake_sources.append(fake_source)\n",
        "\n",
        "            fake_source = fake_source.cuda()\n",
        "            print(\"fake_source shape: \",fake_source.detach().shape)\n",
        "            print(\"text description: \",text[0])\n",
        "            print(\"fake_source[0]: \",fake_source[0])\n",
        "            plt.figure(figsize=(2, 2))\n",
        "            plt.imshow(fake_source[0].cpu().detach().permute(1, 2, 0))\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "            print(f\"Image size: {img.size}\")\n",
        "\n",
        "            nn_text, nn_images = self.nn.get_text_and_images(fake_target, -1)\n",
        "            all_nn_texts.append(nn_text)\n",
        "            all_nn_images.append(nn_images)\n",
        "\n",
        "        for i, sentence in enumerate(text):\n",
        "            nn_sentences = [sents[i] for sents in all_nn_texts]\n",
        "            print(\"\\ncombined text: \",i,\"original sentence: \",sentence,\"nn_sentences: \",nn_sentences)\n",
        "\n",
        "        for i, image in enumerate(right_images):\n",
        "            nn_images = [imgs[i] for imgs in all_nn_images]\n",
        "            fake_source_images = [imgs[i].data.cpu().numpy() for imgs in all_fake_sources]\n",
        "            transfers_images = [imgs[i].data.cpu().numpy() for imgs in all_transfers]\n",
        "            image_tile = np.tile(image, (len(nn_images), 1, 1, 1))\n",
        "            print(image_tile)\n",
        "            plt.imshow(fake_source_images)\n",
        "            plt.show()\n",
        "            plt.imshow(transfers_images)\n",
        "            plt.show()\n",
        "            #self.logger.draw_test(image_tile, fake_source_images, transfers_images, nn_images, 'image {}'.format(i))\n",
        "        print(\"*** end of testing ***\")\n",
        "\n",
        "################ trainer.py ends here ###################\n",
        "\n"
      ],
      "metadata": {
        "id": "c11T_L7rDPjC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ runtime.py ###################\n",
        "class Struct:\n",
        "    def __init__(self, **entries):\n",
        "        self.__dict__.update(entries)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "params = dict()\n",
        "\n",
        "params['type']='gan' #change this if you want to train any other gan\n",
        "params['target_type']='gan'\n",
        "params['lr']=0.0002\n",
        "params['l1_coef']=50\n",
        "params['l2_coef']=100\n",
        "params['diter']=5\n",
        "params['cls']=True\n",
        "params['save_path']='tmp/'\n",
        "params['inference']=False\n",
        "params['target_train']=False\n",
        "params['dataset']='flowers_only'\n",
        "params['split']=0\n",
        "params['batch_size']=128\n",
        "params['num_workers']=1\n",
        "params['ngf']=64\n",
        "params['epochs']=20\n",
        "params['remove_noise']=False\n",
        "params['remove_noise_2']=False\n",
        "params['variational']=False\n",
        "params['vis_screen']=False\n",
        "params['pre_trained_disc']=False\n",
        "params['pre_trained_gen']=False\n",
        "# params['flowers_dataset_path']=\"../input/flowershd5dataset/flowers-hd5/data/flowers/flowers.hdf5\"\n",
        "params['flowers_dataset_path']=hdf5_fpath\n",
        "\n",
        "args = Struct(**params) #Convert nested Python dict to object\n",
        "\n",
        "trainer = Trainer(type=args.type, dataset=args.dataset, split=args.split, lr=args.lr, diter=args.diter,\n",
        "                  vis_screen=args.vis_screen, save_path=args.save_path, l1_coef=args.l1_coef,\n",
        "                  l2_coef=args.l2_coef,pre_trained_disc=args.pre_trained_disc,\n",
        "                  pre_trained_gen=args.pre_trained_gen, batch_size=args.batch_size,\n",
        "                  num_workers=args.num_workers, epochs=args.epochs, args=args)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if not args.inference:\n",
        "    if args.target_train:\n",
        "        trainer.target_train(args.cls)\n",
        "    else:\n",
        "        trainer.train(args.cls)\n",
        "print(\"*** Calling test() ***\")\n",
        "trainer.test()\n",
        "\n",
        "elapsed = str(timedelta(seconds=int(time.time() - start_time)))\n",
        "print('Running {} took {}'.format(\"GAN-CLS\", elapsed))\n",
        "\n",
        "################ runtime.py ends here ###################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKCTQVU6HoqW",
        "outputId": "49639f19-e46f-4ecd-d40f-a24fe2a5eda8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating fresh params for discriminator\n",
            "creating fresh params for generator\n",
            "***Calling Nearest Neighbour***\n",
            "data_path:  source_flowers_only_nn_data.pl\n",
            "data_path: source_flowers_only_nn_labels.pl\n",
            "data_path: source_flowers_only_nn.pl\n",
            "data_path: source_flowers_only_nn_embeddings.pl\n",
            "start creating data for NN test source_flowers_only_nn_data.pl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-71c915dd8720>:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-4-71c915dd8720>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish loading data for NN test\n",
            "*** Inside train() func ***\n",
            "*** Inside _train_gan() func ***\n",
            "Epoch: 0, d_loss= 3.114288, g_loss= 32.561115, ccaD(X)= 0.138272, D(G(X))= 0.233461\n",
            "Epoch: 0, d_loss= 2.896219, g_loss= 30.936943, ccaD(X)= 0.117243, D(G(X))= 0.097638\n",
            "Epoch: 0, d_loss= 2.628963, g_loss= 26.391432, ccaD(X)= 0.155928, D(G(X))= 0.234730\n",
            "Epoch: 0, d_loss= 1.900021, g_loss= 27.237244, ccaD(X)= 0.558011, D(G(X))= 0.349755\n",
            "Epoch: 0, d_loss= 1.810857, g_loss= 24.642483, ccaD(X)= 0.328008, D(G(X))= 0.163123\n",
            "Epoch: 0, d_loss= 1.949191, g_loss= 25.833797, ccaD(X)= 0.447068, D(G(X))= 0.340903\n",
            "Epoch: 0, d_loss= 1.557379, g_loss= 26.337017, ccaD(X)= 0.482368, D(G(X))= 0.189566\n",
            "Epoch: 0, d_loss= 1.934359, g_loss= 24.648979, ccaD(X)= 0.258505, D(G(X))= 0.154115\n",
            "Epoch: 0, d_loss= 2.210422, g_loss= 25.086191, ccaD(X)= 0.155174, D(G(X))= 0.062890\n",
            "Epoch: 0, d_loss= 1.694271, g_loss= 25.373672, ccaD(X)= 0.435611, D(G(X))= 0.228588\n",
            "Epoch: 0, d_loss= 1.983505, g_loss= 25.124418, ccaD(X)= 0.516225, D(G(X))= 0.391995\n",
            "Epoch: 0, d_loss= 1.942851, g_loss= 23.670319, ccaD(X)= 0.206820, D(G(X))= 0.092051\n",
            "Epoch: 0, d_loss= 1.908916, g_loss= 22.252739, ccaD(X)= 0.336547, D(G(X))= 0.258335\n",
            "Epoch: 0, d_loss= 2.175895, g_loss= 23.517994, ccaD(X)= 0.151822, D(G(X))= 0.055710\n",
            "Epoch: 0, d_loss= 1.532499, g_loss= 23.755438, ccaD(X)= 0.330401, D(G(X))= 0.111075\n",
            "Epoch: 0, d_loss= 1.718213, g_loss= 22.367975, ccaD(X)= 0.323156, D(G(X))= 0.169091\n",
            "Epoch: 0, d_loss= 1.851321, g_loss= 23.166662, ccaD(X)= 0.316026, D(G(X))= 0.175062\n",
            "Epoch: 0, d_loss= 2.105718, g_loss= 24.197544, ccaD(X)= 0.542104, D(G(X))= 0.316170\n",
            "Epoch: 0, d_loss= 1.627728, g_loss= 23.676291, ccaD(X)= 0.426337, D(G(X))= 0.149921\n",
            "Epoch: 0, d_loss= 1.789394, g_loss= 22.709227, ccaD(X)= 0.317580, D(G(X))= 0.150399\n",
            "Epoch: 0, d_loss= 1.742687, g_loss= 23.867294, ccaD(X)= 0.421595, D(G(X))= 0.237588\n",
            "Epoch: 0, d_loss= 1.703800, g_loss= 24.071707, ccaD(X)= 0.376317, D(G(X))= 0.143896\n",
            "Epoch: 0, d_loss= 1.868355, g_loss= 26.549162, ccaD(X)= 0.600329, D(G(X))= 0.309316\n",
            "Epoch: 1, d_loss= 1.826873, g_loss= 23.679272, ccaD(X)= 0.317040, D(G(X))= 0.178070\n",
            "Epoch: 1, d_loss= 1.997784, g_loss= 25.399235, ccaD(X)= 0.485130, D(G(X))= 0.357376\n",
            "Epoch: 1, d_loss= 1.767357, g_loss= 23.531000, ccaD(X)= 0.370236, D(G(X))= 0.198462\n",
            "Epoch: 1, d_loss= 1.757612, g_loss= 24.595310, ccaD(X)= 0.450699, D(G(X))= 0.204612\n",
            "Epoch: 1, d_loss= 1.719200, g_loss= 22.777428, ccaD(X)= 0.279541, D(G(X))= 0.117185\n",
            "Epoch: 1, d_loss= 1.672023, g_loss= 24.111340, ccaD(X)= 0.362453, D(G(X))= 0.216873\n",
            "Epoch: 1, d_loss= 1.883113, g_loss= 25.735085, ccaD(X)= 0.474893, D(G(X))= 0.327793\n",
            "Epoch: 1, d_loss= 1.731186, g_loss= 23.560255, ccaD(X)= 0.371043, D(G(X))= 0.227891\n",
            "Epoch: 1, d_loss= 1.767960, g_loss= 23.487267, ccaD(X)= 0.253755, D(G(X))= 0.120183\n",
            "Epoch: 1, d_loss= 1.966191, g_loss= 24.227455, ccaD(X)= 0.203656, D(G(X))= 0.064562\n",
            "Epoch: 1, d_loss= 1.601168, g_loss= 23.330051, ccaD(X)= 0.286155, D(G(X))= 0.098239\n",
            "Epoch: 1, d_loss= 1.549897, g_loss= 23.357143, ccaD(X)= 0.331490, D(G(X))= 0.101469\n",
            "Epoch: 1, d_loss= 1.705405, g_loss= 23.343861, ccaD(X)= 0.401734, D(G(X))= 0.260072\n",
            "Epoch: 1, d_loss= 2.054456, g_loss= 23.840420, ccaD(X)= 0.158662, D(G(X))= 0.087657\n",
            "Epoch: 1, d_loss= 1.435867, g_loss= 24.017933, ccaD(X)= 0.418256, D(G(X))= 0.150107\n",
            "Epoch: 1, d_loss= 1.595644, g_loss= 22.875357, ccaD(X)= 0.440634, D(G(X))= 0.243845\n",
            "Epoch: 1, d_loss= 1.925868, g_loss= 23.416109, ccaD(X)= 0.351732, D(G(X))= 0.340798\n",
            "Epoch: 1, d_loss= 2.035210, g_loss= 24.681345, ccaD(X)= 0.398778, D(G(X))= 0.312437\n",
            "Epoch: 1, d_loss= 1.636217, g_loss= 23.903477, ccaD(X)= 0.466554, D(G(X))= 0.196897\n",
            "Epoch: 1, d_loss= 1.720782, g_loss= 23.106092, ccaD(X)= 0.273932, D(G(X))= 0.118566\n",
            "Epoch: 1, d_loss= 1.633468, g_loss= 23.911316, ccaD(X)= 0.452660, D(G(X))= 0.172155\n",
            "Epoch: 1, d_loss= 1.768926, g_loss= 22.785269, ccaD(X)= 0.323301, D(G(X))= 0.157288\n",
            "Epoch: 1, d_loss= 1.920048, g_loss= 22.637239, ccaD(X)= 0.205701, D(G(X))= 0.150070\n",
            "Epoch: 2, d_loss= 1.786241, g_loss= 23.884729, ccaD(X)= 0.255224, D(G(X))= 0.089586\n",
            "Epoch: 2, d_loss= 1.888079, g_loss= 23.425531, ccaD(X)= 0.210773, D(G(X))= 0.106161\n",
            "Epoch: 2, d_loss= 1.659321, g_loss= 24.639002, ccaD(X)= 0.474553, D(G(X))= 0.246129\n",
            "Epoch: 2, d_loss= 1.739568, g_loss= 23.948692, ccaD(X)= 0.254551, D(G(X))= 0.104490\n",
            "Epoch: 2, d_loss= 1.564590, g_loss= 23.088152, ccaD(X)= 0.321275, D(G(X))= 0.186575\n",
            "Epoch: 2, d_loss= 1.848887, g_loss= 23.091261, ccaD(X)= 0.335698, D(G(X))= 0.249050\n",
            "Epoch: 2, d_loss= 1.859520, g_loss= 24.136169, ccaD(X)= 0.444139, D(G(X))= 0.295009\n",
            "Epoch: 2, d_loss= 1.594190, g_loss= 23.661669, ccaD(X)= 0.385175, D(G(X))= 0.169224\n",
            "Epoch: 2, d_loss= 1.624842, g_loss= 24.144299, ccaD(X)= 0.340729, D(G(X))= 0.169538\n",
            "Epoch: 2, d_loss= 1.656025, g_loss= 23.405064, ccaD(X)= 0.326528, D(G(X))= 0.159198\n",
            "Epoch: 2, d_loss= 1.690685, g_loss= 24.050446, ccaD(X)= 0.465036, D(G(X))= 0.324826\n",
            "Epoch: 2, d_loss= 1.917641, g_loss= 24.023273, ccaD(X)= 0.301068, D(G(X))= 0.233210\n",
            "Epoch: 2, d_loss= 1.746998, g_loss= 23.646381, ccaD(X)= 0.221901, D(G(X))= 0.084293\n",
            "Epoch: 2, d_loss= 1.634958, g_loss= 23.529270, ccaD(X)= 0.323606, D(G(X))= 0.119917\n",
            "Epoch: 2, d_loss= 1.848036, g_loss= 23.678715, ccaD(X)= 0.278421, D(G(X))= 0.181874\n",
            "Epoch: 2, d_loss= 1.761564, g_loss= 23.817196, ccaD(X)= 0.428952, D(G(X))= 0.260003\n",
            "Epoch: 2, d_loss= 1.766031, g_loss= 23.920584, ccaD(X)= 0.257380, D(G(X))= 0.099624\n",
            "Epoch: 2, d_loss= 1.850262, g_loss= 23.779699, ccaD(X)= 0.246551, D(G(X))= 0.200040\n",
            "Epoch: 2, d_loss= 1.809756, g_loss= 22.980122, ccaD(X)= 0.292227, D(G(X))= 0.155048\n",
            "Epoch: 2, d_loss= 1.934605, g_loss= 22.726164, ccaD(X)= 0.224743, D(G(X))= 0.152825\n",
            "Epoch: 2, d_loss= 1.653897, g_loss= 23.607431, ccaD(X)= 0.406656, D(G(X))= 0.325290\n",
            "Epoch: 2, d_loss= 1.718923, g_loss= 23.248156, ccaD(X)= 0.249085, D(G(X))= 0.126504\n",
            "Epoch: 2, d_loss= 1.450300, g_loss= 23.900318, ccaD(X)= 0.423006, D(G(X))= 0.186552\n",
            "Epoch: 3, d_loss= 1.772401, g_loss= 23.663542, ccaD(X)= 0.339507, D(G(X))= 0.247807\n",
            "Epoch: 3, d_loss= 1.753317, g_loss= 23.818663, ccaD(X)= 0.305141, D(G(X))= 0.201531\n",
            "Epoch: 3, d_loss= 1.611725, g_loss= 23.718498, ccaD(X)= 0.358571, D(G(X))= 0.178753\n",
            "Epoch: 3, d_loss= 1.491614, g_loss= 23.628206, ccaD(X)= 0.442812, D(G(X))= 0.186434\n",
            "Epoch: 3, d_loss= 1.435859, g_loss= 24.434002, ccaD(X)= 0.396440, D(G(X))= 0.168807\n",
            "Epoch: 3, d_loss= 1.823004, g_loss= 23.681538, ccaD(X)= 0.481979, D(G(X))= 0.291036\n",
            "Epoch: 3, d_loss= 1.797001, g_loss= 23.645760, ccaD(X)= 0.329274, D(G(X))= 0.203567\n",
            "Epoch: 3, d_loss= 1.750000, g_loss= 24.013386, ccaD(X)= 0.230432, D(G(X))= 0.106630\n",
            "Epoch: 3, d_loss= 1.802331, g_loss= 22.715000, ccaD(X)= 0.298428, D(G(X))= 0.175408\n",
            "Epoch: 3, d_loss= 1.634836, g_loss= 24.636627, ccaD(X)= 0.458258, D(G(X))= 0.210050\n",
            "Epoch: 3, d_loss= 1.725700, g_loss= 23.844229, ccaD(X)= 0.327124, D(G(X))= 0.185453\n",
            "Epoch: 3, d_loss= 1.808872, g_loss= 24.139809, ccaD(X)= 0.275334, D(G(X))= 0.166926\n",
            "Epoch: 3, d_loss= 1.861868, g_loss= 22.898117, ccaD(X)= 0.367035, D(G(X))= 0.269416\n",
            "Epoch: 3, d_loss= 1.843809, g_loss= 23.524157, ccaD(X)= 0.395964, D(G(X))= 0.286779\n",
            "Epoch: 3, d_loss= 1.997825, g_loss= 24.105883, ccaD(X)= 0.276870, D(G(X))= 0.274188\n",
            "Epoch: 3, d_loss= 2.028178, g_loss= 23.184008, ccaD(X)= 0.181439, D(G(X))= 0.178599\n",
            "Epoch: 3, d_loss= 1.803007, g_loss= 22.874327, ccaD(X)= 0.280944, D(G(X))= 0.175818\n",
            "Epoch: 3, d_loss= 1.597645, g_loss= 24.302509, ccaD(X)= 0.422681, D(G(X))= 0.191160\n",
            "Epoch: 3, d_loss= 1.787180, g_loss= 23.148670, ccaD(X)= 0.346107, D(G(X))= 0.257498\n",
            "Epoch: 3, d_loss= 1.662718, g_loss= 24.783854, ccaD(X)= 0.460479, D(G(X))= 0.239232\n",
            "Epoch: 3, d_loss= 1.647382, g_loss= 23.125351, ccaD(X)= 0.353350, D(G(X))= 0.252028\n",
            "Epoch: 3, d_loss= 1.770663, g_loss= 23.333244, ccaD(X)= 0.267298, D(G(X))= 0.141106\n",
            "Epoch: 3, d_loss= 2.355289, g_loss= 22.939768, ccaD(X)= 0.122077, D(G(X))= 0.101205\n",
            "Epoch: 4, d_loss= 1.829045, g_loss= 22.946650, ccaD(X)= 0.403627, D(G(X))= 0.266655\n",
            "Epoch: 4, d_loss= 1.657391, g_loss= 23.510036, ccaD(X)= 0.291768, D(G(X))= 0.168062\n",
            "Epoch: 4, d_loss= 1.583209, g_loss= 23.308979, ccaD(X)= 0.340120, D(G(X))= 0.190334\n",
            "Epoch: 4, d_loss= 1.576104, g_loss= 23.112255, ccaD(X)= 0.381355, D(G(X))= 0.228832\n",
            "Epoch: 4, d_loss= 1.724919, g_loss= 22.998005, ccaD(X)= 0.314245, D(G(X))= 0.194397\n",
            "Epoch: 4, d_loss= 1.860371, g_loss= 23.287548, ccaD(X)= 0.385963, D(G(X))= 0.243763\n",
            "Epoch: 4, d_loss= 1.736430, g_loss= 23.716919, ccaD(X)= 0.351798, D(G(X))= 0.217818\n",
            "Epoch: 4, d_loss= 1.943209, g_loss= 24.381210, ccaD(X)= 0.368435, D(G(X))= 0.322889\n",
            "Epoch: 4, d_loss= 1.719073, g_loss= 22.907122, ccaD(X)= 0.372386, D(G(X))= 0.285368\n",
            "Epoch: 4, d_loss= 1.886687, g_loss= 24.228310, ccaD(X)= 0.493800, D(G(X))= 0.352302\n",
            "Epoch: 4, d_loss= 2.063511, g_loss= 23.536442, ccaD(X)= 0.349172, D(G(X))= 0.256082\n",
            "Epoch: 4, d_loss= 1.914373, g_loss= 22.222345, ccaD(X)= 0.276274, D(G(X))= 0.258019\n",
            "Epoch: 4, d_loss= 1.840176, g_loss= 23.156752, ccaD(X)= 0.255859, D(G(X))= 0.183035\n",
            "Epoch: 4, d_loss= 1.984642, g_loss= 23.480228, ccaD(X)= 0.288487, D(G(X))= 0.218501\n",
            "Epoch: 4, d_loss= 1.811873, g_loss= 24.230330, ccaD(X)= 0.487607, D(G(X))= 0.340317\n",
            "Epoch: 4, d_loss= 1.966961, g_loss= 23.861944, ccaD(X)= 0.429730, D(G(X))= 0.320850\n",
            "Epoch: 4, d_loss= 1.751223, g_loss= 23.454906, ccaD(X)= 0.273335, D(G(X))= 0.116858\n",
            "Epoch: 4, d_loss= 1.859437, g_loss= 23.579184, ccaD(X)= 0.365978, D(G(X))= 0.271369\n",
            "Epoch: 4, d_loss= 1.884738, g_loss= 23.186047, ccaD(X)= 0.299217, D(G(X))= 0.231527\n",
            "Epoch: 4, d_loss= 1.702854, g_loss= 23.241344, ccaD(X)= 0.294027, D(G(X))= 0.170960\n",
            "Epoch: 4, d_loss= 1.803765, g_loss= 23.523504, ccaD(X)= 0.462197, D(G(X))= 0.303160\n",
            "Epoch: 4, d_loss= 1.766231, g_loss= 23.763456, ccaD(X)= 0.335191, D(G(X))= 0.161085\n",
            "Epoch: 4, d_loss= 1.967922, g_loss= 22.372221, ccaD(X)= 0.350954, D(G(X))= 0.222474\n",
            "Epoch: 5, d_loss= 1.656897, g_loss= 23.494587, ccaD(X)= 0.335932, D(G(X))= 0.178021\n",
            "Epoch: 5, d_loss= 1.739619, g_loss= 22.900246, ccaD(X)= 0.247816, D(G(X))= 0.177288\n",
            "Epoch: 5, d_loss= 1.905068, g_loss= 24.852489, ccaD(X)= 0.441192, D(G(X))= 0.351728\n",
            "Epoch: 5, d_loss= 1.705309, g_loss= 23.163460, ccaD(X)= 0.425717, D(G(X))= 0.252754\n",
            "Epoch: 5, d_loss= 1.572794, g_loss= 23.116394, ccaD(X)= 0.409993, D(G(X))= 0.257193\n",
            "Epoch: 5, d_loss= 1.892765, g_loss= 22.306622, ccaD(X)= 0.224638, D(G(X))= 0.171953\n",
            "Epoch: 5, d_loss= 1.716507, g_loss= 24.367535, ccaD(X)= 0.410236, D(G(X))= 0.223034\n",
            "Epoch: 5, d_loss= 1.626668, g_loss= 23.428616, ccaD(X)= 0.403353, D(G(X))= 0.292325\n",
            "Epoch: 5, d_loss= 1.651019, g_loss= 23.404665, ccaD(X)= 0.414789, D(G(X))= 0.254413\n",
            "Epoch: 5, d_loss= 1.598602, g_loss= 23.504484, ccaD(X)= 0.477919, D(G(X))= 0.289485\n",
            "Epoch: 5, d_loss= 2.051949, g_loss= 22.905874, ccaD(X)= 0.153380, D(G(X))= 0.080532\n",
            "Epoch: 5, d_loss= 1.899585, g_loss= 22.919674, ccaD(X)= 0.265011, D(G(X))= 0.140832\n",
            "Epoch: 5, d_loss= 1.775386, g_loss= 23.571135, ccaD(X)= 0.472167, D(G(X))= 0.290662\n",
            "Epoch: 5, d_loss= 1.652367, g_loss= 23.344759, ccaD(X)= 0.427491, D(G(X))= 0.303512\n",
            "Epoch: 5, d_loss= 1.785810, g_loss= 22.461580, ccaD(X)= 0.343191, D(G(X))= 0.301252\n",
            "Epoch: 5, d_loss= 2.121873, g_loss= 23.527863, ccaD(X)= 0.262408, D(G(X))= 0.283539\n",
            "Epoch: 5, d_loss= 2.095533, g_loss= 23.606461, ccaD(X)= 0.246766, D(G(X))= 0.259107\n",
            "Epoch: 5, d_loss= 1.884289, g_loss= 24.245306, ccaD(X)= 0.462724, D(G(X))= 0.332104\n",
            "Epoch: 5, d_loss= 1.680050, g_loss= 23.372166, ccaD(X)= 0.371965, D(G(X))= 0.261802\n",
            "Epoch: 5, d_loss= 1.954660, g_loss= 24.037243, ccaD(X)= 0.285409, D(G(X))= 0.324733\n",
            "Epoch: 5, d_loss= 1.694627, g_loss= 23.422386, ccaD(X)= 0.270313, D(G(X))= 0.123343\n",
            "Epoch: 5, d_loss= 1.666563, g_loss= 23.222727, ccaD(X)= 0.351459, D(G(X))= 0.183124\n",
            "Epoch: 5, d_loss= 1.799050, g_loss= 23.517668, ccaD(X)= 0.209703, D(G(X))= 0.077555\n",
            "Epoch: 6, d_loss= 1.705841, g_loss= 23.758205, ccaD(X)= 0.427562, D(G(X))= 0.201825\n",
            "Epoch: 6, d_loss= 1.694314, g_loss= 22.996784, ccaD(X)= 0.257454, D(G(X))= 0.157617\n",
            "Epoch: 6, d_loss= 1.556674, g_loss= 23.345001, ccaD(X)= 0.341605, D(G(X))= 0.188889\n",
            "Epoch: 6, d_loss= 1.993193, g_loss= 22.832556, ccaD(X)= 0.277183, D(G(X))= 0.274680\n",
            "Epoch: 6, d_loss= 1.878989, g_loss= 23.591328, ccaD(X)= 0.294539, D(G(X))= 0.230578\n",
            "Epoch: 6, d_loss= 1.733080, g_loss= 23.277126, ccaD(X)= 0.244911, D(G(X))= 0.131000\n",
            "Epoch: 6, d_loss= 1.868367, g_loss= 23.055414, ccaD(X)= 0.234424, D(G(X))= 0.202026\n",
            "Epoch: 6, d_loss= 1.653357, g_loss= 23.917055, ccaD(X)= 0.313627, D(G(X))= 0.213238\n",
            "Epoch: 6, d_loss= 1.873617, g_loss= 23.586531, ccaD(X)= 0.197514, D(G(X))= 0.117968\n",
            "Epoch: 6, d_loss= 1.623817, g_loss= 23.881699, ccaD(X)= 0.357618, D(G(X))= 0.234093\n",
            "Epoch: 6, d_loss= 1.790020, g_loss= 23.881477, ccaD(X)= 0.470369, D(G(X))= 0.279630\n",
            "Epoch: 6, d_loss= 2.081652, g_loss= 22.450581, ccaD(X)= 0.155185, D(G(X))= 0.102274\n",
            "Epoch: 6, d_loss= 1.732746, g_loss= 23.876211, ccaD(X)= 0.362252, D(G(X))= 0.220364\n",
            "Epoch: 6, d_loss= 1.928060, g_loss= 23.151148, ccaD(X)= 0.304076, D(G(X))= 0.168683\n",
            "Epoch: 6, d_loss= 1.831182, g_loss= 23.644066, ccaD(X)= 0.283511, D(G(X))= 0.230115\n",
            "Epoch: 6, d_loss= 1.748518, g_loss= 23.900143, ccaD(X)= 0.391542, D(G(X))= 0.228400\n",
            "Epoch: 6, d_loss= 1.821042, g_loss= 23.197577, ccaD(X)= 0.419099, D(G(X))= 0.330629\n",
            "Epoch: 6, d_loss= 2.038868, g_loss= 23.040850, ccaD(X)= 0.283724, D(G(X))= 0.227849\n",
            "Epoch: 6, d_loss= 2.044294, g_loss= 23.139429, ccaD(X)= 0.216399, D(G(X))= 0.254473\n",
            "Epoch: 6, d_loss= 1.940855, g_loss= 22.406555, ccaD(X)= 0.233438, D(G(X))= 0.209563\n",
            "Epoch: 6, d_loss= 1.724092, g_loss= 22.808702, ccaD(X)= 0.333899, D(G(X))= 0.208557\n",
            "Epoch: 6, d_loss= 1.974039, g_loss= 24.650108, ccaD(X)= 0.369926, D(G(X))= 0.295312\n"
          ]
        }
      ]
    }
  ]
}