{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKE0Z9PMyILcb8emoweD4o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayyanar7/2023/blob/main/Text2Imagegen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dRFaarbGM465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ee824c-8fda-42f9-cd11-7a2f0210a905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/flowershd5dataset\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# import kagglehub\n",
        "# ds_path = kagglehub.dataset_download('kmahesh541/flowershd5dataset')\n",
        "# words_path = kagglehub.dataset_download('msripooja/flowershd5words')\n",
        "# mast_d_path = kagglehub.dataset_download('kaushalmak07/mast-d')\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kmahesh541/flowershd5dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print('Dataset path.',ds_path)\n",
        "# print('words path.',words_path)\n",
        "# print('mast path.',mast_d_path)\n",
        "hdf5_fpath = path+\"/flowers-hd5/data/flowers/flowers.hdf5\"\n",
        "print(hdf5_fpath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g64mkDOKrbdw",
        "outputId": "6de9a686-ec6b-4c33-f2ec-f446a608dfd0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/flowershd5dataset/flowers-hd5/data/flowers/flowers.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import io\n",
        "import h5py\n",
        "import argparse\n",
        "import torch\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from datetime import timedelta\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "print(\"All libraries imported!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44UTxyM_skvJ",
        "outputId": "ed335c76-f2da-4fc4-dd8a-e1980ca53694"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = h5py.File(hdf5_fpath)\n",
        "\n",
        "#1. to know the categories in hdf5 file\n",
        "print(list(f))\n",
        "print(\"\\nNo. of items in test = \",len(list(f['test'])))\n",
        "print(\"\\nNo. of items in train = \",len(list(f['train'])))\n",
        "print(\"\\nNo. of items in valid = \",len(list(f['valid'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPcZ-3jLtGNd",
        "outputId": "5d55fffa-0af5-4252-ce41-848a849f127d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test', 'train', 'valid']\n",
            "\n",
            "No. of items in test =  5775\n",
            "\n",
            "No. of items in train =  29390\n",
            "\n",
            "No. of items in valid =  5780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NearestNeighbor:\n",
        "    def __init__(self, dataset, source, cuda, ngf):\n",
        "        self.dataset = dataset\n",
        "        data = None\n",
        "        representation = None\n",
        "        labels = []\n",
        "        embeddings = []\n",
        "        path = ''\n",
        "        data_path = path + 'source_{}_nn_data.pl'.format(source)\n",
        "        labels_path = path + 'source_{}_nn_labels.pl'.format(source)\n",
        "        nbrs_path = path + 'source_{}_nn.pl'.format(source)\n",
        "        embeddings_path = path + 'source_{}_nn_embeddings.pl'.format(source)\n",
        "        print(\"data_path: \",data_path)\n",
        "        print(\"data_path: \"+labels_path)\n",
        "        print(\"data_path: \"+nbrs_path)\n",
        "        print(\"data_path: \"+embeddings_path)\n",
        "        self.model = gan_factory.generator_factory('vae', ngf, False)\n",
        "        if cuda:\n",
        "            self.model = self.model.cuda()\n",
        "        #self.model.load_state_dict(torch.load('./checkpoints/flowers_autoencoder/gen.pth'))\n",
        "\n",
        "        if os.path.exists(data_path):\n",
        "            print('start loading data for NN test {}'.format(data_path))\n",
        "            data = pickle.load(open(data_path, 'rb'))\n",
        "            labels = pickle.load(open(labels_path, 'rb'))\n",
        "            nbrs = pickle.load(open(nbrs_path, 'rb'))\n",
        "            embeddings = pickle.load(open(embeddings_path, 'rb'))\n",
        "        else:\n",
        "            print('start creating data for NN test {}'.format(data_path))\n",
        "            for i, sample in enumerate(dataset):\n",
        "                #print(\"**** iter i = \",i)\n",
        "                if data is None:\n",
        "                    data = sample['right_images'].numpy()\n",
        "                    data_var = Variable(sample['right_images'].float(), volatile=True)\n",
        "                    if cuda:\n",
        "                        data_var = data_var.cuda()\n",
        "                    representation = self.model.encoder_only(data_var).data.cpu().numpy()\n",
        "                    labels = sample['txt']\n",
        "                    embeddings = sample['right_embed']\n",
        "                else:\n",
        "                    data = np.append(data, sample['right_images'].numpy(), axis=0)\n",
        "                    data_var = Variable(sample['right_images'].float(), volatile=True)\n",
        "                    if cuda:\n",
        "                        data_var = data_var.cuda()\n",
        "                    representation = np.append(representation, self.model.encoder_only(data_var).data.cpu().numpy(),\n",
        "                                               axis=0)\n",
        "                    labels += sample['txt']\n",
        "                    embeddings = np.append(embeddings, sample['right_embed'].numpy(), axis=0)\n",
        "            nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(representation.reshape(-1, 228))\n",
        "            pickle.dump(data, open(data_path, 'wb'))\n",
        "            pickle.dump(labels, open(labels_path, 'wb'))\n",
        "            pickle.dump(nbrs, open(nbrs_path, 'wb'))\n",
        "            pickle.dump(embeddings, open(embeddings_path, 'wb'))\n",
        "        print('finish loading data for NN test')\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.nbrs = nbrs\n",
        "        self.embeddings = embeddings\n",
        "\n",
        "    def get_text(self, samples, limit=-1):\n",
        "        text_results, _, _ = self.get_text_and_images_and_embedding(samples, limit)\n",
        "        return text_results\n",
        "\n",
        "    def get_text_and_images(self, samples, limit):\n",
        "        text_results, image_results, _ = self.get_text_and_images_and_embedding(samples, limit)\n",
        "        return text_results, image_results\n",
        "\n",
        "    def get_text_and_images_and_embedding(self, samples, limit=-1):\n",
        "        samples_embedding = self.model.encoder_only(samples).data.cpu().numpy().reshape(-1, 228)\n",
        "        if limit != -1:\n",
        "            samples_embedding = samples_embedding[:limit]\n",
        "        distances, indices = self.nbrs.kneighbors(samples_embedding)\n",
        "        text_results = [self.labels[index] for index in indices[:, 0]]\n",
        "        image_results = [self.data[index] for index in indices[:, 0]]\n",
        "        embedding_results = [self.embeddings[index] for index in indices[:, 0]]\n",
        "        return text_results, image_results, embedding_results"
      ],
      "metadata": {
        "id": "JZBQG45wtZMM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ txt2image_dataset.py ###################\n",
        "\n",
        "class Text2ImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, datasetFile, transform=None, split=0):\n",
        "        self.datasetFile = datasetFile\n",
        "        self.transform = transform\n",
        "        self.dataset = None\n",
        "        self.dataset_keys = None\n",
        "        self.split = 'train' if split == 0 else 'valid' if split == 1 else 'test'\n",
        "        self.h5py2int = lambda x: int(np.array(x))\n",
        "\n",
        "    def __len__(self):\n",
        "        f = h5py.File(self.datasetFile, 'r')\n",
        "        self.dataset_keys = [str(k) for k in f[self.split].keys()]\n",
        "        length = len(f[self.split])\n",
        "        f.close()\n",
        "\n",
        "        return length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.dataset is None:\n",
        "            self.dataset = h5py.File(self.datasetFile, mode='r')\n",
        "            self.dataset_keys = [str(k) for k in self.dataset[self.split].keys()]\n",
        "\n",
        "        example_name = self.dataset_keys[idx]\n",
        "        example = self.dataset[self.split][example_name]\n",
        "\n",
        "        # pdb.set_trace()\n",
        "\n",
        "        right_image = bytes(np.array(example['img']))\n",
        "        right_embed = np.array(example['embeddings'], dtype=float)\n",
        "        wrong_image = bytes(np.array(self.find_wrong_image(example['class'])))\n",
        "        inter_embed = np.array(self.find_inter_embed())\n",
        "\n",
        "        right_image = Image.open(io.BytesIO(right_image)).resize((64, 64))\n",
        "        wrong_image = Image.open(io.BytesIO(wrong_image)).resize((64, 64))\n",
        "\n",
        "        right_image = self.validate_image(right_image)\n",
        "        wrong_image = self.validate_image(wrong_image)\n",
        "\n",
        "        txt = np.array(example['txt']).astype(str)\n",
        "        class_ = np.array(example['class']).astype(str)\n",
        "\n",
        "        sample = {\n",
        "                'right_images': torch.FloatTensor(right_image),\n",
        "                'right_embed': torch.FloatTensor(right_embed),\n",
        "                'wrong_images': torch.FloatTensor(wrong_image),\n",
        "                'inter_embed': torch.FloatTensor(inter_embed),\n",
        "                'txt': str(txt),\n",
        "                'class': str(class_)\n",
        "                 }\n",
        "\n",
        "        sample['right_images'] = sample['right_images'].sub_(127.5).div_(127.5)\n",
        "        sample['wrong_images'] =sample['wrong_images'].sub_(127.5).div_(127.5)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def find_wrong_image(self, category):\n",
        "        idx = np.random.randint(len(self.dataset_keys))\n",
        "        example_name = self.dataset_keys[idx]\n",
        "        example = self.dataset[self.split][example_name]\n",
        "        _category = example['class']\n",
        "\n",
        "        if _category != category:\n",
        "            return example['img']\n",
        "\n",
        "        return self.find_wrong_image(category)\n",
        "\n",
        "    def find_inter_embed(self):\n",
        "        idx = np.random.randint(len(self.dataset_keys))\n",
        "        example_name = self.dataset_keys[idx]\n",
        "        example = self.dataset[self.split][example_name]\n",
        "        return example['embeddings']\n",
        "\n",
        "\n",
        "    def validate_image(self, img):\n",
        "        img = np.array(img, dtype=float)\n",
        "        if len(img.shape) < 3:\n",
        "            rgb = np.empty((64, 64, 3), dtype=np.float32)\n",
        "            rgb[:, :, 0] = img\n",
        "            rgb[:, :, 1] = img\n",
        "            rgb[:, :, 2] = img\n",
        "            img = rgb\n",
        "\n",
        "        return img.transpose(2, 0, 1)\n",
        "\n",
        "################ txt2image_dataset.py ends here ###################\n"
      ],
      "metadata": {
        "id": "kAkAXASftkzS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Concat_embed(nn.Module):\n",
        "    def __init__(self, embed_dim, projected_embed_dim):\n",
        "        super(Concat_embed, self).__init__()\n",
        "        self.projection = nn.Sequential(nn.Linear(in_features=embed_dim, out_features=projected_embed_dim),\n",
        "                                        nn.BatchNorm1d(num_features=projected_embed_dim),\n",
        "                                        nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "    def forward(self, inp, embed):\n",
        "        projected_embed = self.projection(embed)\n",
        "        replicated_embed = projected_embed.repeat(4, 4, 1, 1).permute(2, 3, 0, 1)\n",
        "        hidden_concat = torch.cat([inp, replicated_embed], 1)\n",
        "\n",
        "        return hidden_concat\n",
        "\n",
        "class Utils(object):\n",
        "    def __init__(self, cuda):\n",
        "        self.is_cuda = cuda\n",
        "\n",
        "    def cuda(self, variable):\n",
        "        return variable.cuda() if self.is_cuda else variable\n",
        "\n",
        "    @staticmethod\n",
        "    def smooth_label(tensor, offset):\n",
        "        return tensor + offset\n",
        "\n",
        "    @staticmethod\n",
        "    def save_checkpoint(netD, netG, dir_path, epoch):\n",
        "        path = dir_path #os.path.join(dir_path, subdir_path)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        torch.save(netD.state_dict(), '{0}/disc_{1}.pth'.format(path, epoch))\n",
        "        torch.save(netG.state_dict(), '{0}/gen_{1}.pth'.format(path, epoch))\n",
        "\n",
        "    @staticmethod\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            m.weight.data.normal_(0.0, 0.02)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            m.weight.data.normal_(1.0, 0.02)\n",
        "            m.bias.data.fill_(0)\n",
        "\n",
        "################ utils.py ends here ###################"
      ],
      "metadata": {
        "id": "grFpuuEPtm6B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class vae_encoder_generator(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(vae_encoder_generator, self).__init__()\n",
        "        self.vae_encoder = vae_encoder(ngf)\n",
        "        self.vae_generator = vae_generator(ngf)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        x = self.vae_encoder(inp)\n",
        "        x = self.vae_generator(x)\n",
        "        return x\n",
        "\n",
        "    def generator_only(self, latent):\n",
        "        return self.vae_generator(latent)\n",
        "\n",
        "    def encoder_only(self, inp):\n",
        "        return self.vae_encoder(inp.cuda())\n",
        "\n",
        "\n",
        "class vae_generator(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(vae_generator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.noise_dim = 100\n",
        "        self.embed_dim = 1024\n",
        "        self.projected_embed_dim = 128\n",
        "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
        "        self.ngf = ngf\n",
        "\n",
        "        # self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
        "        #     nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "        self.netG = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.latent_dim, self.ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 8),\n",
        "            nn.ReLU(True), # state size. (ngf*8) x 4 x 4\n",
        "\n",
        "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 4),\n",
        "            nn.ReLU(True), # state size. (ngf*4) x 8 x 8\n",
        "\n",
        "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 2),\n",
        "            nn.ReLU(True), # state size. (ngf*2) x 16 x 16\n",
        "\n",
        "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(self.ngf, self.num_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (num_channels) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, latent_vector):\n",
        "        # projected_embed = self.projection(embed_vector).unsqueeze(2).unsqueeze(3)\n",
        "        # latent_vector = torch.cat([projected_embed, z], 1)\n",
        "        latent_vector = latent_vector.view(-1, self.latent_dim, 1, 1)\n",
        "        #print(\"**** latent_vector is cuda = \",latent_vector.cpu().is_cuda)\n",
        "        output = self.netG(latent_vector.cpu())\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class vae_encoder(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(vae_encoder, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.embed_dim = 1024\n",
        "        self.noise_dim = 100\n",
        "        self.projected_embed_dim = 128\n",
        "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
        "        self.ngf = ngf\n",
        "\n",
        "        self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
        "            nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "        self.netE = nn.Sequential(\n",
        "            # state size. (num_channels) x 64 x 64\n",
        "            nn.Conv2d(self.num_channels, self.ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.Conv2d(self.ngf, self.ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.Conv2d(self.ngf * 2, self.ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.Conv2d(self.ngf * 4, self.ngf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.Conv2d(self.ngf * 8, self.latent_dim, 4, 1, 0, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, images):\n",
        "        output = self.netE(images)\n",
        "        #print(output.is_cuda)\n",
        "        return output\n",
        "\n",
        "\n",
        "class vae_discriminator(nn.Module):\n",
        "    def __init__(self, remove_noise):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 128\n",
        "        self.embed_dim = 1024\n",
        "        if remove_noise:\n",
        "            self.projected_embed_dim = 228\n",
        "            self.noise_dim = 0\n",
        "        else:\n",
        "            self.projected_embed_dim = 128\n",
        "            self.noise_dim = 100\n",
        "        self.B_dim = 128\n",
        "        self.C_dim = 16\n",
        "        self.minibatch_discriminator = minibatch_discriminator(self.num_channels, self.B_dim, self.C_dim)\n",
        "        #\n",
        "        self.netD_1 = nn.Sequential(\n",
        "            nn.Linear(self.projected_embed_dim + self.noise_dim, 228),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(228, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.netD_2 = nn.Sequential(\n",
        "            nn.Linear(128 + self.B_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        x = inp.view(-1, self.projected_embed_dim + self.noise_dim)\n",
        "        x = self.netD_1(x)\n",
        "        x = self.minibatch_discriminator(x)\n",
        "        x = self.netD_2(x)\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "################ vae.py ends here ###################\n"
      ],
      "metadata": {
        "id": "xx3hnGu9tvwG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ gan_cls.py ###################\n",
        "\n",
        "class generator(nn.Module):\n",
        "    def __init__(self, remove_noise, variational):\n",
        "        super(generator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.embed_dim = 1024\n",
        "        self.remove_noise = remove_noise\n",
        "        if remove_noise:\n",
        "            self.noise_dim = 0\n",
        "            self.projected_embed_dim = 228\n",
        "        else:\n",
        "            self.noise_dim = 100\n",
        "            self.projected_embed_dim = 128\n",
        "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
        "        self.ngf = 64\n",
        "        self.variational = variational\n",
        "        self.mu = None\n",
        "        self.sd = None\n",
        "\n",
        "        self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
        "            nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "        if variational:\n",
        "            self.en_mu = nn.Conv2d(self.projected_embed_dim, self.projected_embed_dim, 1, 1, 0)\n",
        "            self.en_sigma = nn.Conv2d(self.projected_embed_dim, self.projected_embed_dim, 1, 1, 0)\n",
        "            self.softplus = nn.Softplus()\n",
        "            self.en_mu.weight.data.normal_(0, 0.002)\n",
        "            self.en_mu.bias.data.normal_(0, 0.002)\n",
        "            self.en_sigma.weight.data.normal_(0, 0.002)\n",
        "            self.en_sigma.bias.data.normal_(0, 0.002)\n",
        "\n",
        "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "        self.netG = nn.Sequential(nn.ConvTranspose2d(self.latent_dim, self.ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 8), nn.ReLU(True), # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf * 4),\n",
        "            nn.ReLU(True), # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf * 2),\n",
        "            nn.ReLU(True), # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf), nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(self.ngf, self.num_channels, 4, 2, 1, bias=False), nn.Tanh()\n",
        "            # state size. (num_channels) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, embed_vector, z, noise):\n",
        "        return self.netG(self.encoder_only(embed_vector, z, noise))\n",
        "\n",
        "    def encoder_only(self, embed_vector, z, noise):\n",
        "        projected_embed = self.projection(embed_vector).unsqueeze(2).unsqueeze(3)\n",
        "        if self.variational:\n",
        "            self.mu = self.en_mu(projected_embed)\n",
        "            self.sd = self.softplus(self.en_sigma(projected_embed))\n",
        "            projected_embed = self.mu + self.sd.mul(noise)\n",
        "        if self.remove_noise:\n",
        "            latent_vector = projected_embed\n",
        "        else:\n",
        "            latent_vector = torch.cat([projected_embed, z], 1)\n",
        "        return latent_vector\n",
        "\n",
        "    def generator_only(self, latent_vector):\n",
        "        return self.netG(latent_vector)\n",
        "\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "    def __init__(self, remove_noise):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.embed_dim = 1024\n",
        "        if remove_noise:\n",
        "            self.projected_embed_dim = 228\n",
        "        else:\n",
        "            self.projected_embed_dim = 128\n",
        "        self.ndf = 64\n",
        "        self.B_dim = 128\n",
        "        self.C_dim = 16\n",
        "\n",
        "        self.netD_1 = nn.Sequential(# input is (nc) x 64 x 64\n",
        "            nn.Conv2d(self.num_channels, self.ndf, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(self.ndf, self.ndf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True), )\n",
        "\n",
        "        self.projector = Concat_embed(self.embed_dim, self.projected_embed_dim)\n",
        "\n",
        "        self.netD_2 = nn.Sequential(# state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(self.ndf * 8 + self.projected_embed_dim, 1, 4, 1, 0, bias=False), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, inp, embed):\n",
        "        x_intermediate = self.netD_1(inp)\n",
        "        x = self.projector(x_intermediate, embed)\n",
        "        x = self.netD_2(x)\n",
        "\n",
        "        return x.view(-1, 1).squeeze(1), x_intermediate\n",
        "\n",
        "################ gan_cls.py ends here ###################\n"
      ],
      "metadata": {
        "id": "TQLQVtRTt7b0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ gan_factory.py ###################\n",
        "\n",
        "class gan_factory(object):\n",
        "    @staticmethod\n",
        "    def generator_factory(type, ngf, remove_noise, variational=False):\n",
        "        if type == 'gan':\n",
        "            return generator(remove_noise, variational)\n",
        "        elif type == 'vae':\n",
        "            return vae_encoder_generator(ngf)\n",
        "\n",
        "    @staticmethod\n",
        "    def discriminator_factory(type, remove_noise):\n",
        "        if type == 'gan':\n",
        "            return discriminator(remove_noise)\n",
        "        elif type == 'vae':\n",
        "            return vae_discriminator(remove_noise)\n",
        "\n",
        "################ gan_factory.py ends here ###################"
      ],
      "metadata": {
        "id": "aZcTHfBXuCrI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, type, dataset, split, lr, diter, vis_screen, save_path, l1_coef, l2_coef, pre_trained_gen,\n",
        "                 pre_trained_disc, batch_size, num_workers, epochs, args, params_search=False):\n",
        "        self.config = args\n",
        "        self.cuda = torch.cuda.is_available()\n",
        "\n",
        "        self.generator = gan_factory.generator_factory(type, args.ngf, args.remove_noise_2, args.variational)\n",
        "        self.discriminator = gan_factory.discriminator_factory(type, args.remove_noise_2)\n",
        "\n",
        "        self.target_generator = gan_factory.generator_factory(args.target_type, args.ngf, args.remove_noise_2)\n",
        "\n",
        "        if self.cuda:\n",
        "            self.generator = self.generator.cuda()\n",
        "            self.discriminator = self.discriminator.cuda()\n",
        "\n",
        "        if pre_trained_disc:\n",
        "            print('loading {} from {}'.format('discriminator', pre_trained_disc))\n",
        "            self.discriminator.load_state_dict(torch.load(pre_trained_disc))\n",
        "        else:\n",
        "            if not params_search:\n",
        "                print('creating fresh params for {}'.format('discriminator'))\n",
        "            self.discriminator.apply(Utils.weights_init)\n",
        "\n",
        "        if pre_trained_gen:\n",
        "            print('loading {} from {}'.format('generator', pre_trained_gen))\n",
        "            self.generator.load_state_dict(torch.load(pre_trained_gen))\n",
        "        else:\n",
        "            if not params_search:\n",
        "                print('creating fresh params for {}'.format('generator'))\n",
        "            self.generator.apply(Utils.weights_init)\n",
        "\n",
        "        if dataset == 'flowers_only':\n",
        "            self.dataset = Text2ImageDataset(self.config.flowers_dataset_path, split=0)\n",
        "            self.target_dataset = Text2ImageDataset(self.config.flowers_dataset_path, split=2)\n",
        "        else:\n",
        "            print('Dataset not supported, please select either birds, flowers or flowers_only.')\n",
        "            exit()\n",
        "\n",
        "        self.noise_dim = 100\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.lr = lr\n",
        "        self.beta1 = 0.5\n",
        "        self.num_epochs = epochs\n",
        "        self.DITER = diter\n",
        "\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "\n",
        "        self.data_loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True,\n",
        "                                      num_workers=self.num_workers)\n",
        "        self.target_data_loader = DataLoader(self.target_dataset, batch_size=self.batch_size, shuffle=True,\n",
        "                                             num_workers=self.num_workers)\n",
        "\n",
        "        self.optimD = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
        "        self.optimG = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
        "\n",
        "        self.save_path = save_path\n",
        "        self.type = type\n",
        "        # self.h_el = args.h_el\n",
        "        self.args = args\n",
        "        if not params_search:\n",
        "            self.checkpoints_path = 'tmp/'\n",
        "            if not os.path.exists(self.checkpoints_path):\n",
        "                os.makedirs(self.checkpoints_path)\n",
        "            print(\"***Calling Nearest Neighbour***\")\n",
        "            self.nn = NearestNeighbor(self.target_data_loader, dataset, self.cuda, args.ngf)\n",
        "        self.params_search = params_search\n",
        "\n",
        "    def train(self, cls=False):\n",
        "        print(\"*** Inside train() func ***\")\n",
        "        if self.type == 'gan':\n",
        "            self._train_gan(cls)\n",
        "\n",
        "    def _train_gan(self, cls):\n",
        "        print(\"*** Inside _train_gan() func ***\")\n",
        "        criterion = nn.BCELoss()\n",
        "        l2_loss = nn.MSELoss()\n",
        "        l1_loss = nn.L1Loss()\n",
        "        iteration = 0\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            for sample in self.data_loader:\n",
        "                iteration += 1\n",
        "                right_images = sample['right_images']\n",
        "                right_embed = sample['right_embed']\n",
        "                wrong_images = sample['wrong_images']\n",
        "\n",
        "                right_images = Variable(right_images.float()).cuda()\n",
        "                right_embed = Variable(right_embed.float()).cuda()\n",
        "                wrong_images = Variable(wrong_images.float()).cuda()\n",
        "\n",
        "                real_labels = torch.ones(right_images.size(0))\n",
        "                fake_labels = torch.zeros(right_images.size(0))\n",
        "\n",
        "                # ======== One sided label smoothing ==========\n",
        "                # Helps preventing the discriminator from overpowering the\n",
        "                # generator adding penalty when the discriminator is too confident\n",
        "                # =============================================\n",
        "                smoothed_real_labels = torch.FloatTensor(Utils.smooth_label(real_labels.numpy(), -0.1))\n",
        "\n",
        "                real_labels = Variable(real_labels).cuda()\n",
        "                smoothed_real_labels = Variable(smoothed_real_labels).cuda()\n",
        "                fake_labels = Variable(fake_labels).cuda()\n",
        "\n",
        "                # Train the discriminator\n",
        "                self.discriminator.zero_grad()\n",
        "                outputs, activation_real = self.discriminator(right_images, right_embed)\n",
        "                real_loss = criterion(outputs, smoothed_real_labels)\n",
        "                real_score = outputs\n",
        "\n",
        "                if cls:\n",
        "                    outputs, _ = self.discriminator(wrong_images, right_embed)\n",
        "                    wrong_loss = criterion(outputs, fake_labels)\n",
        "                    wrong_score = outputs\n",
        "\n",
        "                if self.args.remove_noise:\n",
        "                    noise = Variable(torch.zeros(right_images.size(0), self.noise_dim)).cuda()\n",
        "                else:\n",
        "                    noise = Variable(torch.randn(right_images.size(0), self.noise_dim)).cuda()\n",
        "                noise = noise.view(noise.size(0), 100, 1, 1)\n",
        "                fake_images = self.generator(right_embed, noise, noise)\n",
        "                outputs, _ = self.discriminator(fake_images, right_embed)\n",
        "                fake_loss = criterion(outputs, fake_labels)\n",
        "                fake_score = outputs\n",
        "\n",
        "                d_loss = real_loss + fake_loss\n",
        "\n",
        "                if cls:\n",
        "                    d_loss = d_loss + wrong_loss\n",
        "\n",
        "                d_loss.backward()\n",
        "                self.optimD.step()\n",
        "\n",
        "                # Train the generator\n",
        "                self.generator.zero_grad()\n",
        "                if self.args.remove_noise:\n",
        "                    noise = Variable(torch.zeros(right_images.size(0), self.noise_dim)).cuda()\n",
        "                else:\n",
        "                    noise = Variable(torch.randn(right_images.size(0), self.noise_dim)).cuda()\n",
        "                noise = noise.view(noise.size(0), 100, 1, 1)\n",
        "                fake_images = self.generator(right_embed, noise, noise)\n",
        "                outputs, activation_fake = self.discriminator(fake_images, right_embed)\n",
        "                _, activation_real = self.discriminator(right_images, right_embed)\n",
        "\n",
        "                activation_fake = torch.mean(activation_fake, 0)\n",
        "                activation_real = torch.mean(activation_real, 0)\n",
        "                # ======= Generator Loss function============\n",
        "                # This is a customized loss function, the first term is the regular cross entropy loss\n",
        "                # The second term is feature matching loss, this measure the distance between the real and generated\n",
        "                # images statistics by comparing intermediate layers activations\n",
        "                # The third term is L1 distance between the generated and real images, this is helpful for the conditional case\n",
        "                # because it links the embedding feature vector directly to certain pixel values.\n",
        "                # ===========================================\n",
        "                g_loss = criterion(outputs, real_labels) +\\\n",
        "                         self.l2_coef * l2_loss(activation_fake, activation_real.detach()) +\\\n",
        "                         self.l1_coef * l1_loss(fake_images, right_images)\n",
        "\n",
        "                g_loss.backward()\n",
        "                self.optimG.step()\n",
        "\n",
        "                if iteration % 10 == 0:\n",
        "                    print(\"Epoch: %d, d_loss= %f, g_loss= %f, ccaD(X)= %f, D(G(X))= %f\" % (epoch, d_loss.data.cpu().mean(), g_loss.data.cpu().mean(), real_score.data.cpu().mean(), fake_score.data.cpu().mean()))\n",
        "\n",
        "            if (epoch) % 10 == 0:\n",
        "                Utils.save_checkpoint(self.discriminator, self.generator, self.save_path, epoch)\n",
        "\n",
        "    def test(self):\n",
        "        self.generator.eval()\n",
        "        self.target_generator.eval()\n",
        "        number_of_images = 2\n",
        "        sample = next(iter(self.data_loader))\n",
        "        all_nn_texts = []\n",
        "        all_nn_images = []\n",
        "        all_fake_sources = []\n",
        "        all_transfers = []\n",
        "        text = sample['txt']\n",
        "        right_images = sample['right_images']\n",
        "        right_embed = sample['right_embed']\n",
        "        for i in range(number_of_images):\n",
        "            right_images_v = Variable(right_images.float(), volatile=True)\n",
        "            right_embed_v = Variable(right_embed.float(), volatile=True)\n",
        "            if self.args.remove_noise:\n",
        "                noise = Variable(torch.zeros(right_images_v.size(0), self.noise_dim), volatile=True)\n",
        "            else:\n",
        "                noise = Variable(torch.randn(right_images_v.size(0), self.noise_dim), volatile=True)\n",
        "            if self.cuda:\n",
        "                right_embed_v = right_embed_v.cuda()\n",
        "                noise = noise.cuda()\n",
        "\n",
        "            noise = noise.view(noise.size(0), self.noise_dim, 1, 1)\n",
        "            #print(\"right_embed_v type = \",type(right_embed_v),\"noise = \",type(noise))\n",
        "            fake_target = self.target_generator.generator_only(self.generator.encoder_only(right_embed_v, noise, noise))\n",
        "            all_transfers.append(fake_target)\n",
        "            fake_source = self.generator(right_embed_v, noise,noise)\n",
        "            all_fake_sources.append(fake_source)\n",
        "\n",
        "            fake_source = fake_source.cuda()\n",
        "            print(\"fake_source shape: \",fake_source.detach().shape)\n",
        "            print(\"text description: \",text[0])\n",
        "            plt.imshow(fake_source[0].cpu().detach().permute(1, 2, 0))\n",
        "            plt.show()\n",
        "\n",
        "            nn_text, nn_images = self.nn.get_text_and_images(fake_target, -1)\n",
        "            all_nn_texts.append(nn_text)\n",
        "            all_nn_images.append(nn_images)\n",
        "\n",
        "        for i, sentence in enumerate(text):\n",
        "            nn_sentences = [sents[i] for sents in all_nn_texts]\n",
        "            print(\"\\ncombined text: \",i,\"original sentence: \",sentence,\"nn_sentences: \",nn_sentences)\n",
        "\n",
        "        for i, image in enumerate(right_images):\n",
        "            nn_images = [imgs[i] for imgs in all_nn_images]\n",
        "            fake_source_images = [imgs[i].data.cpu().numpy() for imgs in all_fake_sources]\n",
        "            transfers_images = [imgs[i].data.cpu().numpy() for imgs in all_transfers]\n",
        "            image_tile = np.tile(image, (len(nn_images), 1, 1, 1))\n",
        "            #self.logger.draw_test(image_tile, fake_source_images, transfers_images, nn_images, 'image {}'.format(i))\n",
        "        print(\"*** end of testing ***\")\n",
        "\n",
        "################ trainer.py ends here ###################\n",
        "\n"
      ],
      "metadata": {
        "id": "MYWIbmsJuF-s"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ runtime.py ###################\n",
        "class Struct:\n",
        "    def __init__(self, **entries):\n",
        "        self.__dict__.update(entries)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "params = dict()\n",
        "\n",
        "params['type']='gan' #change this if you want to train any other gan\n",
        "params['target_type']='vae'\n",
        "params['lr']=0.0002\n",
        "params['l1_coef']=50\n",
        "params['l2_coef']=100\n",
        "params['diter']=5\n",
        "params['cls']=False\n",
        "params['save_path']='tmp/'\n",
        "params['inference']=False\n",
        "params['target_train']=False\n",
        "params['dataset']='flowers_only'\n",
        "params['split']=0\n",
        "params['batch_size']=128\n",
        "params['num_workers']=1\n",
        "params['ngf']=64\n",
        "params['epochs']=20\n",
        "params['remove_noise']=False\n",
        "params['remove_noise_2']=False\n",
        "params['variational']=False\n",
        "params['vis_screen']=False\n",
        "params['pre_trained_disc']=False\n",
        "params['pre_trained_gen']=False\n",
        "# params['flowers_dataset_path']=\"../input/flowershd5dataset/flowers-hd5/data/flowers/flowers.hdf5\"\n",
        "params['flowers_dataset_path']=hdf5_fpath\n",
        "\n",
        "args = Struct(**params) #Convert nested Python dict to object\n",
        "\n",
        "trainer = Trainer(type=args.type, dataset=args.dataset, split=args.split, lr=args.lr, diter=args.diter,\n",
        "                  vis_screen=args.vis_screen, save_path=args.save_path, l1_coef=args.l1_coef,\n",
        "                  l2_coef=args.l2_coef,pre_trained_disc=args.pre_trained_disc,\n",
        "                  pre_trained_gen=args.pre_trained_gen, batch_size=args.batch_size,\n",
        "                  num_workers=args.num_workers, epochs=args.epochs, args=args)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if not args.inference:\n",
        "    if args.target_train:\n",
        "        trainer.target_train(args.cls)\n",
        "    else:\n",
        "        trainer.train(args.cls)\n",
        "print(\"*** Calling test() ***\")\n",
        "trainer.test()\n",
        "\n",
        "elapsed = str(timedelta(seconds=int(time.time() - start_time)))\n",
        "print('Running {} took {}'.format(\"GAN-CLS\", elapsed))\n",
        "\n",
        "################ runtime.py ends here ###################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeAAQXBQuSnW",
        "outputId": "a47655a0-8bf6-4c03-8c4d-63cfcdbbaaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating fresh params for discriminator\n",
            "creating fresh params for generator\n",
            "***Calling Nearest Neighbour***\n",
            "data_path:  source_flowers_only_nn_data.pl\n",
            "data_path: source_flowers_only_nn_labels.pl\n",
            "data_path: source_flowers_only_nn.pl\n",
            "data_path: source_flowers_only_nn_embeddings.pl\n",
            "start creating data for NN test source_flowers_only_nn_data.pl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-590872e199ff>:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-8-590872e199ff>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish loading data for NN test\n",
            "*** Inside train() func ***\n",
            "*** Inside _train_gan() func ***\n",
            "Epoch: 0, d_loss= 2.359625, g_loss= 40.215302, ccaD(X)= 0.779924, D(G(X))= 0.733503\n",
            "Epoch: 0, d_loss= 2.141276, g_loss= 37.326611, ccaD(X)= 0.713258, D(G(X))= 0.695277\n",
            "Epoch: 0, d_loss= 1.225104, g_loss= 28.606930, ccaD(X)= 0.451852, D(G(X))= 0.105568\n",
            "Epoch: 0, d_loss= 1.503814, g_loss= 31.895203, ccaD(X)= 0.818662, D(G(X))= 0.476007\n",
            "Epoch: 0, d_loss= 1.347571, g_loss= 27.298159, ccaD(X)= 0.336613, D(G(X))= 0.025685\n",
            "Epoch: 0, d_loss= 0.765134, g_loss= 25.792364, ccaD(X)= 0.635526, D(G(X))= 0.113109\n",
            "Epoch: 0, d_loss= 0.761985, g_loss= 26.844431, ccaD(X)= 0.669454, D(G(X))= 0.155025\n",
            "Epoch: 0, d_loss= 1.011475, g_loss= 26.083965, ccaD(X)= 0.798178, D(G(X))= 0.390475\n",
            "Epoch: 0, d_loss= 0.998766, g_loss= 24.925343, ccaD(X)= 0.495043, D(G(X))= 0.110618\n",
            "Epoch: 0, d_loss= 1.114185, g_loss= 27.975868, ccaD(X)= 0.861273, D(G(X))= 0.487610\n",
            "Epoch: 0, d_loss= 1.200560, g_loss= 23.973112, ccaD(X)= 0.408242, D(G(X))= 0.153540\n",
            "Epoch: 0, d_loss= 1.316343, g_loss= 23.686794, ccaD(X)= 0.357863, D(G(X))= 0.088278\n",
            "Epoch: 0, d_loss= 1.480329, g_loss= 22.992630, ccaD(X)= 0.320726, D(G(X))= 0.068735\n",
            "Epoch: 0, d_loss= 1.113839, g_loss= 26.430252, ccaD(X)= 0.820689, D(G(X))= 0.477898\n",
            "Epoch: 0, d_loss= 1.106649, g_loss= 27.698080, ccaD(X)= 0.824592, D(G(X))= 0.483055\n",
            "Epoch: 0, d_loss= 1.872333, g_loss= 24.820309, ccaD(X)= 0.217520, D(G(X))= 0.096774\n",
            "Epoch: 0, d_loss= 0.873685, g_loss= 24.109646, ccaD(X)= 0.615332, D(G(X))= 0.211622\n",
            "Epoch: 0, d_loss= 0.905833, g_loss= 25.544945, ccaD(X)= 0.683498, D(G(X))= 0.273654\n",
            "Epoch: 0, d_loss= 0.743102, g_loss= 25.529915, ccaD(X)= 0.791091, D(G(X))= 0.257933\n",
            "Epoch: 0, d_loss= 0.786490, g_loss= 24.384655, ccaD(X)= 0.627387, D(G(X))= 0.173589\n",
            "Epoch: 0, d_loss= 1.237905, g_loss= 23.789722, ccaD(X)= 0.410292, D(G(X))= 0.202650\n",
            "Epoch: 0, d_loss= 1.177100, g_loss= 23.798059, ccaD(X)= 0.453692, D(G(X))= 0.213976\n",
            "Epoch: 0, d_loss= 1.120289, g_loss= 24.882977, ccaD(X)= 0.698608, D(G(X))= 0.432497\n",
            "Epoch: 1, d_loss= 1.430585, g_loss= 25.981125, ccaD(X)= 0.765490, D(G(X))= 0.599529\n",
            "Epoch: 1, d_loss= 1.064782, g_loss= 24.509832, ccaD(X)= 0.755908, D(G(X))= 0.412187\n",
            "Epoch: 1, d_loss= 1.018537, g_loss= 23.980963, ccaD(X)= 0.546123, D(G(X))= 0.257824\n",
            "Epoch: 1, d_loss= 1.080697, g_loss= 25.632269, ccaD(X)= 0.698106, D(G(X))= 0.416986\n",
            "Epoch: 1, d_loss= 1.331139, g_loss= 25.826218, ccaD(X)= 0.786924, D(G(X))= 0.559291\n",
            "Epoch: 1, d_loss= 1.494815, g_loss= 23.492771, ccaD(X)= 0.293871, D(G(X))= 0.088955\n",
            "Epoch: 1, d_loss= 1.073940, g_loss= 25.448639, ccaD(X)= 0.648065, D(G(X))= 0.385958\n",
            "Epoch: 1, d_loss= 1.030715, g_loss= 26.463318, ccaD(X)= 0.772805, D(G(X))= 0.412452\n",
            "Epoch: 1, d_loss= 1.204629, g_loss= 24.758099, ccaD(X)= 0.376609, D(G(X))= 0.103388\n",
            "Epoch: 1, d_loss= 1.259927, g_loss= 27.602406, ccaD(X)= 0.840360, D(G(X))= 0.551623\n",
            "Epoch: 1, d_loss= 1.166297, g_loss= 24.055590, ccaD(X)= 0.389672, D(G(X))= 0.126700\n",
            "Epoch: 1, d_loss= 1.303588, g_loss= 24.778742, ccaD(X)= 0.510395, D(G(X))= 0.395375\n",
            "Epoch: 1, d_loss= 0.987817, g_loss= 25.125172, ccaD(X)= 0.759384, D(G(X))= 0.403778\n",
            "Epoch: 1, d_loss= 0.949652, g_loss= 25.828739, ccaD(X)= 0.672851, D(G(X))= 0.327613\n",
            "Epoch: 1, d_loss= 1.006743, g_loss= 26.228359, ccaD(X)= 0.760753, D(G(X))= 0.415634\n",
            "Epoch: 1, d_loss= 0.896162, g_loss= 24.768654, ccaD(X)= 0.544017, D(G(X))= 0.166006\n",
            "Epoch: 1, d_loss= 1.377544, g_loss= 23.619686, ccaD(X)= 0.563884, D(G(X))= 0.476388\n",
            "Epoch: 1, d_loss= 0.826066, g_loss= 24.497501, ccaD(X)= 0.649984, D(G(X))= 0.240961\n",
            "Epoch: 1, d_loss= 1.006766, g_loss= 25.356253, ccaD(X)= 0.704134, D(G(X))= 0.390073\n",
            "Epoch: 1, d_loss= 0.865484, g_loss= 24.049683, ccaD(X)= 0.582098, D(G(X))= 0.201110\n",
            "Epoch: 1, d_loss= 1.097820, g_loss= 24.143841, ccaD(X)= 0.420133, D(G(X))= 0.128695\n",
            "Epoch: 1, d_loss= 0.907189, g_loss= 25.232098, ccaD(X)= 0.827961, D(G(X))= 0.393393\n",
            "Epoch: 1, d_loss= 1.196569, g_loss= 24.633699, ccaD(X)= 0.481107, D(G(X))= 0.307870\n",
            "Epoch: 2, d_loss= 1.080935, g_loss= 24.749380, ccaD(X)= 0.554499, D(G(X))= 0.314395\n",
            "Epoch: 2, d_loss= 1.299413, g_loss= 23.436384, ccaD(X)= 0.371870, D(G(X))= 0.211796\n",
            "Epoch: 2, d_loss= 1.387114, g_loss= 27.318760, ccaD(X)= 0.844296, D(G(X))= 0.595672\n",
            "Epoch: 2, d_loss= 0.823234, g_loss= 25.182541, ccaD(X)= 0.599143, D(G(X))= 0.196430\n",
            "Epoch: 2, d_loss= 0.749203, g_loss= 25.595554, ccaD(X)= 0.658157, D(G(X))= 0.180960\n",
            "Epoch: 2, d_loss= 1.773299, g_loss= 23.978748, ccaD(X)= 0.221823, D(G(X))= 0.116465\n",
            "Epoch: 2, d_loss= 1.114109, g_loss= 26.150082, ccaD(X)= 0.763596, D(G(X))= 0.476980\n",
            "Epoch: 2, d_loss= 0.992245, g_loss= 24.412008, ccaD(X)= 0.495385, D(G(X))= 0.152441\n",
            "Epoch: 2, d_loss= 1.104615, g_loss= 26.054560, ccaD(X)= 0.782214, D(G(X))= 0.464609\n",
            "Epoch: 2, d_loss= 1.078031, g_loss= 25.637005, ccaD(X)= 0.786310, D(G(X))= 0.465116\n",
            "Epoch: 2, d_loss= 1.116570, g_loss= 23.998878, ccaD(X)= 0.570892, D(G(X))= 0.364383\n",
            "Epoch: 2, d_loss= 1.191950, g_loss= 24.301163, ccaD(X)= 0.475817, D(G(X))= 0.283962\n",
            "Epoch: 2, d_loss= 1.003946, g_loss= 25.693087, ccaD(X)= 0.729709, D(G(X))= 0.403515\n",
            "Epoch: 2, d_loss= 0.987897, g_loss= 23.853401, ccaD(X)= 0.515745, D(G(X))= 0.191837\n",
            "Epoch: 2, d_loss= 1.107979, g_loss= 24.638060, ccaD(X)= 0.575087, D(G(X))= 0.360075\n",
            "Epoch: 2, d_loss= 1.065362, g_loss= 24.450171, ccaD(X)= 0.742644, D(G(X))= 0.436656\n",
            "Epoch: 2, d_loss= 1.124652, g_loss= 24.874760, ccaD(X)= 0.756574, D(G(X))= 0.482314\n",
            "Epoch: 2, d_loss= 1.098150, g_loss= 24.510468, ccaD(X)= 0.540743, D(G(X))= 0.324561\n",
            "Epoch: 2, d_loss= 1.160864, g_loss= 25.636246, ccaD(X)= 0.719995, D(G(X))= 0.475820\n",
            "Epoch: 2, d_loss= 1.170107, g_loss= 26.359095, ccaD(X)= 0.861949, D(G(X))= 0.516455\n",
            "Epoch: 2, d_loss= 1.229261, g_loss= 23.345455, ccaD(X)= 0.399020, D(G(X))= 0.222991\n",
            "Epoch: 2, d_loss= 1.227611, g_loss= 26.742434, ccaD(X)= 0.828281, D(G(X))= 0.543310\n",
            "Epoch: 2, d_loss= 1.283481, g_loss= 26.746069, ccaD(X)= 0.821158, D(G(X))= 0.560426\n",
            "Epoch: 3, d_loss= 1.330339, g_loss= 25.287046, ccaD(X)= 0.813031, D(G(X))= 0.580842\n",
            "Epoch: 3, d_loss= 1.035804, g_loss= 23.960995, ccaD(X)= 0.722306, D(G(X))= 0.417827\n",
            "Epoch: 3, d_loss= 1.017657, g_loss= 24.171360, ccaD(X)= 0.457295, D(G(X))= 0.158081\n",
            "Epoch: 3, d_loss= 1.169331, g_loss= 24.702007, ccaD(X)= 0.525279, D(G(X))= 0.353448\n",
            "Epoch: 3, d_loss= 1.018278, g_loss= 24.435415, ccaD(X)= 0.680396, D(G(X))= 0.377433\n",
            "Epoch: 3, d_loss= 1.049234, g_loss= 25.038383, ccaD(X)= 0.516027, D(G(X))= 0.266736\n",
            "Epoch: 3, d_loss= 1.362217, g_loss= 24.327541, ccaD(X)= 0.348457, D(G(X))= 0.208123\n",
            "Epoch: 3, d_loss= 1.028427, g_loss= 24.678587, ccaD(X)= 0.717995, D(G(X))= 0.421574\n",
            "Epoch: 3, d_loss= 0.910153, g_loss= 24.457176, ccaD(X)= 0.715258, D(G(X))= 0.348822\n",
            "Epoch: 3, d_loss= 1.038445, g_loss= 26.164761, ccaD(X)= 0.683881, D(G(X))= 0.395817\n",
            "Epoch: 3, d_loss= 1.212890, g_loss= 23.935869, ccaD(X)= 0.501630, D(G(X))= 0.343704\n",
            "Epoch: 3, d_loss= 1.033126, g_loss= 23.894110, ccaD(X)= 0.687154, D(G(X))= 0.408229\n",
            "Epoch: 3, d_loss= 1.309513, g_loss= 25.478971, ccaD(X)= 0.631259, D(G(X))= 0.500099\n",
            "Epoch: 3, d_loss= 1.013671, g_loss= 23.702652, ccaD(X)= 0.566053, D(G(X))= 0.301650\n",
            "Epoch: 3, d_loss= 1.222413, g_loss= 25.407570, ccaD(X)= 0.790035, D(G(X))= 0.530355\n",
            "Epoch: 3, d_loss= 1.180847, g_loss= 23.851841, ccaD(X)= 0.416442, D(G(X))= 0.216267\n",
            "Epoch: 3, d_loss= 1.453735, g_loss= 23.169670, ccaD(X)= 0.333464, D(G(X))= 0.265757\n",
            "Epoch: 3, d_loss= 1.130161, g_loss= 23.567776, ccaD(X)= 0.585270, D(G(X))= 0.390898\n",
            "Epoch: 3, d_loss= 1.197391, g_loss= 23.840292, ccaD(X)= 0.360493, D(G(X))= 0.124274\n",
            "Epoch: 3, d_loss= 1.093540, g_loss= 23.800922, ccaD(X)= 0.429848, D(G(X))= 0.183249\n",
            "Epoch: 3, d_loss= 1.074850, g_loss= 24.737835, ccaD(X)= 0.728127, D(G(X))= 0.443823\n",
            "Epoch: 3, d_loss= 2.078187, g_loss= 23.155893, ccaD(X)= 0.141688, D(G(X))= 0.051640\n",
            "Epoch: 3, d_loss= 1.559459, g_loss= 26.050867, ccaD(X)= 0.705216, D(G(X))= 0.633810\n",
            "Epoch: 4, d_loss= 1.062861, g_loss= 23.564232, ccaD(X)= 0.519781, D(G(X))= 0.283924\n",
            "Epoch: 4, d_loss= 1.120375, g_loss= 25.423964, ccaD(X)= 0.795248, D(G(X))= 0.491128\n",
            "Epoch: 4, d_loss= 1.085428, g_loss= 23.643423, ccaD(X)= 0.489542, D(G(X))= 0.247228\n",
            "Epoch: 4, d_loss= 1.127451, g_loss= 25.327339, ccaD(X)= 0.638876, D(G(X))= 0.417508\n",
            "Epoch: 4, d_loss= 1.461545, g_loss= 24.172215, ccaD(X)= 0.268329, D(G(X))= 0.106698\n",
            "Epoch: 4, d_loss= 1.153331, g_loss= 25.613522, ccaD(X)= 0.824779, D(G(X))= 0.524742\n",
            "Epoch: 4, d_loss= 1.217449, g_loss= 23.731628, ccaD(X)= 0.391286, D(G(X))= 0.203009\n",
            "Epoch: 4, d_loss= 1.010778, g_loss= 24.029667, ccaD(X)= 0.534784, D(G(X))= 0.265395\n",
            "Epoch: 4, d_loss= 1.326886, g_loss= 22.505129, ccaD(X)= 0.318424, D(G(X))= 0.125079\n",
            "Epoch: 4, d_loss= 1.201222, g_loss= 25.818855, ccaD(X)= 0.816686, D(G(X))= 0.536788\n",
            "Epoch: 4, d_loss= 1.105862, g_loss= 23.546961, ccaD(X)= 0.514510, D(G(X))= 0.312871\n",
            "Epoch: 4, d_loss= 1.140957, g_loss= 23.815849, ccaD(X)= 0.430129, D(G(X))= 0.201846\n",
            "Epoch: 4, d_loss= 1.205912, g_loss= 23.628046, ccaD(X)= 0.526710, D(G(X))= 0.380580\n",
            "Epoch: 4, d_loss= 1.155093, g_loss= 23.830252, ccaD(X)= 0.491378, D(G(X))= 0.302726\n",
            "Epoch: 4, d_loss= 1.259484, g_loss= 24.703642, ccaD(X)= 0.323295, D(G(X))= 0.061117\n",
            "Epoch: 4, d_loss= 1.147622, g_loss= 24.382370, ccaD(X)= 0.587784, D(G(X))= 0.399904\n",
            "Epoch: 4, d_loss= 0.867797, g_loss= 23.500654, ccaD(X)= 0.583413, D(G(X))= 0.214532\n",
            "Epoch: 4, d_loss= 1.068799, g_loss= 25.187433, ccaD(X)= 0.706282, D(G(X))= 0.430320\n",
            "Epoch: 4, d_loss= 1.561785, g_loss= 25.712015, ccaD(X)= 0.859432, D(G(X))= 0.671769\n",
            "Epoch: 4, d_loss= 1.263044, g_loss= 22.983185, ccaD(X)= 0.387219, D(G(X))= 0.242219\n",
            "Epoch: 4, d_loss= 1.402502, g_loss= 23.504490, ccaD(X)= 0.324827, D(G(X))= 0.221728\n",
            "Epoch: 4, d_loss= 1.180164, g_loss= 24.292336, ccaD(X)= 0.579682, D(G(X))= 0.406868\n",
            "Epoch: 4, d_loss= 1.327153, g_loss= 23.567247, ccaD(X)= 0.324299, D(G(X))= 0.123182\n",
            "Epoch: 5, d_loss= 1.387148, g_loss= 23.590662, ccaD(X)= 0.310381, D(G(X))= 0.168169\n",
            "Epoch: 5, d_loss= 0.903892, g_loss= 24.272676, ccaD(X)= 0.671789, D(G(X))= 0.318136\n",
            "Epoch: 5, d_loss= 1.078886, g_loss= 23.994331, ccaD(X)= 0.528750, D(G(X))= 0.309583\n",
            "Epoch: 5, d_loss= 1.220082, g_loss= 23.813547, ccaD(X)= 0.488144, D(G(X))= 0.349546\n",
            "Epoch: 5, d_loss= 1.039881, g_loss= 23.254957, ccaD(X)= 0.451494, D(G(X))= 0.176750\n",
            "Epoch: 5, d_loss= 0.957205, g_loss= 24.862003, ccaD(X)= 0.687665, D(G(X))= 0.361288\n",
            "Epoch: 5, d_loss= 1.098879, g_loss= 23.739941, ccaD(X)= 0.436640, D(G(X))= 0.180120\n",
            "Epoch: 5, d_loss= 0.992187, g_loss= 24.613516, ccaD(X)= 0.634034, D(G(X))= 0.345936\n",
            "Epoch: 5, d_loss= 1.237746, g_loss= 24.426025, ccaD(X)= 0.718195, D(G(X))= 0.511803\n",
            "Epoch: 5, d_loss= 1.117679, g_loss= 23.880367, ccaD(X)= 0.498281, D(G(X))= 0.291664\n",
            "Epoch: 5, d_loss= 1.094399, g_loss= 23.190628, ccaD(X)= 0.491099, D(G(X))= 0.275612\n",
            "Epoch: 5, d_loss= 0.822255, g_loss= 24.690907, ccaD(X)= 0.673631, D(G(X))= 0.263907\n",
            "Epoch: 5, d_loss= 0.957349, g_loss= 25.664391, ccaD(X)= 0.751192, D(G(X))= 0.395455\n",
            "Epoch: 5, d_loss= 0.958159, g_loss= 23.696760, ccaD(X)= 0.530786, D(G(X))= 0.226522\n",
            "Epoch: 5, d_loss= 1.149021, g_loss= 23.505001, ccaD(X)= 0.467050, D(G(X))= 0.263969\n",
            "Epoch: 5, d_loss= 0.989686, g_loss= 24.131447, ccaD(X)= 0.520546, D(G(X))= 0.240464\n",
            "Epoch: 5, d_loss= 1.129396, g_loss= 25.044489, ccaD(X)= 0.834869, D(G(X))= 0.504501\n",
            "Epoch: 5, d_loss= 1.053676, g_loss= 24.960791, ccaD(X)= 0.721418, D(G(X))= 0.437704\n",
            "Epoch: 5, d_loss= 0.962945, g_loss= 25.038267, ccaD(X)= 0.675814, D(G(X))= 0.359331\n",
            "Epoch: 5, d_loss= 1.209556, g_loss= 23.934242, ccaD(X)= 0.747769, D(G(X))= 0.514997\n",
            "Epoch: 5, d_loss= 1.319088, g_loss= 25.645769, ccaD(X)= 0.793925, D(G(X))= 0.569203\n",
            "Epoch: 5, d_loss= 0.961253, g_loss= 24.000301, ccaD(X)= 0.542419, D(G(X))= 0.239052\n",
            "Epoch: 5, d_loss= 0.789857, g_loss= 25.046017, ccaD(X)= 0.620805, D(G(X))= 0.193885\n"
          ]
        }
      ]
    }
  ]
}