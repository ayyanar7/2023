{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKE0Z9PMyILcb8emoweD4o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayyanar7/2023/blob/main/Text2Imagegen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dRFaarbGM465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ee824c-8fda-42f9-cd11-7a2f0210a905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/flowershd5dataset\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# import kagglehub\n",
        "# ds_path = kagglehub.dataset_download('kmahesh541/flowershd5dataset')\n",
        "# words_path = kagglehub.dataset_download('msripooja/flowershd5words')\n",
        "# mast_d_path = kagglehub.dataset_download('kaushalmak07/mast-d')\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kmahesh541/flowershd5dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print('Dataset path.',ds_path)\n",
        "# print('words path.',words_path)\n",
        "# print('mast path.',mast_d_path)\n",
        "hdf5_fpath = path+\"/flowers-hd5/data/flowers/flowers.hdf5\"\n",
        "print(hdf5_fpath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g64mkDOKrbdw",
        "outputId": "6de9a686-ec6b-4c33-f2ec-f446a608dfd0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/flowershd5dataset/flowers-hd5/data/flowers/flowers.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import io\n",
        "import h5py\n",
        "import argparse\n",
        "import torch\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from datetime import timedelta\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "print(\"All libraries imported!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44UTxyM_skvJ",
        "outputId": "ed335c76-f2da-4fc4-dd8a-e1980ca53694"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = h5py.File(hdf5_fpath)\n",
        "\n",
        "#1. to know the categories in hdf5 file\n",
        "print(list(f))\n",
        "print(\"\\nNo. of items in test = \",len(list(f['test'])))\n",
        "print(\"\\nNo. of items in train = \",len(list(f['train'])))\n",
        "print(\"\\nNo. of items in valid = \",len(list(f['valid'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPcZ-3jLtGNd",
        "outputId": "5d55fffa-0af5-4252-ce41-848a849f127d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test', 'train', 'valid']\n",
            "\n",
            "No. of items in test =  5775\n",
            "\n",
            "No. of items in train =  29390\n",
            "\n",
            "No. of items in valid =  5780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NearestNeighbor:\n",
        "    def __init__(self, dataset, source, cuda, ngf):\n",
        "        self.dataset = dataset\n",
        "        data = None\n",
        "        representation = None\n",
        "        labels = []\n",
        "        embeddings = []\n",
        "        path = ''\n",
        "        data_path = path + 'source_{}_nn_data.pl'.format(source)\n",
        "        labels_path = path + 'source_{}_nn_labels.pl'.format(source)\n",
        "        nbrs_path = path + 'source_{}_nn.pl'.format(source)\n",
        "        embeddings_path = path + 'source_{}_nn_embeddings.pl'.format(source)\n",
        "        print(\"data_path: \",data_path)\n",
        "        print(\"data_path: \"+labels_path)\n",
        "        print(\"data_path: \"+nbrs_path)\n",
        "        print(\"data_path: \"+embeddings_path)\n",
        "        self.model = gan_factory.generator_factory('vae', ngf, False)\n",
        "        if cuda:\n",
        "            self.model = self.model.cuda()\n",
        "        #self.model.load_state_dict(torch.load('./checkpoints/flowers_autoencoder/gen.pth'))\n",
        "\n",
        "        if os.path.exists(data_path):\n",
        "            print('start loading data for NN test {}'.format(data_path))\n",
        "            data = pickle.load(open(data_path, 'rb'))\n",
        "            labels = pickle.load(open(labels_path, 'rb'))\n",
        "            nbrs = pickle.load(open(nbrs_path, 'rb'))\n",
        "            embeddings = pickle.load(open(embeddings_path, 'rb'))\n",
        "        else:\n",
        "            print('start creating data for NN test {}'.format(data_path))\n",
        "            for i, sample in enumerate(dataset):\n",
        "                #print(\"**** iter i = \",i)\n",
        "                if data is None:\n",
        "                    data = sample['right_images'].numpy()\n",
        "                    data_var = Variable(sample['right_images'].float(), volatile=True)\n",
        "                    if cuda:\n",
        "                        data_var = data_var.cuda()\n",
        "                    representation = self.model.encoder_only(data_var).data.cpu().numpy()\n",
        "                    labels = sample['txt']\n",
        "                    embeddings = sample['right_embed']\n",
        "                else:\n",
        "                    data = np.append(data, sample['right_images'].numpy(), axis=0)\n",
        "                    data_var = Variable(sample['right_images'].float(), volatile=True)\n",
        "                    if cuda:\n",
        "                        data_var = data_var.cuda()\n",
        "                    representation = np.append(representation, self.model.encoder_only(data_var).data.cpu().numpy(),\n",
        "                                               axis=0)\n",
        "                    labels += sample['txt']\n",
        "                    embeddings = np.append(embeddings, sample['right_embed'].numpy(), axis=0)\n",
        "            nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(representation.reshape(-1, 228))\n",
        "            pickle.dump(data, open(data_path, 'wb'))\n",
        "            pickle.dump(labels, open(labels_path, 'wb'))\n",
        "            pickle.dump(nbrs, open(nbrs_path, 'wb'))\n",
        "            pickle.dump(embeddings, open(embeddings_path, 'wb'))\n",
        "        print('finish loading data for NN test')\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.nbrs = nbrs\n",
        "        self.embeddings = embeddings\n",
        "\n",
        "    def get_text(self, samples, limit=-1):\n",
        "        text_results, _, _ = self.get_text_and_images_and_embedding(samples, limit)\n",
        "        return text_results\n",
        "\n",
        "    def get_text_and_images(self, samples, limit):\n",
        "        text_results, image_results, _ = self.get_text_and_images_and_embedding(samples, limit)\n",
        "        return text_results, image_results\n",
        "\n",
        "    def get_text_and_images_and_embedding(self, samples, limit=-1):\n",
        "        samples_embedding = self.model.encoder_only(samples).data.cpu().numpy().reshape(-1, 228)\n",
        "        if limit != -1:\n",
        "            samples_embedding = samples_embedding[:limit]\n",
        "        distances, indices = self.nbrs.kneighbors(samples_embedding)\n",
        "        text_results = [self.labels[index] for index in indices[:, 0]]\n",
        "        image_results = [self.data[index] for index in indices[:, 0]]\n",
        "        embedding_results = [self.embeddings[index] for index in indices[:, 0]]\n",
        "        return text_results, image_results, embedding_results"
      ],
      "metadata": {
        "id": "JZBQG45wtZMM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ txt2image_dataset.py ###################\n",
        "\n",
        "class Text2ImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, datasetFile, transform=None, split=0):\n",
        "        self.datasetFile = datasetFile\n",
        "        self.transform = transform\n",
        "        self.dataset = None\n",
        "        self.dataset_keys = None\n",
        "        self.split = 'train' if split == 0 else 'valid' if split == 1 else 'test'\n",
        "        self.h5py2int = lambda x: int(np.array(x))\n",
        "\n",
        "    def __len__(self):\n",
        "        f = h5py.File(self.datasetFile, 'r')\n",
        "        self.dataset_keys = [str(k) for k in f[self.split].keys()]\n",
        "        length = len(f[self.split])\n",
        "        f.close()\n",
        "\n",
        "        return length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.dataset is None:\n",
        "            self.dataset = h5py.File(self.datasetFile, mode='r')\n",
        "            self.dataset_keys = [str(k) for k in self.dataset[self.split].keys()]\n",
        "\n",
        "        example_name = self.dataset_keys[idx]\n",
        "        example = self.dataset[self.split][example_name]\n",
        "\n",
        "        # pdb.set_trace()\n",
        "\n",
        "        right_image = bytes(np.array(example['img']))\n",
        "        right_embed = np.array(example['embeddings'], dtype=float)\n",
        "        wrong_image = bytes(np.array(self.find_wrong_image(example['class'])))\n",
        "        inter_embed = np.array(self.find_inter_embed())\n",
        "\n",
        "        right_image = Image.open(io.BytesIO(right_image)).resize((64, 64))\n",
        "        wrong_image = Image.open(io.BytesIO(wrong_image)).resize((64, 64))\n",
        "\n",
        "        right_image = self.validate_image(right_image)\n",
        "        wrong_image = self.validate_image(wrong_image)\n",
        "\n",
        "        txt = np.array(example['txt']).astype(str)\n",
        "        class_ = np.array(example['class']).astype(str)\n",
        "\n",
        "        sample = {\n",
        "                'right_images': torch.FloatTensor(right_image),\n",
        "                'right_embed': torch.FloatTensor(right_embed),\n",
        "                'wrong_images': torch.FloatTensor(wrong_image),\n",
        "                'inter_embed': torch.FloatTensor(inter_embed),\n",
        "                'txt': str(txt),\n",
        "                'class': str(class_)\n",
        "                 }\n",
        "\n",
        "        sample['right_images'] = sample['right_images'].sub_(127.5).div_(127.5)\n",
        "        sample['wrong_images'] =sample['wrong_images'].sub_(127.5).div_(127.5)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def find_wrong_image(self, category):\n",
        "        idx = np.random.randint(len(self.dataset_keys))\n",
        "        example_name = self.dataset_keys[idx]\n",
        "        example = self.dataset[self.split][example_name]\n",
        "        _category = example['class']\n",
        "\n",
        "        if _category != category:\n",
        "            return example['img']\n",
        "\n",
        "        return self.find_wrong_image(category)\n",
        "\n",
        "    def find_inter_embed(self):\n",
        "        idx = np.random.randint(len(self.dataset_keys))\n",
        "        example_name = self.dataset_keys[idx]\n",
        "        example = self.dataset[self.split][example_name]\n",
        "        return example['embeddings']\n",
        "\n",
        "\n",
        "    def validate_image(self, img):\n",
        "        img = np.array(img, dtype=float)\n",
        "        if len(img.shape) < 3:\n",
        "            rgb = np.empty((64, 64, 3), dtype=np.float32)\n",
        "            rgb[:, :, 0] = img\n",
        "            rgb[:, :, 1] = img\n",
        "            rgb[:, :, 2] = img\n",
        "            img = rgb\n",
        "\n",
        "        return img.transpose(2, 0, 1)\n",
        "\n",
        "################ txt2image_dataset.py ends here ###################\n"
      ],
      "metadata": {
        "id": "kAkAXASftkzS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Concat_embed(nn.Module):\n",
        "    def __init__(self, embed_dim, projected_embed_dim):\n",
        "        super(Concat_embed, self).__init__()\n",
        "        self.projection = nn.Sequential(nn.Linear(in_features=embed_dim, out_features=projected_embed_dim),\n",
        "                                        nn.BatchNorm1d(num_features=projected_embed_dim),\n",
        "                                        nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "    def forward(self, inp, embed):\n",
        "        projected_embed = self.projection(embed)\n",
        "        replicated_embed = projected_embed.repeat(4, 4, 1, 1).permute(2, 3, 0, 1)\n",
        "        hidden_concat = torch.cat([inp, replicated_embed], 1)\n",
        "\n",
        "        return hidden_concat\n",
        "\n",
        "class Utils(object):\n",
        "    def __init__(self, cuda):\n",
        "        self.is_cuda = cuda\n",
        "\n",
        "    def cuda(self, variable):\n",
        "        return variable.cuda() if self.is_cuda else variable\n",
        "\n",
        "    @staticmethod\n",
        "    def smooth_label(tensor, offset):\n",
        "        return tensor + offset\n",
        "\n",
        "    @staticmethod\n",
        "    def save_checkpoint(netD, netG, dir_path, epoch):\n",
        "        path = dir_path #os.path.join(dir_path, subdir_path)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        torch.save(netD.state_dict(), '{0}/disc_{1}.pth'.format(path, epoch))\n",
        "        torch.save(netG.state_dict(), '{0}/gen_{1}.pth'.format(path, epoch))\n",
        "\n",
        "    @staticmethod\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            m.weight.data.normal_(0.0, 0.02)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            m.weight.data.normal_(1.0, 0.02)\n",
        "            m.bias.data.fill_(0)\n",
        "\n",
        "################ utils.py ends here ###################"
      ],
      "metadata": {
        "id": "grFpuuEPtm6B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class vae_encoder_generator(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(vae_encoder_generator, self).__init__()\n",
        "        self.vae_encoder = vae_encoder(ngf)\n",
        "        self.vae_generator = vae_generator(ngf)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        x = self.vae_encoder(inp)\n",
        "        x = self.vae_generator(x)\n",
        "        return x\n",
        "\n",
        "    def generator_only(self, latent):\n",
        "        return self.vae_generator(latent)\n",
        "\n",
        "    def encoder_only(self, inp):\n",
        "        return self.vae_encoder(inp.cuda())\n",
        "\n",
        "\n",
        "class vae_generator(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(vae_generator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.noise_dim = 100\n",
        "        self.embed_dim = 1024\n",
        "        self.projected_embed_dim = 128\n",
        "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
        "        self.ngf = ngf\n",
        "\n",
        "        # self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
        "        #     nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "        self.netG = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.latent_dim, self.ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 8),\n",
        "            nn.ReLU(True), # state size. (ngf*8) x 4 x 4\n",
        "\n",
        "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 4),\n",
        "            nn.ReLU(True), # state size. (ngf*4) x 8 x 8\n",
        "\n",
        "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 2),\n",
        "            nn.ReLU(True), # state size. (ngf*2) x 16 x 16\n",
        "\n",
        "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(self.ngf, self.num_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (num_channels) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, latent_vector):\n",
        "        # projected_embed = self.projection(embed_vector).unsqueeze(2).unsqueeze(3)\n",
        "        # latent_vector = torch.cat([projected_embed, z], 1)\n",
        "        latent_vector = latent_vector.view(-1, self.latent_dim, 1, 1)\n",
        "        #print(\"**** latent_vector is cuda = \",latent_vector.cpu().is_cuda)\n",
        "        output = self.netG(latent_vector.cpu())\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class vae_encoder(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(vae_encoder, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.embed_dim = 1024\n",
        "        self.noise_dim = 100\n",
        "        self.projected_embed_dim = 128\n",
        "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
        "        self.ngf = ngf\n",
        "\n",
        "        self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
        "            nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "        self.netE = nn.Sequential(\n",
        "            # state size. (num_channels) x 64 x 64\n",
        "            nn.Conv2d(self.num_channels, self.ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.Conv2d(self.ngf, self.ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.Conv2d(self.ngf * 2, self.ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.Conv2d(self.ngf * 4, self.ngf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.Conv2d(self.ngf * 8, self.latent_dim, 4, 1, 0, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, images):\n",
        "        output = self.netE(images)\n",
        "        #print(output.is_cuda)\n",
        "        return output\n",
        "\n",
        "\n",
        "class vae_discriminator(nn.Module):\n",
        "    def __init__(self, remove_noise):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 128\n",
        "        self.embed_dim = 1024\n",
        "        if remove_noise:\n",
        "            self.projected_embed_dim = 228\n",
        "            self.noise_dim = 0\n",
        "        else:\n",
        "            self.projected_embed_dim = 128\n",
        "            self.noise_dim = 100\n",
        "        self.B_dim = 128\n",
        "        self.C_dim = 16\n",
        "        self.minibatch_discriminator = minibatch_discriminator(self.num_channels, self.B_dim, self.C_dim)\n",
        "        #\n",
        "        self.netD_1 = nn.Sequential(\n",
        "            nn.Linear(self.projected_embed_dim + self.noise_dim, 228),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(228, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.netD_2 = nn.Sequential(\n",
        "            nn.Linear(128 + self.B_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        x = inp.view(-1, self.projected_embed_dim + self.noise_dim)\n",
        "        x = self.netD_1(x)\n",
        "        x = self.minibatch_discriminator(x)\n",
        "        x = self.netD_2(x)\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "################ vae.py ends here ###################\n"
      ],
      "metadata": {
        "id": "xx3hnGu9tvwG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ gan_cls.py ###################\n",
        "\n",
        "class generator(nn.Module):\n",
        "    def __init__(self, remove_noise, variational):\n",
        "        super(generator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.embed_dim = 1024\n",
        "        self.remove_noise = remove_noise\n",
        "        if remove_noise:\n",
        "            self.noise_dim = 0\n",
        "            self.projected_embed_dim = 228\n",
        "        else:\n",
        "            self.noise_dim = 100\n",
        "            self.projected_embed_dim = 128\n",
        "        self.latent_dim = self.noise_dim + self.projected_embed_dim\n",
        "        self.ngf = 64\n",
        "        self.variational = variational\n",
        "        self.mu = None\n",
        "        self.sd = None\n",
        "\n",
        "        self.projection = nn.Sequential(nn.Linear(in_features=self.embed_dim, out_features=self.projected_embed_dim),\n",
        "            nn.BatchNorm1d(num_features=self.projected_embed_dim), nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
        "\n",
        "        if variational:\n",
        "            self.en_mu = nn.Conv2d(self.projected_embed_dim, self.projected_embed_dim, 1, 1, 0)\n",
        "            self.en_sigma = nn.Conv2d(self.projected_embed_dim, self.projected_embed_dim, 1, 1, 0)\n",
        "            self.softplus = nn.Softplus()\n",
        "            self.en_mu.weight.data.normal_(0, 0.002)\n",
        "            self.en_mu.bias.data.normal_(0, 0.002)\n",
        "            self.en_sigma.weight.data.normal_(0, 0.002)\n",
        "            self.en_sigma.bias.data.normal_(0, 0.002)\n",
        "\n",
        "        # based on: https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "        self.netG = nn.Sequential(nn.ConvTranspose2d(self.latent_dim, self.ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(self.ngf * 8), nn.ReLU(True), # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf * 4),\n",
        "            nn.ReLU(True), # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf * 2),\n",
        "            nn.ReLU(True), # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ngf), nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(self.ngf, self.num_channels, 4, 2, 1, bias=False), nn.Tanh()\n",
        "            # state size. (num_channels) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, embed_vector, z, noise):\n",
        "        return self.netG(self.encoder_only(embed_vector, z, noise))\n",
        "\n",
        "    def encoder_only(self, embed_vector, z, noise):\n",
        "        projected_embed = self.projection(embed_vector).unsqueeze(2).unsqueeze(3)\n",
        "        if self.variational:\n",
        "            self.mu = self.en_mu(projected_embed)\n",
        "            self.sd = self.softplus(self.en_sigma(projected_embed))\n",
        "            projected_embed = self.mu + self.sd.mul(noise)\n",
        "        if self.remove_noise:\n",
        "            latent_vector = projected_embed\n",
        "        else:\n",
        "            latent_vector = torch.cat([projected_embed, z], 1)\n",
        "        return latent_vector\n",
        "\n",
        "    def generator_only(self, latent_vector):\n",
        "        return self.netG(latent_vector)\n",
        "\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "    def __init__(self, remove_noise):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.image_size = 64\n",
        "        self.num_channels = 3\n",
        "        self.embed_dim = 1024\n",
        "        if remove_noise:\n",
        "            self.projected_embed_dim = 228\n",
        "        else:\n",
        "            self.projected_embed_dim = 128\n",
        "        self.ndf = 64\n",
        "        self.B_dim = 128\n",
        "        self.C_dim = 16\n",
        "\n",
        "        self.netD_1 = nn.Sequential(# input is (nc) x 64 x 64\n",
        "            nn.Conv2d(self.num_channels, self.ndf, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(self.ndf, self.ndf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1, bias=False), nn.BatchNorm2d(self.ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True), )\n",
        "\n",
        "        self.projector = Concat_embed(self.embed_dim, self.projected_embed_dim)\n",
        "\n",
        "        self.netD_2 = nn.Sequential(# state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(self.ndf * 8 + self.projected_embed_dim, 1, 4, 1, 0, bias=False), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, inp, embed):\n",
        "        x_intermediate = self.netD_1(inp)\n",
        "        x = self.projector(x_intermediate, embed)\n",
        "        x = self.netD_2(x)\n",
        "\n",
        "        return x.view(-1, 1).squeeze(1), x_intermediate\n",
        "\n",
        "################ gan_cls.py ends here ###################\n"
      ],
      "metadata": {
        "id": "TQLQVtRTt7b0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ gan_factory.py ###################\n",
        "\n",
        "class gan_factory(object):\n",
        "    @staticmethod\n",
        "    def generator_factory(type, ngf, remove_noise, variational=False):\n",
        "        if type == 'gan':\n",
        "            return generator(remove_noise, variational)\n",
        "        elif type == 'vae':\n",
        "            return vae_encoder_generator(ngf)\n",
        "\n",
        "    @staticmethod\n",
        "    def discriminator_factory(type, remove_noise):\n",
        "        if type == 'gan':\n",
        "            return discriminator(remove_noise)\n",
        "        elif type == 'vae':\n",
        "            return vae_discriminator(remove_noise)\n",
        "\n",
        "################ gan_factory.py ends here ###################"
      ],
      "metadata": {
        "id": "aZcTHfBXuCrI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, type, dataset, split, lr, diter, vis_screen, save_path, l1_coef, l2_coef, pre_trained_gen,\n",
        "                 pre_trained_disc, batch_size, num_workers, epochs, args, params_search=False):\n",
        "        self.config = args\n",
        "        self.cuda = torch.cuda.is_available()\n",
        "\n",
        "        self.generator = gan_factory.generator_factory(type, args.ngf, args.remove_noise_2, args.variational)\n",
        "        self.discriminator = gan_factory.discriminator_factory(type, args.remove_noise_2)\n",
        "\n",
        "        self.target_generator = gan_factory.generator_factory(args.target_type, args.ngf, args.remove_noise_2)\n",
        "\n",
        "        if self.cuda:\n",
        "            self.generator = self.generator.cuda()\n",
        "            self.discriminator = self.discriminator.cuda()\n",
        "\n",
        "        if pre_trained_disc:\n",
        "            print('loading {} from {}'.format('discriminator', pre_trained_disc))\n",
        "            self.discriminator.load_state_dict(torch.load(pre_trained_disc))\n",
        "        else:\n",
        "            if not params_search:\n",
        "                print('creating fresh params for {}'.format('discriminator'))\n",
        "            self.discriminator.apply(Utils.weights_init)\n",
        "\n",
        "        if pre_trained_gen:\n",
        "            print('loading {} from {}'.format('generator', pre_trained_gen))\n",
        "            self.generator.load_state_dict(torch.load(pre_trained_gen))\n",
        "        else:\n",
        "            if not params_search:\n",
        "                print('creating fresh params for {}'.format('generator'))\n",
        "            self.generator.apply(Utils.weights_init)\n",
        "\n",
        "        if dataset == 'flowers_only':\n",
        "            self.dataset = Text2ImageDataset(self.config.flowers_dataset_path, split=0)\n",
        "            self.target_dataset = Text2ImageDataset(self.config.flowers_dataset_path, split=2)\n",
        "        else:\n",
        "            print('Dataset not supported, please select either birds, flowers or flowers_only.')\n",
        "            exit()\n",
        "\n",
        "        self.noise_dim = 100\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.lr = lr\n",
        "        self.beta1 = 0.5\n",
        "        self.num_epochs = epochs\n",
        "        self.DITER = diter\n",
        "\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "\n",
        "        self.data_loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True,\n",
        "                                      num_workers=self.num_workers)\n",
        "        self.target_data_loader = DataLoader(self.target_dataset, batch_size=self.batch_size, shuffle=True,\n",
        "                                             num_workers=self.num_workers)\n",
        "\n",
        "        self.optimD = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
        "        self.optimG = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
        "\n",
        "        self.save_path = save_path\n",
        "        self.type = type\n",
        "        # self.h_el = args.h_el\n",
        "        self.args = args\n",
        "        if not params_search:\n",
        "            self.checkpoints_path = 'tmp/'\n",
        "            if not os.path.exists(self.checkpoints_path):\n",
        "                os.makedirs(self.checkpoints_path)\n",
        "            print(\"***Calling Nearest Neighbour***\")\n",
        "            self.nn = NearestNeighbor(self.target_data_loader, dataset, self.cuda, args.ngf)\n",
        "        self.params_search = params_search\n",
        "\n",
        "    def train(self, cls=False):\n",
        "        print(\"*** Inside train() func ***\")\n",
        "        if self.type == 'gan':\n",
        "            self._train_gan(cls)\n",
        "\n",
        "    def _train_gan(self, cls):\n",
        "        print(\"*** Inside _train_gan() func ***\")\n",
        "        criterion = nn.BCELoss()\n",
        "        l2_loss = nn.MSELoss()\n",
        "        l1_loss = nn.L1Loss()\n",
        "        iteration = 0\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            for sample in self.data_loader:\n",
        "                iteration += 1\n",
        "                right_images = sample['right_images']\n",
        "                right_embed = sample['right_embed']\n",
        "                wrong_images = sample['wrong_images']\n",
        "\n",
        "                right_images = Variable(right_images.float()).cuda()\n",
        "                right_embed = Variable(right_embed.float()).cuda()\n",
        "                wrong_images = Variable(wrong_images.float()).cuda()\n",
        "\n",
        "                real_labels = torch.ones(right_images.size(0))\n",
        "                fake_labels = torch.zeros(right_images.size(0))\n",
        "\n",
        "                # ======== One sided label smoothing ==========\n",
        "                # Helps preventing the discriminator from overpowering the\n",
        "                # generator adding penalty when the discriminator is too confident\n",
        "                # =============================================\n",
        "                smoothed_real_labels = torch.FloatTensor(Utils.smooth_label(real_labels.numpy(), -0.1))\n",
        "\n",
        "                real_labels = Variable(real_labels).cuda()\n",
        "                smoothed_real_labels = Variable(smoothed_real_labels).cuda()\n",
        "                fake_labels = Variable(fake_labels).cuda()\n",
        "\n",
        "                # Train the discriminator\n",
        "                self.discriminator.zero_grad()\n",
        "                outputs, activation_real = self.discriminator(right_images, right_embed)\n",
        "                real_loss = criterion(outputs, smoothed_real_labels)\n",
        "                real_score = outputs\n",
        "\n",
        "                if cls:\n",
        "                    outputs, _ = self.discriminator(wrong_images, right_embed)\n",
        "                    wrong_loss = criterion(outputs, fake_labels)\n",
        "                    wrong_score = outputs\n",
        "\n",
        "                if self.args.remove_noise:\n",
        "                    noise = Variable(torch.zeros(right_images.size(0), self.noise_dim)).cuda()\n",
        "                else:\n",
        "                    noise = Variable(torch.randn(right_images.size(0), self.noise_dim)).cuda()\n",
        "                noise = noise.view(noise.size(0), 100, 1, 1)\n",
        "                fake_images = self.generator(right_embed, noise, noise)\n",
        "                outputs, _ = self.discriminator(fake_images, right_embed)\n",
        "                fake_loss = criterion(outputs, fake_labels)\n",
        "                fake_score = outputs\n",
        "\n",
        "                d_loss = real_loss + fake_loss\n",
        "\n",
        "                if cls:\n",
        "                    d_loss = d_loss + wrong_loss\n",
        "\n",
        "                d_loss.backward()\n",
        "                self.optimD.step()\n",
        "\n",
        "                # Train the generator\n",
        "                self.generator.zero_grad()\n",
        "                if self.args.remove_noise:\n",
        "                    noise = Variable(torch.zeros(right_images.size(0), self.noise_dim)).cuda()\n",
        "                else:\n",
        "                    noise = Variable(torch.randn(right_images.size(0), self.noise_dim)).cuda()\n",
        "                noise = noise.view(noise.size(0), 100, 1, 1)\n",
        "                fake_images = self.generator(right_embed, noise, noise)\n",
        "                outputs, activation_fake = self.discriminator(fake_images, right_embed)\n",
        "                _, activation_real = self.discriminator(right_images, right_embed)\n",
        "\n",
        "                activation_fake = torch.mean(activation_fake, 0)\n",
        "                activation_real = torch.mean(activation_real, 0)\n",
        "                # ======= Generator Loss function============\n",
        "                # This is a customized loss function, the first term is the regular cross entropy loss\n",
        "                # The second term is feature matching loss, this measure the distance between the real and generated\n",
        "                # images statistics by comparing intermediate layers activations\n",
        "                # The third term is L1 distance between the generated and real images, this is helpful for the conditional case\n",
        "                # because it links the embedding feature vector directly to certain pixel values.\n",
        "                # ===========================================\n",
        "                g_loss = criterion(outputs, real_labels) +\\\n",
        "                         self.l2_coef * l2_loss(activation_fake, activation_real.detach()) +\\\n",
        "                         self.l1_coef * l1_loss(fake_images, right_images)\n",
        "\n",
        "                g_loss.backward()\n",
        "                self.optimG.step()\n",
        "\n",
        "                if iteration % 10 == 0:\n",
        "                    print(\"Epoch: %d, d_loss= %f, g_loss= %f, ccaD(X)= %f, D(G(X))= %f\" % (epoch, d_loss.data.cpu().mean(), g_loss.data.cpu().mean(), real_score.data.cpu().mean(), fake_score.data.cpu().mean()))\n",
        "\n",
        "            if (epoch) % 10 == 0:\n",
        "                Utils.save_checkpoint(self.discriminator, self.generator, self.save_path, epoch)\n",
        "\n",
        "    def test(self):\n",
        "        self.generator.eval()\n",
        "        self.target_generator.eval()\n",
        "        number_of_images = 2\n",
        "        sample = next(iter(self.data_loader))\n",
        "        all_nn_texts = []\n",
        "        all_nn_images = []\n",
        "        all_fake_sources = []\n",
        "        all_transfers = []\n",
        "        text = sample['txt']\n",
        "        right_images = sample['right_images']\n",
        "        right_embed = sample['right_embed']\n",
        "        for i in range(number_of_images):\n",
        "            right_images_v = Variable(right_images.float(), volatile=True)\n",
        "            right_embed_v = Variable(right_embed.float(), volatile=True)\n",
        "            if self.args.remove_noise:\n",
        "                noise = Variable(torch.zeros(right_images_v.size(0), self.noise_dim), volatile=True)\n",
        "            else:\n",
        "                noise = Variable(torch.randn(right_images_v.size(0), self.noise_dim), volatile=True)\n",
        "            if self.cuda:\n",
        "                right_embed_v = right_embed_v.cuda()\n",
        "                noise = noise.cuda()\n",
        "\n",
        "            noise = noise.view(noise.size(0), self.noise_dim, 1, 1)\n",
        "            #print(\"right_embed_v type = \",type(right_embed_v),\"noise = \",type(noise))\n",
        "            fake_target = self.target_generator.generator_only(self.generator.encoder_only(right_embed_v, noise, noise))\n",
        "            all_transfers.append(fake_target)\n",
        "            fake_source = self.generator(right_embed_v, noise,noise)\n",
        "            all_fake_sources.append(fake_source)\n",
        "\n",
        "            fake_source = fake_source.cuda()\n",
        "            print(\"fake_source shape: \",fake_source.detach().shape)\n",
        "            print(\"text description: \",text[0])\n",
        "            plt.imshow(fake_source[0].cpu().detach().permute(1, 2, 0))\n",
        "            plt.show()\n",
        "\n",
        "            nn_text, nn_images = self.nn.get_text_and_images(fake_target, -1)\n",
        "            all_nn_texts.append(nn_text)\n",
        "            all_nn_images.append(nn_images)\n",
        "\n",
        "        for i, sentence in enumerate(text):\n",
        "            nn_sentences = [sents[i] for sents in all_nn_texts]\n",
        "            print(\"\\ncombined text: \",i,\"original sentence: \",sentence,\"nn_sentences: \",nn_sentences)\n",
        "\n",
        "        for i, image in enumerate(right_images):\n",
        "            nn_images = [imgs[i] for imgs in all_nn_images]\n",
        "            fake_source_images = [imgs[i].data.cpu().numpy() for imgs in all_fake_sources]\n",
        "            transfers_images = [imgs[i].data.cpu().numpy() for imgs in all_transfers]\n",
        "            image_tile = np.tile(image, (len(nn_images), 1, 1, 1))\n",
        "            #self.logger.draw_test(image_tile, fake_source_images, transfers_images, nn_images, 'image {}'.format(i))\n",
        "        print(\"*** end of testing ***\")\n",
        "\n",
        "################ trainer.py ends here ###################\n",
        "\n"
      ],
      "metadata": {
        "id": "MYWIbmsJuF-s"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ runtime.py ###################\n",
        "class Struct:\n",
        "    def __init__(self, **entries):\n",
        "        self.__dict__.update(entries)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "params = dict()\n",
        "\n",
        "params['type']='gan' #change this if you want to train any other gan\n",
        "params['target_type']='vae'\n",
        "params['lr']=0.0002\n",
        "params['l1_coef']=50\n",
        "params['l2_coef']=100\n",
        "params['diter']=5\n",
        "params['cls']=False\n",
        "params['save_path']='tmp/'\n",
        "params['inference']=False\n",
        "params['target_train']=False\n",
        "params['dataset']='flowers_only'\n",
        "params['split']=0\n",
        "params['batch_size']=128\n",
        "params['num_workers']=1\n",
        "params['ngf']=64\n",
        "params['epochs']=20\n",
        "params['remove_noise']=False\n",
        "params['remove_noise_2']=False\n",
        "params['variational']=False\n",
        "params['vis_screen']=False\n",
        "params['pre_trained_disc']=False\n",
        "params['pre_trained_gen']=False\n",
        "# params['flowers_dataset_path']=\"../input/flowershd5dataset/flowers-hd5/data/flowers/flowers.hdf5\"\n",
        "params['flowers_dataset_path']=hdf5_fpath\n",
        "\n",
        "args = Struct(**params) #Convert nested Python dict to object\n",
        "\n",
        "trainer = Trainer(type=args.type, dataset=args.dataset, split=args.split, lr=args.lr, diter=args.diter,\n",
        "                  vis_screen=args.vis_screen, save_path=args.save_path, l1_coef=args.l1_coef,\n",
        "                  l2_coef=args.l2_coef,pre_trained_disc=args.pre_trained_disc,\n",
        "                  pre_trained_gen=args.pre_trained_gen, batch_size=args.batch_size,\n",
        "                  num_workers=args.num_workers, epochs=args.epochs, args=args)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if not args.inference:\n",
        "    if args.target_train:\n",
        "        trainer.target_train(args.cls)\n",
        "    else:\n",
        "        trainer.train(args.cls)\n",
        "print(\"*** Calling test() ***\")\n",
        "trainer.test()\n",
        "\n",
        "elapsed = str(timedelta(seconds=int(time.time() - start_time)))\n",
        "print('Running {} took {}'.format(\"GAN-CLS\", elapsed))\n",
        "\n",
        "################ runtime.py ends here ###################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeAAQXBQuSnW",
        "outputId": "a47655a0-8bf6-4c03-8c4d-63cfcdbbaaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating fresh params for discriminator\n",
            "creating fresh params for generator\n",
            "***Calling Nearest Neighbour***\n",
            "data_path:  source_flowers_only_nn_data.pl\n",
            "data_path: source_flowers_only_nn_labels.pl\n",
            "data_path: source_flowers_only_nn.pl\n",
            "data_path: source_flowers_only_nn_embeddings.pl\n",
            "start creating data for NN test source_flowers_only_nn_data.pl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-590872e199ff>:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n",
            "<ipython-input-8-590872e199ff>:42: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data_var = Variable(sample['right_images'].float(), volatile=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish loading data for NN test\n",
            "*** Inside train() func ***\n",
            "*** Inside _train_gan() func ***\n",
            "Epoch: 0, d_loss= 2.359625, g_loss= 40.215302, ccaD(X)= 0.779924, D(G(X))= 0.733503\n",
            "Epoch: 0, d_loss= 2.141276, g_loss= 37.326611, ccaD(X)= 0.713258, D(G(X))= 0.695277\n",
            "Epoch: 0, d_loss= 1.225104, g_loss= 28.606930, ccaD(X)= 0.451852, D(G(X))= 0.105568\n",
            "Epoch: 0, d_loss= 1.503814, g_loss= 31.895203, ccaD(X)= 0.818662, D(G(X))= 0.476007\n",
            "Epoch: 0, d_loss= 1.347571, g_loss= 27.298159, ccaD(X)= 0.336613, D(G(X))= 0.025685\n",
            "Epoch: 0, d_loss= 0.765134, g_loss= 25.792364, ccaD(X)= 0.635526, D(G(X))= 0.113109\n",
            "Epoch: 0, d_loss= 0.761985, g_loss= 26.844431, ccaD(X)= 0.669454, D(G(X))= 0.155025\n",
            "Epoch: 0, d_loss= 1.011475, g_loss= 26.083965, ccaD(X)= 0.798178, D(G(X))= 0.390475\n",
            "Epoch: 0, d_loss= 0.998766, g_loss= 24.925343, ccaD(X)= 0.495043, D(G(X))= 0.110618\n",
            "Epoch: 0, d_loss= 1.114185, g_loss= 27.975868, ccaD(X)= 0.861273, D(G(X))= 0.487610\n",
            "Epoch: 0, d_loss= 1.200560, g_loss= 23.973112, ccaD(X)= 0.408242, D(G(X))= 0.153540\n",
            "Epoch: 0, d_loss= 1.316343, g_loss= 23.686794, ccaD(X)= 0.357863, D(G(X))= 0.088278\n",
            "Epoch: 0, d_loss= 1.480329, g_loss= 22.992630, ccaD(X)= 0.320726, D(G(X))= 0.068735\n",
            "Epoch: 0, d_loss= 1.113839, g_loss= 26.430252, ccaD(X)= 0.820689, D(G(X))= 0.477898\n",
            "Epoch: 0, d_loss= 1.106649, g_loss= 27.698080, ccaD(X)= 0.824592, D(G(X))= 0.483055\n",
            "Epoch: 0, d_loss= 1.872333, g_loss= 24.820309, ccaD(X)= 0.217520, D(G(X))= 0.096774\n",
            "Epoch: 0, d_loss= 0.873685, g_loss= 24.109646, ccaD(X)= 0.615332, D(G(X))= 0.211622\n",
            "Epoch: 0, d_loss= 0.905833, g_loss= 25.544945, ccaD(X)= 0.683498, D(G(X))= 0.273654\n",
            "Epoch: 0, d_loss= 0.743102, g_loss= 25.529915, ccaD(X)= 0.791091, D(G(X))= 0.257933\n",
            "Epoch: 0, d_loss= 0.786490, g_loss= 24.384655, ccaD(X)= 0.627387, D(G(X))= 0.173589\n",
            "Epoch: 0, d_loss= 1.237905, g_loss= 23.789722, ccaD(X)= 0.410292, D(G(X))= 0.202650\n",
            "Epoch: 0, d_loss= 1.177100, g_loss= 23.798059, ccaD(X)= 0.453692, D(G(X))= 0.213976\n",
            "Epoch: 0, d_loss= 1.120289, g_loss= 24.882977, ccaD(X)= 0.698608, D(G(X))= 0.432497\n",
            "Epoch: 1, d_loss= 1.430585, g_loss= 25.981125, ccaD(X)= 0.765490, D(G(X))= 0.599529\n",
            "Epoch: 1, d_loss= 1.064782, g_loss= 24.509832, ccaD(X)= 0.755908, D(G(X))= 0.412187\n",
            "Epoch: 1, d_loss= 1.018537, g_loss= 23.980963, ccaD(X)= 0.546123, D(G(X))= 0.257824\n",
            "Epoch: 1, d_loss= 1.080697, g_loss= 25.632269, ccaD(X)= 0.698106, D(G(X))= 0.416986\n",
            "Epoch: 1, d_loss= 1.331139, g_loss= 25.826218, ccaD(X)= 0.786924, D(G(X))= 0.559291\n",
            "Epoch: 1, d_loss= 1.494815, g_loss= 23.492771, ccaD(X)= 0.293871, D(G(X))= 0.088955\n",
            "Epoch: 1, d_loss= 1.073940, g_loss= 25.448639, ccaD(X)= 0.648065, D(G(X))= 0.385958\n",
            "Epoch: 1, d_loss= 1.030715, g_loss= 26.463318, ccaD(X)= 0.772805, D(G(X))= 0.412452\n",
            "Epoch: 1, d_loss= 1.204629, g_loss= 24.758099, ccaD(X)= 0.376609, D(G(X))= 0.103388\n",
            "Epoch: 1, d_loss= 1.259927, g_loss= 27.602406, ccaD(X)= 0.840360, D(G(X))= 0.551623\n",
            "Epoch: 1, d_loss= 1.166297, g_loss= 24.055590, ccaD(X)= 0.389672, D(G(X))= 0.126700\n",
            "Epoch: 1, d_loss= 1.303588, g_loss= 24.778742, ccaD(X)= 0.510395, D(G(X))= 0.395375\n",
            "Epoch: 1, d_loss= 0.987817, g_loss= 25.125172, ccaD(X)= 0.759384, D(G(X))= 0.403778\n",
            "Epoch: 1, d_loss= 0.949652, g_loss= 25.828739, ccaD(X)= 0.672851, D(G(X))= 0.327613\n",
            "Epoch: 1, d_loss= 1.006743, g_loss= 26.228359, ccaD(X)= 0.760753, D(G(X))= 0.415634\n",
            "Epoch: 1, d_loss= 0.896162, g_loss= 24.768654, ccaD(X)= 0.544017, D(G(X))= 0.166006\n",
            "Epoch: 1, d_loss= 1.377544, g_loss= 23.619686, ccaD(X)= 0.563884, D(G(X))= 0.476388\n",
            "Epoch: 1, d_loss= 0.826066, g_loss= 24.497501, ccaD(X)= 0.649984, D(G(X))= 0.240961\n",
            "Epoch: 1, d_loss= 1.006766, g_loss= 25.356253, ccaD(X)= 0.704134, D(G(X))= 0.390073\n",
            "Epoch: 1, d_loss= 0.865484, g_loss= 24.049683, ccaD(X)= 0.582098, D(G(X))= 0.201110\n",
            "Epoch: 1, d_loss= 1.097820, g_loss= 24.143841, ccaD(X)= 0.420133, D(G(X))= 0.128695\n",
            "Epoch: 1, d_loss= 0.907189, g_loss= 25.232098, ccaD(X)= 0.827961, D(G(X))= 0.393393\n",
            "Epoch: 1, d_loss= 1.196569, g_loss= 24.633699, ccaD(X)= 0.481107, D(G(X))= 0.307870\n",
            "Epoch: 2, d_loss= 1.080935, g_loss= 24.749380, ccaD(X)= 0.554499, D(G(X))= 0.314395\n",
            "Epoch: 2, d_loss= 1.299413, g_loss= 23.436384, ccaD(X)= 0.371870, D(G(X))= 0.211796\n",
            "Epoch: 2, d_loss= 1.387114, g_loss= 27.318760, ccaD(X)= 0.844296, D(G(X))= 0.595672\n",
            "Epoch: 2, d_loss= 0.823234, g_loss= 25.182541, ccaD(X)= 0.599143, D(G(X))= 0.196430\n",
            "Epoch: 2, d_loss= 0.749203, g_loss= 25.595554, ccaD(X)= 0.658157, D(G(X))= 0.180960\n",
            "Epoch: 2, d_loss= 1.773299, g_loss= 23.978748, ccaD(X)= 0.221823, D(G(X))= 0.116465\n",
            "Epoch: 2, d_loss= 1.114109, g_loss= 26.150082, ccaD(X)= 0.763596, D(G(X))= 0.476980\n",
            "Epoch: 2, d_loss= 0.992245, g_loss= 24.412008, ccaD(X)= 0.495385, D(G(X))= 0.152441\n",
            "Epoch: 2, d_loss= 1.104615, g_loss= 26.054560, ccaD(X)= 0.782214, D(G(X))= 0.464609\n",
            "Epoch: 2, d_loss= 1.078031, g_loss= 25.637005, ccaD(X)= 0.786310, D(G(X))= 0.465116\n",
            "Epoch: 2, d_loss= 1.116570, g_loss= 23.998878, ccaD(X)= 0.570892, D(G(X))= 0.364383\n",
            "Epoch: 2, d_loss= 1.191950, g_loss= 24.301163, ccaD(X)= 0.475817, D(G(X))= 0.283962\n",
            "Epoch: 2, d_loss= 1.003946, g_loss= 25.693087, ccaD(X)= 0.729709, D(G(X))= 0.403515\n",
            "Epoch: 2, d_loss= 0.987897, g_loss= 23.853401, ccaD(X)= 0.515745, D(G(X))= 0.191837\n",
            "Epoch: 2, d_loss= 1.107979, g_loss= 24.638060, ccaD(X)= 0.575087, D(G(X))= 0.360075\n",
            "Epoch: 2, d_loss= 1.065362, g_loss= 24.450171, ccaD(X)= 0.742644, D(G(X))= 0.436656\n",
            "Epoch: 2, d_loss= 1.124652, g_loss= 24.874760, ccaD(X)= 0.756574, D(G(X))= 0.482314\n",
            "Epoch: 2, d_loss= 1.098150, g_loss= 24.510468, ccaD(X)= 0.540743, D(G(X))= 0.324561\n",
            "Epoch: 2, d_loss= 1.160864, g_loss= 25.636246, ccaD(X)= 0.719995, D(G(X))= 0.475820\n",
            "Epoch: 2, d_loss= 1.170107, g_loss= 26.359095, ccaD(X)= 0.861949, D(G(X))= 0.516455\n",
            "Epoch: 2, d_loss= 1.229261, g_loss= 23.345455, ccaD(X)= 0.399020, D(G(X))= 0.222991\n",
            "Epoch: 2, d_loss= 1.227611, g_loss= 26.742434, ccaD(X)= 0.828281, D(G(X))= 0.543310\n",
            "Epoch: 2, d_loss= 1.283481, g_loss= 26.746069, ccaD(X)= 0.821158, D(G(X))= 0.560426\n",
            "Epoch: 3, d_loss= 1.330339, g_loss= 25.287046, ccaD(X)= 0.813031, D(G(X))= 0.580842\n",
            "Epoch: 3, d_loss= 1.035804, g_loss= 23.960995, ccaD(X)= 0.722306, D(G(X))= 0.417827\n",
            "Epoch: 3, d_loss= 1.017657, g_loss= 24.171360, ccaD(X)= 0.457295, D(G(X))= 0.158081\n",
            "Epoch: 3, d_loss= 1.169331, g_loss= 24.702007, ccaD(X)= 0.525279, D(G(X))= 0.353448\n",
            "Epoch: 3, d_loss= 1.018278, g_loss= 24.435415, ccaD(X)= 0.680396, D(G(X))= 0.377433\n",
            "Epoch: 3, d_loss= 1.049234, g_loss= 25.038383, ccaD(X)= 0.516027, D(G(X))= 0.266736\n",
            "Epoch: 3, d_loss= 1.362217, g_loss= 24.327541, ccaD(X)= 0.348457, D(G(X))= 0.208123\n",
            "Epoch: 3, d_loss= 1.028427, g_loss= 24.678587, ccaD(X)= 0.717995, D(G(X))= 0.421574\n",
            "Epoch: 3, d_loss= 0.910153, g_loss= 24.457176, ccaD(X)= 0.715258, D(G(X))= 0.348822\n",
            "Epoch: 3, d_loss= 1.038445, g_loss= 26.164761, ccaD(X)= 0.683881, D(G(X))= 0.395817\n",
            "Epoch: 3, d_loss= 1.212890, g_loss= 23.935869, ccaD(X)= 0.501630, D(G(X))= 0.343704\n",
            "Epoch: 3, d_loss= 1.033126, g_loss= 23.894110, ccaD(X)= 0.687154, D(G(X))= 0.408229\n",
            "Epoch: 3, d_loss= 1.309513, g_loss= 25.478971, ccaD(X)= 0.631259, D(G(X))= 0.500099\n",
            "Epoch: 3, d_loss= 1.013671, g_loss= 23.702652, ccaD(X)= 0.566053, D(G(X))= 0.301650\n",
            "Epoch: 3, d_loss= 1.222413, g_loss= 25.407570, ccaD(X)= 0.790035, D(G(X))= 0.530355\n",
            "Epoch: 3, d_loss= 1.180847, g_loss= 23.851841, ccaD(X)= 0.416442, D(G(X))= 0.216267\n",
            "Epoch: 3, d_loss= 1.453735, g_loss= 23.169670, ccaD(X)= 0.333464, D(G(X))= 0.265757\n",
            "Epoch: 3, d_loss= 1.130161, g_loss= 23.567776, ccaD(X)= 0.585270, D(G(X))= 0.390898\n",
            "Epoch: 3, d_loss= 1.197391, g_loss= 23.840292, ccaD(X)= 0.360493, D(G(X))= 0.124274\n",
            "Epoch: 3, d_loss= 1.093540, g_loss= 23.800922, ccaD(X)= 0.429848, D(G(X))= 0.183249\n",
            "Epoch: 3, d_loss= 1.074850, g_loss= 24.737835, ccaD(X)= 0.728127, D(G(X))= 0.443823\n",
            "Epoch: 3, d_loss= 2.078187, g_loss= 23.155893, ccaD(X)= 0.141688, D(G(X))= 0.051640\n",
            "Epoch: 3, d_loss= 1.559459, g_loss= 26.050867, ccaD(X)= 0.705216, D(G(X))= 0.633810\n",
            "Epoch: 4, d_loss= 1.062861, g_loss= 23.564232, ccaD(X)= 0.519781, D(G(X))= 0.283924\n",
            "Epoch: 4, d_loss= 1.120375, g_loss= 25.423964, ccaD(X)= 0.795248, D(G(X))= 0.491128\n",
            "Epoch: 4, d_loss= 1.085428, g_loss= 23.643423, ccaD(X)= 0.489542, D(G(X))= 0.247228\n",
            "Epoch: 4, d_loss= 1.127451, g_loss= 25.327339, ccaD(X)= 0.638876, D(G(X))= 0.417508\n",
            "Epoch: 4, d_loss= 1.461545, g_loss= 24.172215, ccaD(X)= 0.268329, D(G(X))= 0.106698\n",
            "Epoch: 4, d_loss= 1.153331, g_loss= 25.613522, ccaD(X)= 0.824779, D(G(X))= 0.524742\n",
            "Epoch: 4, d_loss= 1.217449, g_loss= 23.731628, ccaD(X)= 0.391286, D(G(X))= 0.203009\n",
            "Epoch: 4, d_loss= 1.010778, g_loss= 24.029667, ccaD(X)= 0.534784, D(G(X))= 0.265395\n",
            "Epoch: 4, d_loss= 1.326886, g_loss= 22.505129, ccaD(X)= 0.318424, D(G(X))= 0.125079\n",
            "Epoch: 4, d_loss= 1.201222, g_loss= 25.818855, ccaD(X)= 0.816686, D(G(X))= 0.536788\n",
            "Epoch: 4, d_loss= 1.105862, g_loss= 23.546961, ccaD(X)= 0.514510, D(G(X))= 0.312871\n",
            "Epoch: 4, d_loss= 1.140957, g_loss= 23.815849, ccaD(X)= 0.430129, D(G(X))= 0.201846\n",
            "Epoch: 4, d_loss= 1.205912, g_loss= 23.628046, ccaD(X)= 0.526710, D(G(X))= 0.380580\n",
            "Epoch: 4, d_loss= 1.155093, g_loss= 23.830252, ccaD(X)= 0.491378, D(G(X))= 0.302726\n",
            "Epoch: 4, d_loss= 1.259484, g_loss= 24.703642, ccaD(X)= 0.323295, D(G(X))= 0.061117\n",
            "Epoch: 4, d_loss= 1.147622, g_loss= 24.382370, ccaD(X)= 0.587784, D(G(X))= 0.399904\n",
            "Epoch: 4, d_loss= 0.867797, g_loss= 23.500654, ccaD(X)= 0.583413, D(G(X))= 0.214532\n",
            "Epoch: 4, d_loss= 1.068799, g_loss= 25.187433, ccaD(X)= 0.706282, D(G(X))= 0.430320\n",
            "Epoch: 4, d_loss= 1.561785, g_loss= 25.712015, ccaD(X)= 0.859432, D(G(X))= 0.671769\n",
            "Epoch: 4, d_loss= 1.263044, g_loss= 22.983185, ccaD(X)= 0.387219, D(G(X))= 0.242219\n",
            "Epoch: 4, d_loss= 1.402502, g_loss= 23.504490, ccaD(X)= 0.324827, D(G(X))= 0.221728\n",
            "Epoch: 4, d_loss= 1.180164, g_loss= 24.292336, ccaD(X)= 0.579682, D(G(X))= 0.406868\n",
            "Epoch: 4, d_loss= 1.327153, g_loss= 23.567247, ccaD(X)= 0.324299, D(G(X))= 0.123182\n",
            "Epoch: 5, d_loss= 1.387148, g_loss= 23.590662, ccaD(X)= 0.310381, D(G(X))= 0.168169\n",
            "Epoch: 5, d_loss= 0.903892, g_loss= 24.272676, ccaD(X)= 0.671789, D(G(X))= 0.318136\n",
            "Epoch: 5, d_loss= 1.078886, g_loss= 23.994331, ccaD(X)= 0.528750, D(G(X))= 0.309583\n",
            "Epoch: 5, d_loss= 1.220082, g_loss= 23.813547, ccaD(X)= 0.488144, D(G(X))= 0.349546\n",
            "Epoch: 5, d_loss= 1.039881, g_loss= 23.254957, ccaD(X)= 0.451494, D(G(X))= 0.176750\n",
            "Epoch: 5, d_loss= 0.957205, g_loss= 24.862003, ccaD(X)= 0.687665, D(G(X))= 0.361288\n",
            "Epoch: 5, d_loss= 1.098879, g_loss= 23.739941, ccaD(X)= 0.436640, D(G(X))= 0.180120\n",
            "Epoch: 5, d_loss= 0.992187, g_loss= 24.613516, ccaD(X)= 0.634034, D(G(X))= 0.345936\n",
            "Epoch: 5, d_loss= 1.237746, g_loss= 24.426025, ccaD(X)= 0.718195, D(G(X))= 0.511803\n",
            "Epoch: 5, d_loss= 1.117679, g_loss= 23.880367, ccaD(X)= 0.498281, D(G(X))= 0.291664\n",
            "Epoch: 5, d_loss= 1.094399, g_loss= 23.190628, ccaD(X)= 0.491099, D(G(X))= 0.275612\n",
            "Epoch: 5, d_loss= 0.822255, g_loss= 24.690907, ccaD(X)= 0.673631, D(G(X))= 0.263907\n",
            "Epoch: 5, d_loss= 0.957349, g_loss= 25.664391, ccaD(X)= 0.751192, D(G(X))= 0.395455\n",
            "Epoch: 5, d_loss= 0.958159, g_loss= 23.696760, ccaD(X)= 0.530786, D(G(X))= 0.226522\n",
            "Epoch: 5, d_loss= 1.149021, g_loss= 23.505001, ccaD(X)= 0.467050, D(G(X))= 0.263969\n",
            "Epoch: 5, d_loss= 0.989686, g_loss= 24.131447, ccaD(X)= 0.520546, D(G(X))= 0.240464\n",
            "Epoch: 5, d_loss= 1.129396, g_loss= 25.044489, ccaD(X)= 0.834869, D(G(X))= 0.504501\n",
            "Epoch: 5, d_loss= 1.053676, g_loss= 24.960791, ccaD(X)= 0.721418, D(G(X))= 0.437704\n",
            "Epoch: 5, d_loss= 0.962945, g_loss= 25.038267, ccaD(X)= 0.675814, D(G(X))= 0.359331\n",
            "Epoch: 5, d_loss= 1.209556, g_loss= 23.934242, ccaD(X)= 0.747769, D(G(X))= 0.514997\n",
            "Epoch: 5, d_loss= 1.319088, g_loss= 25.645769, ccaD(X)= 0.793925, D(G(X))= 0.569203\n",
            "Epoch: 5, d_loss= 0.961253, g_loss= 24.000301, ccaD(X)= 0.542419, D(G(X))= 0.239052\n",
            "Epoch: 5, d_loss= 0.789857, g_loss= 25.046017, ccaD(X)= 0.620805, D(G(X))= 0.193885\n",
            "Epoch: 6, d_loss= 0.793624, g_loss= 24.104824, ccaD(X)= 0.639791, D(G(X))= 0.221785\n",
            "Epoch: 6, d_loss= 1.054506, g_loss= 23.828957, ccaD(X)= 0.551396, D(G(X))= 0.309997\n",
            "Epoch: 6, d_loss= 1.136913, g_loss= 23.664810, ccaD(X)= 0.529701, D(G(X))= 0.353383\n",
            "Epoch: 6, d_loss= 1.050376, g_loss= 23.163736, ccaD(X)= 0.425293, D(G(X))= 0.148312\n",
            "Epoch: 6, d_loss= 1.352405, g_loss= 23.377045, ccaD(X)= 0.441667, D(G(X))= 0.384365\n",
            "Epoch: 6, d_loss= 1.198735, g_loss= 23.817291, ccaD(X)= 0.367048, D(G(X))= 0.159094\n",
            "Epoch: 6, d_loss= 1.234102, g_loss= 24.538942, ccaD(X)= 0.718189, D(G(X))= 0.504955\n",
            "Epoch: 6, d_loss= 1.113349, g_loss= 23.450068, ccaD(X)= 0.446039, D(G(X))= 0.234944\n",
            "Epoch: 6, d_loss= 1.004519, g_loss= 23.834793, ccaD(X)= 0.652965, D(G(X))= 0.372342\n",
            "Epoch: 6, d_loss= 2.035719, g_loss= 23.517477, ccaD(X)= 0.141857, D(G(X))= 0.108673\n",
            "Epoch: 6, d_loss= 1.015689, g_loss= 24.970179, ccaD(X)= 0.704067, D(G(X))= 0.406862\n",
            "Epoch: 6, d_loss= 1.095611, g_loss= 24.147175, ccaD(X)= 0.440874, D(G(X))= 0.180826\n",
            "Epoch: 6, d_loss= 1.263730, g_loss= 23.180815, ccaD(X)= 0.450929, D(G(X))= 0.338825\n",
            "Epoch: 6, d_loss= 1.204816, g_loss= 23.974148, ccaD(X)= 0.743029, D(G(X))= 0.516515\n",
            "Epoch: 6, d_loss= 1.144154, g_loss= 24.368208, ccaD(X)= 0.529649, D(G(X))= 0.307497\n",
            "Epoch: 6, d_loss= 1.152648, g_loss= 24.055532, ccaD(X)= 0.673783, D(G(X))= 0.454677\n",
            "Epoch: 6, d_loss= 0.917948, g_loss= 23.926849, ccaD(X)= 0.548000, D(G(X))= 0.218841\n",
            "Epoch: 6, d_loss= 1.653992, g_loss= 23.210178, ccaD(X)= 0.201265, D(G(X))= 0.034768\n",
            "Epoch: 6, d_loss= 1.023170, g_loss= 24.689785, ccaD(X)= 0.710188, D(G(X))= 0.416196\n",
            "Epoch: 6, d_loss= 1.189248, g_loss= 24.687462, ccaD(X)= 0.602568, D(G(X))= 0.435039\n",
            "Epoch: 6, d_loss= 0.993965, g_loss= 24.212959, ccaD(X)= 0.719128, D(G(X))= 0.403499\n",
            "Epoch: 6, d_loss= 1.059368, g_loss= 24.228416, ccaD(X)= 0.666187, D(G(X))= 0.410090\n",
            "Epoch: 6, d_loss= 0.957660, g_loss= 25.158817, ccaD(X)= 0.782336, D(G(X))= 0.419270\n",
            "Epoch: 7, d_loss= 1.111154, g_loss= 23.652191, ccaD(X)= 0.576546, D(G(X))= 0.370288\n",
            "Epoch: 7, d_loss= 0.964047, g_loss= 24.764376, ccaD(X)= 0.614581, D(G(X))= 0.314759\n",
            "Epoch: 7, d_loss= 1.095111, g_loss= 22.544361, ccaD(X)= 0.409805, D(G(X))= 0.156337\n",
            "Epoch: 7, d_loss= 1.021886, g_loss= 24.318878, ccaD(X)= 0.552863, D(G(X))= 0.292834\n",
            "Epoch: 7, d_loss= 0.936994, g_loss= 25.003130, ccaD(X)= 0.820202, D(G(X))= 0.406320\n",
            "Epoch: 7, d_loss= 1.027368, g_loss= 25.302885, ccaD(X)= 0.807490, D(G(X))= 0.459270\n",
            "Epoch: 7, d_loss= 1.108005, g_loss= 23.030548, ccaD(X)= 0.458058, D(G(X))= 0.230059\n",
            "Epoch: 7, d_loss= 1.000612, g_loss= 24.731255, ccaD(X)= 0.694424, D(G(X))= 0.387366\n",
            "Epoch: 7, d_loss= 0.940781, g_loss= 24.836874, ccaD(X)= 0.725405, D(G(X))= 0.371485\n",
            "Epoch: 7, d_loss= 1.066523, g_loss= 24.738367, ccaD(X)= 0.769629, D(G(X))= 0.463403\n",
            "Epoch: 7, d_loss= 0.982286, g_loss= 23.217789, ccaD(X)= 0.545214, D(G(X))= 0.252803\n",
            "Epoch: 7, d_loss= 1.340600, g_loss= 24.842209, ccaD(X)= 0.834016, D(G(X))= 0.597661\n",
            "Epoch: 7, d_loss= 1.365447, g_loss= 23.862274, ccaD(X)= 0.299152, D(G(X))= 0.140350\n",
            "Epoch: 7, d_loss= 1.174739, g_loss= 23.537224, ccaD(X)= 0.362690, D(G(X))= 0.124611\n",
            "Epoch: 7, d_loss= 1.020170, g_loss= 24.398523, ccaD(X)= 0.705877, D(G(X))= 0.413121\n",
            "Epoch: 7, d_loss= 1.426193, g_loss= 23.163502, ccaD(X)= 0.321091, D(G(X))= 0.225478\n",
            "Epoch: 7, d_loss= 0.978552, g_loss= 24.317192, ccaD(X)= 0.630798, D(G(X))= 0.336375\n",
            "Epoch: 7, d_loss= 1.252080, g_loss= 24.509775, ccaD(X)= 0.701822, D(G(X))= 0.513479\n",
            "Epoch: 7, d_loss= 0.954203, g_loss= 25.551432, ccaD(X)= 0.801787, D(G(X))= 0.416287\n",
            "Epoch: 7, d_loss= 1.166017, g_loss= 23.584118, ccaD(X)= 0.530751, D(G(X))= 0.364215\n",
            "Epoch: 7, d_loss= 1.240210, g_loss= 25.279299, ccaD(X)= 0.750364, D(G(X))= 0.535663\n",
            "Epoch: 7, d_loss= 0.917368, g_loss= 24.124182, ccaD(X)= 0.682276, D(G(X))= 0.337806\n",
            "Epoch: 7, d_loss= 0.840805, g_loss= 24.762320, ccaD(X)= 0.749380, D(G(X))= 0.323965\n",
            "Epoch: 8, d_loss= 1.334357, g_loss= 24.991993, ccaD(X)= 0.780374, D(G(X))= 0.580148\n",
            "Epoch: 8, d_loss= 0.874424, g_loss= 23.558842, ccaD(X)= 0.602779, D(G(X))= 0.246037\n",
            "Epoch: 8, d_loss= 1.171196, g_loss= 23.377295, ccaD(X)= 0.362381, D(G(X))= 0.110379\n",
            "Epoch: 8, d_loss= 0.709036, g_loss= 24.818823, ccaD(X)= 0.678286, D(G(X))= 0.192109\n",
            "Epoch: 8, d_loss= 1.069439, g_loss= 24.107088, ccaD(X)= 0.666368, D(G(X))= 0.410658\n",
            "Epoch: 8, d_loss= 1.055448, g_loss= 23.673378, ccaD(X)= 0.499660, D(G(X))= 0.248946\n",
            "Epoch: 8, d_loss= 1.038543, g_loss= 24.160431, ccaD(X)= 0.611605, D(G(X))= 0.359849\n",
            "Epoch: 8, d_loss= 1.514152, g_loss= 23.975475, ccaD(X)= 0.242027, D(G(X))= 0.095123\n",
            "Epoch: 8, d_loss= 1.000209, g_loss= 23.665039, ccaD(X)= 0.619969, D(G(X))= 0.342682\n",
            "Epoch: 8, d_loss= 0.893116, g_loss= 23.839724, ccaD(X)= 0.687512, D(G(X))= 0.318685\n",
            "Epoch: 8, d_loss= 1.364073, g_loss= 23.657179, ccaD(X)= 0.283671, D(G(X))= 0.048574\n",
            "Epoch: 8, d_loss= 1.064303, g_loss= 24.325136, ccaD(X)= 0.490477, D(G(X))= 0.241176\n",
            "Epoch: 8, d_loss= 0.828900, g_loss= 24.109165, ccaD(X)= 0.642440, D(G(X))= 0.248575\n",
            "Epoch: 8, d_loss= 0.967159, g_loss= 24.091578, ccaD(X)= 0.595527, D(G(X))= 0.295595\n",
            "Epoch: 8, d_loss= 1.146392, g_loss= 25.346346, ccaD(X)= 0.758362, D(G(X))= 0.495834\n",
            "Epoch: 8, d_loss= 0.838082, g_loss= 24.178593, ccaD(X)= 0.590038, D(G(X))= 0.207519\n",
            "Epoch: 8, d_loss= 1.423650, g_loss= 22.346912, ccaD(X)= 0.274352, D(G(X))= 0.075896\n",
            "Epoch: 8, d_loss= 1.004355, g_loss= 23.793615, ccaD(X)= 0.553494, D(G(X))= 0.287629\n",
            "Epoch: 8, d_loss= 1.314855, g_loss= 23.442867, ccaD(X)= 0.313116, D(G(X))= 0.133978\n",
            "Epoch: 8, d_loss= 1.004760, g_loss= 23.552885, ccaD(X)= 0.427181, D(G(X))= 0.098182\n",
            "Epoch: 8, d_loss= 0.904810, g_loss= 23.712469, ccaD(X)= 0.740414, D(G(X))= 0.359312\n",
            "Epoch: 8, d_loss= 0.975937, g_loss= 23.690557, ccaD(X)= 0.663238, D(G(X))= 0.361648\n",
            "Epoch: 8, d_loss= 0.863083, g_loss= 24.043646, ccaD(X)= 0.733280, D(G(X))= 0.333705\n",
            "Epoch: 9, d_loss= 0.922333, g_loss= 24.388741, ccaD(X)= 0.682645, D(G(X))= 0.336602\n",
            "Epoch: 9, d_loss= 1.181139, g_loss= 23.305807, ccaD(X)= 0.369477, D(G(X))= 0.140410\n",
            "Epoch: 9, d_loss= 0.784416, g_loss= 25.168550, ccaD(X)= 0.724118, D(G(X))= 0.279965\n",
            "Epoch: 9, d_loss= 1.235987, g_loss= 22.955799, ccaD(X)= 0.352202, D(G(X))= 0.111823\n",
            "Epoch: 9, d_loss= 0.837462, g_loss= 23.813538, ccaD(X)= 0.594312, D(G(X))= 0.211562\n",
            "Epoch: 9, d_loss= 0.793691, g_loss= 24.851711, ccaD(X)= 0.673699, D(G(X))= 0.246637\n",
            "Epoch: 9, d_loss= 1.035973, g_loss= 23.547825, ccaD(X)= 0.599423, D(G(X))= 0.346369\n",
            "Epoch: 9, d_loss= 0.992517, g_loss= 23.696190, ccaD(X)= 0.540502, D(G(X))= 0.254151\n",
            "Epoch: 9, d_loss= 0.972441, g_loss= 24.208086, ccaD(X)= 0.757547, D(G(X))= 0.410404\n",
            "Epoch: 9, d_loss= 0.783868, g_loss= 24.483625, ccaD(X)= 0.666191, D(G(X))= 0.226651\n",
            "Epoch: 9, d_loss= 0.989389, g_loss= 24.737049, ccaD(X)= 0.737784, D(G(X))= 0.410976\n",
            "Epoch: 9, d_loss= 0.900941, g_loss= 24.282631, ccaD(X)= 0.817789, D(G(X))= 0.394804\n",
            "Epoch: 9, d_loss= 0.981536, g_loss= 24.014696, ccaD(X)= 0.544644, D(G(X))= 0.257259\n",
            "Epoch: 9, d_loss= 1.264555, g_loss= 26.370232, ccaD(X)= 0.857771, D(G(X))= 0.569020\n",
            "Epoch: 9, d_loss= 1.173215, g_loss= 23.708841, ccaD(X)= 0.398677, D(G(X))= 0.182011\n",
            "Epoch: 9, d_loss= 0.793673, g_loss= 23.768221, ccaD(X)= 0.582897, D(G(X))= 0.166728\n",
            "Epoch: 9, d_loss= 1.884543, g_loss= 22.277937, ccaD(X)= 0.161990, D(G(X))= 0.083632\n",
            "Epoch: 9, d_loss= 1.083991, g_loss= 24.010990, ccaD(X)= 0.743717, D(G(X))= 0.458233\n",
            "Epoch: 9, d_loss= 0.841709, g_loss= 23.498301, ccaD(X)= 0.556492, D(G(X))= 0.172356\n",
            "Epoch: 9, d_loss= 1.170734, g_loss= 24.088432, ccaD(X)= 0.346821, D(G(X))= 0.081902\n",
            "Epoch: 9, d_loss= 1.090299, g_loss= 23.357321, ccaD(X)= 0.397574, D(G(X))= 0.129022\n",
            "Epoch: 9, d_loss= 0.848058, g_loss= 23.735220, ccaD(X)= 0.619591, D(G(X))= 0.244820\n",
            "Epoch: 9, d_loss= 0.749786, g_loss= 24.267570, ccaD(X)= 0.594675, D(G(X))= 0.150551\n",
            "Epoch: 10, d_loss= 0.955795, g_loss= 24.292385, ccaD(X)= 0.649929, D(G(X))= 0.334009\n",
            "Epoch: 10, d_loss= 0.890816, g_loss= 24.343748, ccaD(X)= 0.490809, D(G(X))= 0.109830\n",
            "Epoch: 10, d_loss= 0.889917, g_loss= 25.043932, ccaD(X)= 0.830353, D(G(X))= 0.389258\n",
            "Epoch: 10, d_loss= 0.890646, g_loss= 24.377571, ccaD(X)= 0.709918, D(G(X))= 0.339231\n",
            "Epoch: 10, d_loss= 1.237072, g_loss= 22.899530, ccaD(X)= 0.334659, D(G(X))= 0.107109\n",
            "Epoch: 10, d_loss= 0.823002, g_loss= 25.212612, ccaD(X)= 0.784911, D(G(X))= 0.340122\n",
            "Epoch: 10, d_loss= 0.934427, g_loss= 26.150734, ccaD(X)= 0.760046, D(G(X))= 0.388810\n",
            "Epoch: 10, d_loss= 0.914731, g_loss= 25.017357, ccaD(X)= 0.812867, D(G(X))= 0.395686\n",
            "Epoch: 10, d_loss= 1.211900, g_loss= 23.219946, ccaD(X)= 0.329306, D(G(X))= 0.076898\n",
            "Epoch: 10, d_loss= 0.930719, g_loss= 24.919876, ccaD(X)= 0.775331, D(G(X))= 0.392698\n",
            "Epoch: 10, d_loss= 0.907071, g_loss= 24.880074, ccaD(X)= 0.737195, D(G(X))= 0.363283\n",
            "Epoch: 10, d_loss= 0.843905, g_loss= 25.674906, ccaD(X)= 0.757339, D(G(X))= 0.338141\n",
            "Epoch: 10, d_loss= 1.134799, g_loss= 23.577089, ccaD(X)= 0.352865, D(G(X))= 0.070988\n",
            "Epoch: 10, d_loss= 0.996985, g_loss= 22.995546, ccaD(X)= 0.465217, D(G(X))= 0.148706\n",
            "Epoch: 10, d_loss= 0.964899, g_loss= 24.744871, ccaD(X)= 0.791308, D(G(X))= 0.409053\n",
            "Epoch: 10, d_loss= 1.344317, g_loss= 22.734951, ccaD(X)= 0.304416, D(G(X))= 0.067016\n",
            "Epoch: 10, d_loss= 0.854245, g_loss= 24.686049, ccaD(X)= 0.580543, D(G(X))= 0.200394\n",
            "Epoch: 10, d_loss= 0.868347, g_loss= 24.286400, ccaD(X)= 0.619777, D(G(X))= 0.252166\n",
            "Epoch: 10, d_loss= 1.443506, g_loss= 23.425810, ccaD(X)= 0.250540, D(G(X))= 0.063863\n",
            "Epoch: 10, d_loss= 1.009548, g_loss= 24.003899, ccaD(X)= 0.820173, D(G(X))= 0.447334\n",
            "Epoch: 10, d_loss= 0.886933, g_loss= 24.075897, ccaD(X)= 0.683019, D(G(X))= 0.315418\n",
            "Epoch: 10, d_loss= 0.904265, g_loss= 24.125313, ccaD(X)= 0.603784, D(G(X))= 0.264471\n",
            "Epoch: 10, d_loss= 0.923738, g_loss= 24.681149, ccaD(X)= 0.699683, D(G(X))= 0.354216\n",
            "Epoch: 11, d_loss= 1.028760, g_loss= 25.779875, ccaD(X)= 0.706611, D(G(X))= 0.415484\n",
            "Epoch: 11, d_loss= 0.921675, g_loss= 23.918047, ccaD(X)= 0.599030, D(G(X))= 0.271111\n",
            "Epoch: 11, d_loss= 1.081438, g_loss= 25.056347, ccaD(X)= 0.839901, D(G(X))= 0.481360\n",
            "Epoch: 11, d_loss= 0.819795, g_loss= 25.038206, ccaD(X)= 0.610784, D(G(X))= 0.209446\n",
            "Epoch: 11, d_loss= 0.870122, g_loss= 23.278360, ccaD(X)= 0.700794, D(G(X))= 0.310143\n",
            "Epoch: 11, d_loss= 0.898768, g_loss= 23.619705, ccaD(X)= 0.664507, D(G(X))= 0.316521\n",
            "Epoch: 11, d_loss= 0.914771, g_loss= 24.820316, ccaD(X)= 0.792631, D(G(X))= 0.394251\n",
            "Epoch: 11, d_loss= 0.909969, g_loss= 25.145386, ccaD(X)= 0.705351, D(G(X))= 0.344456\n",
            "Epoch: 11, d_loss= 0.827785, g_loss= 24.727716, ccaD(X)= 0.623974, D(G(X))= 0.222304\n",
            "Epoch: 11, d_loss= 1.149109, g_loss= 26.240223, ccaD(X)= 0.881711, D(G(X))= 0.523159\n",
            "Epoch: 11, d_loss= 0.851873, g_loss= 23.750109, ccaD(X)= 0.534945, D(G(X))= 0.152487\n",
            "Epoch: 11, d_loss= 0.849861, g_loss= 24.118618, ccaD(X)= 0.619616, D(G(X))= 0.234698\n",
            "Epoch: 11, d_loss= 0.847760, g_loss= 23.492682, ccaD(X)= 0.505340, D(G(X))= 0.107776\n",
            "Epoch: 11, d_loss= 1.162436, g_loss= 25.274307, ccaD(X)= 0.747926, D(G(X))= 0.470851\n",
            "Epoch: 11, d_loss= 1.262393, g_loss= 22.988115, ccaD(X)= 0.318265, D(G(X))= 0.084316\n",
            "Epoch: 11, d_loss= 0.826341, g_loss= 24.872030, ccaD(X)= 0.776375, D(G(X))= 0.332686\n",
            "Epoch: 11, d_loss= 0.919448, g_loss= 24.231161, ccaD(X)= 0.507050, D(G(X))= 0.156700\n",
            "Epoch: 11, d_loss= 0.781291, g_loss= 24.547443, ccaD(X)= 0.597169, D(G(X))= 0.158563\n",
            "Epoch: 11, d_loss= 0.813627, g_loss= 23.573921, ccaD(X)= 0.573725, D(G(X))= 0.167969\n",
            "Epoch: 11, d_loss= 1.020934, g_loss= 23.539192, ccaD(X)= 0.419719, D(G(X))= 0.101565\n",
            "Epoch: 11, d_loss= 0.681516, g_loss= 24.248226, ccaD(X)= 0.707261, D(G(X))= 0.186663\n",
            "Epoch: 11, d_loss= 0.798248, g_loss= 23.606075, ccaD(X)= 0.590728, D(G(X))= 0.167592\n",
            "Epoch: 11, d_loss= 1.267577, g_loss= 26.569366, ccaD(X)= 0.924119, D(G(X))= 0.563580\n",
            "Epoch: 12, d_loss= 1.284745, g_loss= 22.804350, ccaD(X)= 0.314287, D(G(X))= 0.070750\n",
            "Epoch: 12, d_loss= 0.804455, g_loss= 23.835531, ccaD(X)= 0.630942, D(G(X))= 0.222308\n",
            "Epoch: 12, d_loss= 1.291221, g_loss= 25.511213, ccaD(X)= 0.905821, D(G(X))= 0.580404\n",
            "Epoch: 12, d_loss= 0.660967, g_loss= 24.297684, ccaD(X)= 0.679997, D(G(X))= 0.159871\n",
            "Epoch: 12, d_loss= 0.982280, g_loss= 26.363415, ccaD(X)= 0.865927, D(G(X))= 0.444272\n",
            "Epoch: 12, d_loss= 1.364063, g_loss= 25.044340, ccaD(X)= 0.850754, D(G(X))= 0.590622\n",
            "Epoch: 12, d_loss= 0.856447, g_loss= 23.616453, ccaD(X)= 0.531806, D(G(X))= 0.142131\n",
            "Epoch: 12, d_loss= 0.912308, g_loss= 24.549351, ccaD(X)= 0.661033, D(G(X))= 0.302677\n",
            "Epoch: 12, d_loss= 0.927574, g_loss= 25.366003, ccaD(X)= 0.822464, D(G(X))= 0.405845\n",
            "Epoch: 12, d_loss= 0.787445, g_loss= 24.924311, ccaD(X)= 0.803124, D(G(X))= 0.319165\n",
            "Epoch: 12, d_loss= 0.744702, g_loss= 24.213659, ccaD(X)= 0.591822, D(G(X))= 0.119946\n",
            "Epoch: 12, d_loss= 0.940008, g_loss= 23.258801, ccaD(X)= 0.472698, D(G(X))= 0.137205\n",
            "Epoch: 12, d_loss= 0.695664, g_loss= 24.394600, ccaD(X)= 0.713107, D(G(X))= 0.202096\n",
            "Epoch: 12, d_loss= 0.774052, g_loss= 25.197680, ccaD(X)= 0.708943, D(G(X))= 0.257756\n",
            "Epoch: 12, d_loss= 1.239518, g_loss= 26.525227, ccaD(X)= 0.876988, D(G(X))= 0.549933\n",
            "Epoch: 12, d_loss= 0.930286, g_loss= 23.209255, ccaD(X)= 0.466574, D(G(X))= 0.108022\n",
            "Epoch: 12, d_loss= 0.876240, g_loss= 24.613968, ccaD(X)= 0.684374, D(G(X))= 0.309897\n",
            "Epoch: 12, d_loss= 0.678336, g_loss= 24.730247, ccaD(X)= 0.629695, D(G(X))= 0.111257\n",
            "Epoch: 12, d_loss= 0.782758, g_loss= 25.323286, ccaD(X)= 0.729612, D(G(X))= 0.275220\n",
            "Epoch: 12, d_loss= 0.884311, g_loss= 24.531988, ccaD(X)= 0.704589, D(G(X))= 0.327951\n",
            "Epoch: 12, d_loss= 1.016942, g_loss= 25.084330, ccaD(X)= 0.846655, D(G(X))= 0.454750\n",
            "Epoch: 12, d_loss= 1.043670, g_loss= 23.430340, ccaD(X)= 0.395386, D(G(X))= 0.067154\n",
            "Epoch: 12, d_loss= 0.748740, g_loss= 24.478170, ccaD(X)= 0.581481, D(G(X))= 0.116361\n",
            "Epoch: 13, d_loss= 0.740143, g_loss= 25.346069, ccaD(X)= 0.820049, D(G(X))= 0.291895\n",
            "Epoch: 13, d_loss= 0.720310, g_loss= 24.125446, ccaD(X)= 0.753374, D(G(X))= 0.246771\n",
            "Epoch: 13, d_loss= 0.707315, g_loss= 24.688248, ccaD(X)= 0.722377, D(G(X))= 0.211835\n",
            "Epoch: 13, d_loss= 0.780771, g_loss= 24.118616, ccaD(X)= 0.685026, D(G(X))= 0.249233\n",
            "Epoch: 13, d_loss= 0.965787, g_loss= 23.316559, ccaD(X)= 0.444583, D(G(X))= 0.108852\n",
            "Epoch: 13, d_loss= 0.865333, g_loss= 24.259024, ccaD(X)= 0.493791, D(G(X))= 0.092816\n",
            "Epoch: 13, d_loss= 1.341544, g_loss= 21.757347, ccaD(X)= 0.284889, D(G(X))= 0.073501\n",
            "Epoch: 13, d_loss= 0.866680, g_loss= 23.224483, ccaD(X)= 0.511413, D(G(X))= 0.113238\n",
            "Epoch: 13, d_loss= 0.980200, g_loss= 23.498690, ccaD(X)= 0.452555, D(G(X))= 0.120614\n",
            "Epoch: 13, d_loss= 0.719108, g_loss= 23.713717, ccaD(X)= 0.739115, D(G(X))= 0.235742\n",
            "Epoch: 13, d_loss= 0.810785, g_loss= 25.280752, ccaD(X)= 0.897616, D(G(X))= 0.351041\n",
            "Epoch: 13, d_loss= 0.879190, g_loss= 23.555849, ccaD(X)= 0.474648, D(G(X))= 0.076610\n",
            "Epoch: 13, d_loss= 0.848597, g_loss= 23.368286, ccaD(X)= 0.577043, D(G(X))= 0.197580\n",
            "Epoch: 13, d_loss= 0.821550, g_loss= 24.000744, ccaD(X)= 0.609461, D(G(X))= 0.205000\n",
            "Epoch: 13, d_loss= 0.696899, g_loss= 24.877529, ccaD(X)= 0.733664, D(G(X))= 0.213897\n",
            "Epoch: 13, d_loss= 0.554347, g_loss= 25.057371, ccaD(X)= 0.748195, D(G(X))= 0.109965\n",
            "Epoch: 13, d_loss= 0.938212, g_loss= 23.632154, ccaD(X)= 0.536774, D(G(X))= 0.205398\n",
            "Epoch: 13, d_loss= 0.881922, g_loss= 23.772186, ccaD(X)= 0.482915, D(G(X))= 0.071810\n"
          ]
        }
      ]
    }
  ]
}